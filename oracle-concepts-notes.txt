Notes from Oracle Database Concepts Guide 11g Release 2 (11.2)

* Chapter 1: Introduction to Oracle Database

Oracle Real Application Clusters (Oracle RAC)
  Oracle9i Database introduced Oracle RAC in 2001, enabling multiple instances to access a
  single database simultaneously.

PL/SQL is an Oracle-specific procedural extension to SQL.  PL/SQL can control the flow of
a SQL program, use variables, and write error-handling procedures.

The main benefit of PL/SQL is stored procedures or functions.
A procedure or function is a schema object containing SQL and other logic
that runs server-side.

Oracle also supports java stored procedures.  A java stored procedure is:
    a Java method published to SQL and stored in the database for general use. You can
    call existing PL/SQL programs from Java and Java programs from PL/SQL

** Transaction Management

*** Data Consistency:

Oracle Database always enforces statement-level read consistency, which guarantees that
the data returned by a single query is committed and consistent with respect to a single
point in time. Depending on the transaction isolation level, this point is the time at
which the statement was opened or the time the transaction began. The Flashback Query
feature enables you to specify this point in time explicitly.

The database can also provide read consistency to all queries in a transaction, known as
transaction-level read consistency. In this case, each statement in a transaction sees
data from the same point in time, which is the time at which the transaction began.

** Oracle Database Architecture

*** Database and Instance

An Oracle database server consists of a database and at least one database instance
(commonly referred to as simply an instance). Because an instance and a database are so
closely connected, the term Oracle database is sometimes used to refer to both instance
and database. In the strictest sense the terms have the following meanings:

  - Database

    A database is a set of files, located on disk, that store data. These files can exist
    independently of a database instance.

  - Database instance

    An instance is a set of memory structures that manage database files. The instance
    consists of a shared memory area, called the system global area (SGA), and a set of
    background processes. An instance can exist independently of database files.

For each user connection to the instance, the application is run by a client process. Each
client process is associated with its own server process. The server process has its own
private session memory, known as the program global area (PGA).

*** Database Storage Structures

**** Physical Storage Structures

The physical database structures are the files that store the data. When you execute the
SQL command CREATE DATABASE, the following files are created:

  - Data files

    Every Oracle database has one or more physical data files, which contain all the
    database data. The data of logical database structures, such as tables and indexes, is
    physically stored in the data files.

  - Control files

    Every Oracle database has a control file. A control file contains metadata specifying
    the physical structure of the database, including the database name and the names and
    locations of the database files.

  - Online redo log files

    Every Oracle Database has an online redo log, which is a set of two or more online
    redo log files. An online redo log is made up of redo entries (also called redo
    records), which record all changes made to data.

Many other files are important for the functioning of an Oracle database server. These
files include parameter files and diagnostic files. Backup files and archived redo log
files are offline files important for backup and recovery.

See Also:

  - Chapter 11, "Physical Storage Structures"

**** Logical Storage Structures

The following logical storage structures enable Oracle Database to have fine-grained
control of disk space use:

  - Data blocks

    At the finest level of granularity, Oracle Database data is stored in data blocks.
    One data block corresponds to a specific number of bytes on disk.

  - Extents

    An extent is a specific number of logically contiguous data blocks, obtained in a
    single allocation, used to store a specific type of information.

  - Segments

    A segment is a set of extents allocated for a user object (for example, a table or
    index), undo data, or temporary data.

  - Tablespaces 

    A database is divided into logical storage units called tablespaces. A tablespace is
    the logical container for a segment. Each tablespace contains at least one data file.

See Also:

  - Chapter 12, "Logical Storage Structures"

*** Database Instance Structures

An Oracle database uses memory structures and processes to manage and access the
database. All memory structures exist in the main memory of the computers that constitute
the RDBMS.

When applications connect to an Oracle database, they are connected to a database
instance. The instance services applications by allocating other memory areas in addition
to the SGA, and starting other processes in addition to background processes.

**** Oracle Database Processes

A process is a mechanism in an operating system that can run a series of steps. Some
operating systems use the terms job, task, or thread. For the purpose of this discussion,
a thread is equivalent to a process. An Oracle database instance has the following types
of processes:

  - Client processes

    These processes are created and maintained to run the software code of an application
    program or an Oracle tool. Most environments have separate computers for client
    processes.

  - Background processes

    These processes consolidate functions that would otherwise be handled by multiple
    Oracle Database programs running for each client process. Background processes
    asynchronously perform I/O and monitor other Oracle Database processes to provide
    increased parallelism for better performance and reliability.

  - Server processes

    These processes communicate with client processes and interact with Oracle Database to
    fulfill requests.

Oracle processes include server processes and background processes. In most environments,
Oracle processes and client processes run on separate computers.

See Also:

  - Chapter 15, "Process Architecture"

**** Instance Memory Structures

Oracle Database creates and uses memory structures for purposes such as memory for program
code, data shared among users, and private data areas for each connected user. The
following memory structures are associated with an instance:

  - System Global Area (SGA)

    The SGA is a group of shared memory structures that contain data and control
    information for one database instance. Examples of SGA components include cached data
    blocks and shared SQL areas.

  - Program Global Areas (PGA)

    A PGA is a memory region that contain data and control information for a server or
    background process. Access to the PGA is exclusive to the process. Each server process
    and background process has its own PGA.

See Also:

  - Chapter 14, "Memory Architecture"

*** Application and Networking Architecture

XXX: start here
fill in down to Doc roadmap

** Oracle Database Documentation Roadmap


XXX: probably delete this section

Intro to Schema Objects

    A database user has a password and various database privileges. Each user owns a
    single schema, which has the same name as the user. The schema contains the data for
    the user owning the schema. For example, the hr user owns the hr schema, which
    contains schema objects such as the employees table. In a production database, the
    schema owner usually represents a database application rather than a person.


Partitions 
    Partitions are pieces of large tables and indexes. Each partition has its own name and
    may optionally have its own storage characteristics.

Sequences 
    A sequence is a user-created object that can be shared by multiple users to generate
    integers. Typically, sequences are used to generate primary key values.

Dimensions
    A dimension defines a parent-child relationship between pairs of column sets, where
    all the columns of a column set must come from the same table. Dimensions are commonly
    used to categorize data such as customers, products, and time.

Synonyms
    A synonym is an alias for another schema object. Because a synonym is simply an alias,
    it requires no storage other than its definition in the data dictionary.

PL/SQL subprograms and packages
    PL/SQL is the Oracle procedural extension of SQL. A PL/SQL subprogram is a named
    PL/SQL block that can be invoked with a set of parameters. A PL/SQL package groups
    logically related PL/SQL types, variables, and subprograms.


  Other types of objects are also stored in the database and can be created and
  manipulated with SQL statements but are not contained in a schema. These objects include
  database users, roles, contexts, and directory objects.


Schema Object Storage

  Oracle Database stores a schema object logically within a tablespace. There is no
  relationship between schemas and tablespaces: a tablespace can contain objects from
  different schemas, and the objects for a schema can be contained in different
  tablespaces. The data of each object is physically contained in one or more data files.

  DataFile: a physical structure associated with only 1 tablespace

  Segment: stored in tablespaces; may span data files


Schema Object Dependencies

  created when a schema object refers to another; e.g.: a view on the tables in its sql query,
  p PL/SQL program may refer to another PL/SQL program

  Oracle provides an automated tracking of these dependencies.
  Dependencies are rebuilt on the fly as needed.


* Part I: Oracle Relational Data Structures

* Chapter 2 Tables and Table Clusters

** Introduction to Schema Objects

A database user has a password and various database privileges. Each user owns a single
schema, which has the same name as the user. The schema contains the data for the user
owning the schema.

*** Schema Object Types

The most important schema objects in a relational database are tables. A table stores data
in rows.

Oracle SQL enables you to create and manipulate many other types of schema objects,
including the following:

  - Indexes

    Indexes are schema objects that contains an entry for each indexed row of the table or
    table cluster and provide direct, fast access to rows. Oracle Database supports
    several types of index. An index-organized table is a table in which the data is
    stored in an index structure. See Chapter 3, "Indexes and Index-Organized Tables".

  - Partitions

    Partitions are pieces of large tables and indexes. Each partition has its own name and
    may optionally have its own storage characteristics. See "Overview of Partitions" on
    page 4-1.

  - Views

    Views are customized presentations of data in one or more tables or other views. You
    can think of them as stored queries. Views do not actually contain data. See "Overview
    of Views" on page 4-12.

  - Sequences

    A sequence is a user-created object that can be shared by multiple users to generate
    integers. Typically, sequences are used to generate primary key values. See "Overview
    of Sequences" on page 4-20.

  - Dimensions

    A dimension defines a parent-child relationship between pairs of column sets, where
    all the columns of a column set must come from the same table. Dimensions are commonly
    used to categorize data such as customers, products, and time. See "Overview of
    Dimensions" on page 2-22.

  - Synonyms

    A synonym is an alias for another schema object. Because a synonym is simply an alias,
    it requires no storage other than its definition in the data dictionary. See "Overview
    of Synonyms" on page 4-22.

  - PL/SQL subprograms and packages

    PL/SQL is the Oracle procedural extension of SQL. A PL/SQL subprogram is a named
    PL/SQL block that can be invoked with a set of parameters. A PL/SQL package groups
    logically related PL/SQL types, variables, and subprograms. See "PL/SQL Subprograms"
    on page 8-3 and "PL/SQL Packages" on page 8-6.

Other types of objects are also stored in the database and can be created and manipulated
with SQL statements but are not contained in a schema. These objects include database
users, roles, contexts, and directory objects.

See Also:

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn how to
    manage schema objects

  - Oracle Database SQL Language Reference for more about schema objects and database
    objects

*** Schema Object Storage

Some schema objects store data in logical storage structures called segments. For example,
a nonpartitioned heap-organized table or an index creates a segment. Other schema objects,
such as views and sequences, consist of metadata only. This section describes only schema
objects that have segments.

Oracle Database stores a schema object logically within a tablespace. There is no
relationship between schemas and tablespaces: a tablespace can contain objects from
different schemas, and the objects for a schema can be contained in different
tablespaces. The data of each object is physically contained in one or more data files.

A segment cannot span multiple tablespaces.

See Also:

  - Chapter 12, "Logical Storage Structures" to learn about tablespaces and segments

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn how to
    manage storage for schema objects

*** Schema Object Dependencies

Some schema objects reference other objects, creating schema object dependencies. For
example, a view contains a query that references tables or other views, while a PL/SQL
subprogram invokes other subprograms. If the definition of object A references object B,
then A is a dependent object with respect to B and B is a referenced object with respect
to A.

Oracle Database provides an automatic mechanism to ensure that a dependent object is
always up to date with respect to its referenced objects. When a dependent object is
created, the database tracks dependencies between the dependent object and its referenced
objects. When a referenced object changes in a way that might affect a dependent object,
the dependent object is marked invalid. For example, if a user drops a table, no view
based on the dropped table is usable.

An invalid dependent object must be recompiled against the new definition of a referenced
object before the dependent object is usable. Recompilation occurs automatically when the
invalid dependent object is referenced.

See Also:

  - Oracle Database Administrator's Guide and Oracle Database Advanced Application
    Developer's Guide to learn how to manage schema object dependencies

*** SYS and SYSTEM schemas

The administrative account SYS is automatically created when a database is created. This
account can perform all database administrative functions. The SYS schema stores the base
tables and views for the data dictionary. These base tables and views are critical for the
operation of Oracle Database. Tables in the SYS schema are manipulated only by the
database and must never be modified by any user.

The SYSTEM account is also automatically created when a database is created. The SYSTEM
schema stores additional tables and views that display administrative information, and
internal tables and views used by various Oracle Database options and tools. Never use the
SYSTEM schema to store tables of interest to nonadministrative users.

See Also:

  - "User Accounts" on page 17-1 and "Connection with Administrator Privileges" on page
    13-6

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn about
    SYS, SYSTEM, and other administrative accounts

*** Sample Schemas

An Oracle database may include sample schemas, which are a set of interlinked schemas that
enable Oracle documentation and Oracle instructional materials to illustrate common
database tasks. The hr schema is a sample schema that contains information about
employees, departments and locations, work histories, and so on.

The hr sample database contains these tables:

  - employees
  - departments
  - jobs
  - job_history
  - locations
  - countries
  - regions

** Overview of Tables

  - Relational Tables: the common type

  - Object Tables: The columns correspond to the top-level attributes of an object type.

Relational Tables

  - A heap-organized table does not store rows in any particular order. The CREATE TABLE
    statement creates a heap-organized table by default.
  
  - An index-organized table orders rows according to the primary key values.

  - An external table is a read-only table whose metadata is stored in the database but
    whose data in stored outside the database.

A table is either permanent or temporary.  A temporary table exists only for the duration
of the transaction, or the session.  Temporary tables are useful in applications where a
result set must be held temporarily, perhaps because the result is constructed by running
multiple operations.

*** Columns and Rows

A table may contain a virtual column, which is a function of other columns.  Virtual
columns do not require storage.

*** Oracle Data Types

The most commonly used data types fall into the following categories:
  - Character Data Types
  - Numeric Data Types
  - Datetime Data Types
  - Rowid Data Types
  - Format Models and Data Types

Other important categories of built-in types include raw, large objects (LOBs), and
collections. PL/SQL has data types for constants and variables, which include BOOLEAN,
reference types, composite types (records), and user-defined types.

**** Character Data Types

The most commonly used character data type is VARCHAR2, which is the most efficient option
for storing character data.  The byte values correspond to the character encoding scheme,
generally called a character set or code page. The database character set is established
at database creation. Examples of character sets are 7-bit ASCII, EBCDIC, and Unicode
UTF-8.  The length semantics of character data types can be measured in bytes or
characters. Byte semantics treat strings as a sequence of bytes. This is the default for
character data types. Character semantics treat strings as a sequence of characters. A
character is technically a code point of the database character set.

For each row, Oracle Database stores each value in the column as a variable-length field
unless a value exceeds the maximum length, in which case the database returns an error.

***** NCHAR and NVARCHAR2 DataTypes

The NCHAR and NVARCHAR2 datatypes store Unicode character data. Unicode is a universal
encoded character set that can store information in any language using a single character
set. NCHAR stores fixed-length character strings that correspond to the national character
set, whereas NVARCHAR2 stores variable length character strings.

You specify a national character set when creating a database. The character set of NCHAR
and NVARCHAR2 data types must be either AL16UTF16 or UTF8. Both character sets use Unicode
encoding.  When you create a table with an NCHAR or NVARCHAR2 column, the maximum size is
always in character length semantics. Character length semantics is the default and only
length semantics for NCHAR or NVARCHAR2.

**** Numeric Data Types

Oracle Database stores numeric data in variable-length format. Each value is stored in
scientific notation, with 1 byte used to store the exponent. The database uses up to 20
bytes to store the mantissa, which is the part of a floating-point number that contains
its significant digits. Oracle Database does not store leading and trailing zeros.

***** NUMBER Data Type

The NUMBER data type stores fixed and floating-point numbers. The database can store
numbers of virtually any magnitude. This data is guaranteed to be portable among different
operating systems running Oracle Database. The NUMBER data type is recommended for most
cases in which you must store numeric data.

You specify a fixed-point number in the form NUMBER(p,s), where p and s refer to the
following characteristics:

  - Precision

    The precision specifies the total number of digits. If a precision is not specified,
    then the column stores the values exactly as provided by the application without any
    rounding.

  - Scale

    The scale specifies the number of digits from the decimal point to the least
    significant digit. Positive scale counts digits to the right of the decimal point up
    to and including the least significant digit. Negative scale counts digits to the left
    of the decimal point up to but not including the least significant digit. If you
    specify a precision without a scale, as in NUMBER(6), then the scale is 0.

    In Example 2-1, the salary column is type NUMBER(8,2), so the precision is 8 and the
    scale is 2. Thus, the database stores a salary of 100,000 as 100000.00.

***** Floating-Point Numbers 

Oracle Database provides two numeric data types exclusively for floating-point numbers:
BINARY_FLOAT and BINARY_DOUBLE. These types support all of the basic functionality
provided by the NUMBER data type. However, while NUMBER uses decimal precision,
BINARY_FLOAT and BINARY_DOUBLE use binary precision, which enables faster arithmetic
calculations and usually reduces storage requirements.

BINARY_FLOAT and BINARY_DOUBLE are approximate numeric data types. They store approximate
representations of decimal values, rather than exact representations. For example, the
value 0.1 cannot be exactly represented by either BINARY_DOUBLE or BINARY_FLOAT. They are
frequently used for scientific computations. Their behavior is similar to the data types
FLOAT and DOUBLE in Java and XMLSchema.

**** Datetime Data Types

DATE and TIMESTAMP.  Oracle Database provides comprehensive time zone support for time
stamps.

***** DATE Data Type

The DATE data type stores date and time.  Although datetimes can be represented in
character or number data types, DATE has special associated properties. DATE supports
arithmetic.

The database stores dates internally as numbers. Dates are stored in fixed-length fields
of 7 bytes each, corresponding to century, year, month, day, hour, minute, and second.

The database displays dates according to the specified format model. A format model is a
character literal that describes the format of a datetime in a character string. The
standard date format is DD-MON-RR, which displays dates in the form 01-JAN-09.

Oracle Database stores time in 24-hour formatâ€”HH:MI:SS. If no time portion is entered,
then by default the time in a date field is 00:00:00 A.M. In a time-only entry, the date
portion defaults to the first day of the current month.

See Also:

  - Oracle Database Advanced Application Developer's Guide for more information about
    centuries and date format masks

  - Oracle Database SQL Language Reference for information about datetime format codes

***** TIMESTAMP data type

The TIMESTAMP data type is an extension of the DATE data type. It stores fractional
seconds in addition to the information stored in the DATE data type. The TIMESTAMP data
type is useful for storing precise time values, such as in applications that must track
event order.

The DATETIME data types TIMESTAMP WITH TIME ZONE and TIMESTAMP WITH LOCAL TIME ZONE are
time-zone aware. When a user selects the data, the value is adjusted to the time zone of
the user session. This data type is useful for collecting and evaluating date information
across geographic regions.

See Also:

  - Oracle Database SQL Language Reference for details about the syntax of creating and
    entering data in time stamp columns

**** Rowid Data Types

Every row stored in the database has an address. Oracle Database uses a ROWID data type to
store the address (rowid) of every row in the database. Rowids fall into the following
categories:

  - Physical rowids store the addresses of rows in heap-organized tables, table clusters,
    and table and index partitions.

  - Logical rowids store the addresses of rows in index-organized tables.

  - Foreign rowids are identifiers in foreign tables, such as DB2 tables accessed through
    a gateway. They are not standard Oracle Database rowids.

A data type called the universal rowid, or UROWID, supports all kinds of rowids.

***** Use of rowids

Oracle Database uses rowids internally for the construction of indexes. A B-tree index,
which is the most common type, contains an ordered list of keys divided into ranges. Each
key is associated with a rowid that points to the associated row's address for fast
access. End users and application developers can also use rowids for several important
functions:
    
  - Rowids are the fastest means of accessing particular rows.

  - Rowids provide the ability to see how a table is organized.

  - Rowids are unique identifiers for rows in a given table.

You can also create tables with columns defined using the ROWID data type.  For example,
you can define an exception table with a column of data type ROWID to store the rowids of
rows that violate integrity constraints. Columns defined using the ROWID data type behave
like other table columns: values can be updated, and so on.

***** ROWID Pseudocolumn

Every table in an Oracle database has a pseudocolumn named ROWID. A pseudocolumn behaves
like a table column, but is not actually stored in the table. You can select from
pseudocolumns, but you cannot insert, update, or delete their values. A pseudocolumn is
also similar to a SQL function without arguments. Functions without arguments typically
return the same value for every row in the result set, whereas pseudocolumns typically
return a different value for each row.

Values of the ROWID pseudocolumn are strings representing the address of each row. These
strings have the data type ROWID. This pseudocolumn is not evident when listing the
structure of a table by executing SELECT or DESCRIBE, nor does the pseudocolumn consume
space. However, the rowid of each row can be retrieved with a SQL query using the reserved
word ROWID as a column name.

  SQL> SELECT ROWID FROM employees WHERE employee_id = 100;

  ROWID
  ------------------
  AAAPecAAFAAAABSAAA

See Also:

  - "Rowid Format" on page 12-10 

  - Oracle Database Advanced Application Developer's Guide to learn how to identify rows
    by address

  - Oracle Database SQL Language Reference to learn about rowid types

**** Format Models and Data Types

A format model is a character literal that describes the format of datetime or numeric
data stored in a character string. A format model does not change the internal
representation of the value in the database.

When you convert a character string into a date or number, a format model determines how
the database interprets the string. In SQL, you can use a format model as an argument of
the TO_CHAR and TO_DATE functions to format a value to be returned from the database or to
format a value to be stored in the database.

See Also:

  - Oracle Database SQL Language Reference to learn more about format models

*** Integrity Constraints

Integrity constraints are named rules that restrict the values for one or more columns in
a table. These rules prevent invalid data entry into tables. Also, constraints can prevent
the deletion of a table when certain dependencies exist.

If a constraint is enabled, then the database checks data as it is entered or
updated. Data that does not conform to the constraint is prevented from being entered. If
a constraint is disabled, then data that does not conform to the constraint can be allowed
to enter the database.

You can create a constraint when or after you create a table. Constraints can be
temporarily disabled if needed. The database stores constraints in the data dictionary.

See Also:

  - Chapter 5, "Data Integrity" to learn about integrity constraints

  - Oracle Database SQL Language Reference to learn about SQL constraint clauses

*** Object Tables

An Oracle object type is a user-defined type with a name, attributes, and methods. Object
types make it possible to model real-world entities such as customers and purchase orders
as objects in the database.

An object type defines a logical structure, but does not create storage.

  CREATE TYPE department_typ AS OBJECT
     ( d_name     VARCHAR2(100),
       d_address  VARCHAR2(200) );
  /

An object table is a special kind of table in which each row represents an object.

Like a relational column, an object table can contain rows of just one kind of thing,
namely, object instances of the same declared type as the table. By default, every row
object in an object table has an associated logical object identifier (OID) that uniquely
identifies it in an object table. The OID column of an object table is a hidden column.

See Also:

  - Oracle Database Object-Relational Developer's Guide to learn about object-relational
    features in Oracle Database

  - Oracle Database SQL Language Reference for CREATE TYPE syntax and semantics

*** Temporary Tables

Oracle Database temporary tables hold data that exists only for the duration of a
transaction or session. Data in a temporary table is private to the session, which means
that each session can only see and modify its own data.

Temporary tables are useful in applications where a result set must be buffered.

**** Temporary Table Creation

The CREATE GLOBAL TEMPORARY TABLE statement creates a temporary table. The ON COMMIT
clause specifies whether the table data is transaction-specific (default) or
session-specific.

Unlike temporary tables in some other relational databases, when you create a temporary
table in an Oracle database, you create a static table definition. The temporary table is
a persistent object described in the data dictionary, but appears empty until your session
inserts data into the table. You create a temporary table for the database itself, not for
every PL/SQL stored procedure.

Because temporary tables are statically defined, you can create indexes for them with the
CREATE INDEX statement. Indexes created on temporary tables are also temporary. The data
in the index has the same session or transaction scope as the data in the temporary
table. You can also create a view or trigger on a temporary table.

See Also:

  - Oracle Database Administrator's Guide to learn how create and manage temporary tables

  - Oracle Database SQL Language Reference for CREATE GLOBAL TEMPORARY TABLE syntax and
    semantics

  - "Overview of Views" on page 4-12 and "Overview of Triggers" on page 8-16

**** Segment Allocation in Temporary Tables

Like permanent tables, temporary tables are defined in the data dictionary. Temporary
segments are allocated when data is first inserted. Until data is loaded in a session the
table appears empty. Temporary segments are deallocated at the end of the transaction for
transaction-specific temporary tables and at the end of the session for session-specific
temporary tables.

See Also:

  - "Temporary Segments" on page 12-23


*** External Tables

An external table accesses data in external sources as if this data were in a table in the
External Tables database. You can use SQL, PL/SQL, and Java to query the external data.

External tables are useful for querying flat files.

You could create an external table, copy the file to the location specified in the
external table definition, and use SQL to query the records in the text file.

**** External Table Creation

Internally, creating an external table means creating metadata in the data
dictionary. Unlike an ordinary table, an external table does not describe data stored in
the database, nor does it describe how data is stored externally. Rather, external table
metadata describes how the external table layer must present data to the database.

A CREATE TABLE ... ORGANIZATION EXTERNAL statement has two parts. The external table
definition describes the column types. This definition is like a view that enables SQL to
query external data without loading it into the database. The second part of the statement
maps the external data to the columns.

External tables are read-only unless created with CREATE TABLE AS SELECT with the
ORACLE_DATAPUMP access driver. Restrictions for external tables include no support for
indexed columns, virtual columns, and column objects.

**** External Table Access Drivers

Oracle provides the ORACLE_LOADER (default) and ORACLE_DATAPUMP access drivers for
external tables. For both drivers, the external files are not Oracle data files.

ORACLE_LOADER enables read-only access to external files using SQL*Loader. You cannot
create, update, or append to an external file using the ORACLE_LOADER driver.

The ORACLE_DATAPUMP driver enables you to unload external data. This operation involves
reading data from the database and inserting the data into an external table, represented
by one or more external files. After external files are created, the database cannot
update or append data to them. The driver also enables you to load external data, which
involves reading an external table and loading its data into a database.

See Also:

  - Oracle Database Administrator's Guide to learn about managing external tables,
    external connections, and directory objects

  - Oracle Database Utilities to learn about external tables

  - Oracle Database SQL Language Reference for information about creating and querying
    external tables

*** Table Storage

Oracle Database uses a data segment in a tablespace to hold table data. As explained in
"User Segments" on page 12-21, a segment contains extents made up of data blocks.

The data segment for a table (or cluster data segment, when dealing with a table cluster)
is located in either the default tablespace of the table owner or in a tablespace named in
the CREATE TABLE statement.

**** Table Organization

By default, a table is organized as a heap, which means that the database places rows
where they fit best rather than in a user-specified order. Thus, a heap-organized table is
an unordered collection of rows. As users add rows, the database places the rows in the
first available free space in the data segment. Rows are not guaranteed to be retrieved in
the order in which they were inserted.

A table can contain a virtual column, which unlike normal columns does not consume space
on disk. The database derives the values in a virtual column on demand by computing a set
of user-specified expressions or functions. You can index virtual columns, collect
statistics on them, and create integrity constraints. Thus, virtual columns are much like
nonvirtual columns.

**** Row Storage

The database stores rows in data blocks. Each row of a table containing data for less than
256 columns is contained in one or more row pieces.

If possible, Oracle Database stores each row as one row piece. However, if all of the row
data cannot be inserted into a single data block, or if an update to an existing row
causes the row to outgrow its data block, then the database stores the row using multiple
row pieces (see "Data Block Format" on page 12-7).

Rows in a table cluster contain the same information as rows in nonclustered
tables. Additionally, rows in a table cluster contain information that references the
cluster key to which they belong.

**** Rowids of Row Pieces

A rowid is effectively a 10-byte physical address of a row. As explained in "Rowid Data
Types" on page 2-13, every row in a heap-organized table has a rowid unique to this table
that corresponds to the physical address of a row piece. For table clusters, rows in
different tables that are in the same data block can have the same rowid.

Oracle Database uses rowids internally for the construction of indexes. For example, each
key in a B-tree index is associated with a rowid that points to the address of the
associated row for fast access (see "B-Tree Indexes" on page 3-5). Physical rowids provide
the fastest possible access to a table row, enabling the database to retrieve a row in as
little as a single I/O.

**** Storage of NULL values

A null is the absence of a value in a column. Nulls indicate missing, unknown, or
inapplicable data.

Nulls are stored in the database if they fall between columns with data values. In these
cases, they require 1 byte to store the length of the column (zero). Trailing nulls in a
row require no storage because a new row header signals that the remaining columns in the
previous row are null. For example, if the last three columns of a table are null, then no
data is stored for these columns.


*** Table Compression

**** Basic and OLTP Table Compression

Dictionary-based table compression provides good compression ratios for heap-organized
tables. Oracle Database supports the following types of dictionary-based table
compression:

  - Basic table compression

    This type of compression is intended for bulk load operations. The database does not
    compress data modified using conventional DML. You must use direct path loads, ALTER
    TABLE . . . MOVE operations, or online table redefinition to achieve basic
    compression.

  - OLTP table compression

    This type of compression is intended for OLTP applications and compresses data
    manipulated by any SQL operation.

For basic and OLTP table compression, the database stores compressed rows in row-major
format. All columns of one row are stored together, followed by all columns of the next
row, and so on (see Figure 12-7 on page 12-9). Duplicate values are replaced with a short
reference to a symbol table stored at the beginning of the block. Thus, information needed
to re-create the uncompressed data is stored in the data block itself.

Compressed data blocks look much like normal data blocks. Most database features and
functions that work on regular data blocks also work on compressed blocks.

You can declare compression at the tablespace, table, partition, or subpartition level. If
specified at the tablespace level, then all tables created in the tablespace are
compressed by default.

See Also:

  - "Data Block Compression" on page 12-11 to learn about the format of compressed data
    blocks

  - Oracle Database Administrator's Guide and Oracle Database Performance Tuning Guide to
    learn about table compression

  - "SQL*Loader" on page 18-5 to learn about using SQL*Loader for direct path loads

**** Hybrid Columnar Compression

With Hybrid Columnar Compression, the database stores the same column for a group of rows
together. The data block does not store data in row-major format, but uses a combination
of both row and columnar methods.

Storing column data together, with the same data type and similar characteristics,
dramatically increases the storage savings achieved from compression. The database
compresses data manipulated by any SQL operation, although compression levels are higher
for direct path loads. Database operations work transparently against compressed objects,
so no application changes are required.

***** Types of Hybrid Columnar Compression

If your underlying storage supports Hybrid Columnar Compression, then you can specify the
following compression types, depending on your requirements:

  - Warehouse compression

    This type of compression is optimized to save storage space, and is intended for data
    warehouse applications.

  - Online archival compression

    This type of compression is optimized for maximum compression levels, and is intended
    for historical data and data that does not change.

To achieve warehouse or online archival compression, you must use direct path loads, ALTER
TABLE . . . MOVE operations, or online table redefinition.

Hybrid Columnar Compression is optimized for Data Warehousing and decision support
applications on Exadata storage. Exadata maximizes the performance of queries on tables
that are compressed using Hybrid Columnar Compression, taking advantage of the processing
power, memory, and Infiniband network bandwidth that are integral to the Exadata storage
server.

Other Oracle storage systems support Hybrid Columnar Compression, and deliver the same
space savings as on Exadata storage, but do not deliver the same level of query
performance. For these storage systems, Hybrid Columnar Compression is ideal for
in-database archiving of older data that is infrequently accessed.

***** Compression Units

Hybrid Columnar Compression uses a logical construct called a compression unit to store a
set of rows. When you load data into a table, the database stores groups of rows in
columnar format, with the values for each column stored and compressed together. After the
database has compressed the column data for a set of rows, the database fits the data into
the compression unit.

Hybrid Columnar Compression has implications for row locking (see "Row Locks (TX)" on page
9-18). When an update occurs for a row in an uncompressed data block, only the updated row
is locked. In contrast, the database must lock all rows in the compression unit if an
update is made to any row in the unit. Updates to rows using Hybrid Columnar Compression
cause rowids to change.

  NB: When tables use Hybrid Columnar Compression, Oracle DML locks larger blocks of data
      (compression units), which may reduce concurrency.

See Also:

  - Oracle Database Licensing Information to learn about licensing requirements for Hybrid
    Columnar Compression

  - Oracle Database Administrator's Guide to learn how to use Hybrid Columnar Compression

** Overview of Table Clusters

A table cluster is a group of tables that share common columns and store related data in
the same blocks. When tables are clustered, a single data block can contain rows from
multiple tables. For example, a block can store rows from both the employees and
departments tables rather than from only a single table.

The cluster key is the column or columns that the clustered tables have in common. For
example, the employees and departments tables share the department_id column. You specify
the cluster key when creating the table cluster and when creating every table added to the
table cluster.

The cluster key value is the value of the cluster key columns for a particular set of
rows. All data that contains the same cluster key value, such as department_id=20, is
physically stored together. Each cluster key value is stored only once in the cluster and
the cluster index, no matter how many rows of different tables contain the value.

For an analogy, suppose an HR manager has two book cases: one with boxes of employees
folders and the other with boxes of departments folders. Users often ask for the folders
for all employees in a particular department. To make retrieval easier, the manager
rearranges all the boxes in a single book case. She divides the boxes by department
ID. Thus, all folders for employees in department 20 and the folder for department 20
itself are in one box; the folders for employees in department 100 and the folder for
department 100 are in a different box, and so on.

You can consider clustering tables when they are primarily queried (but not modified) and
records from the tables are frequently queried together or joined. Because table clusters
store related rows of different tables in the same data blocks, properly used table
clusters offer the following benefits over nonclustered tables:

  - Disk I/O is reduced for joins of clustered tables.

  - Access time improves for joins of clustered tables.

  - Less storage is required to store related table and index data because the cluster key
    value is not stored repeatedly for each row.

Typically, clustering tables is not appropriate in the following situations:

  - The tables are frequently updated.

  - The tables frequently require a full table scan.

  - The tables require truncating.

See Also:

  - Oracle Database Performance Tuning Guide for guidelines on when to use table clusters

*** Overview of Indexed Clusters

An indexed cluster is a table cluster that uses an index to locate data. The cluster index
is a B-tree index on the cluster key. A cluster index must be created before any rows can
be inserted into clustered tables.

*** Overview of Hashed Clusters

A hash cluster is like an indexed cluster, except the index key is replaced with a hash
function. No separate cluster index exists. In a hash cluster, the data is the index.

With an indexed table or indexed cluster, Oracle Database locates table rows using key
values stored in a separate index. To find or store a row in an indexed table or table
cluster, the database must perform at least two I/Os:

  - One or more I/Os to find or store the key value in the index

  - Another I/O to read or write the row in the table or table cluster

To find or store a row in a hash cluster, Oracle Database applies the hash function to the
cluster key value of the row. The resulting hash value corresponds to a data block in the
cluster, which the database reads or writes on behalf of the issued statement.

Hashing is an optional way of storing table data to improve the performance of data
retrieval. Hash clusters may be beneficial when the following conditions are met:

  - A table is queried much more often than modified.

  - The hash key column is queried frequently with equality conditions, for example, WHERE
    department_id=20. For such queries, the cluster key value is hashed. The hash key
    value points directly to the disk area that stores the rows.

  - You can reasonably guess the number of hash keys and the size of the data stored with
    each key value.

**** Hash Cluster Creation

The cluster key, like the key of an indexed cluster, is a single column or composite key
shared by the tables in the cluster. The hash key values are actual or possible values
inserted into the cluster key column. For example, if the cluster key is department_id,
then hash key values could be 10, 20, 30, and so on.

Oracle Database uses a hash function that accepts an infinite number of hash key values as
input and sorts them into a finite number of buckets. Each bucket has a unique numeric ID
known as a hash value. Each hash value maps to the database block address for the block
that stores the rows corresponding to the hash key value (department 10, 20, 30, and so
on).

To create a hash cluster, you use the same CREATE CLUSTER statement as for an indexed
cluster, with the addition of a hash key. The number of hash values for the cluster
depends on the hash key. In Example 2-9, the number of departments that are likely to
exist is 100, so HASHKEYS is set to 100.

  CREATE CLUSTER employees_departments_cluster
     (department_id NUMBER(4))
  SIZE 8192 HASHKEYS 100;

After you create employees_departments_cluster, you can create the employees and
departments tables in the cluster. You can then load data into the hash cluster just as in
the indexed cluster described in Example 2-8.

See Also:

  - Oracle Database Administrator's Guide to learn how to create and manage hash clusters

**** Hash Cluster Queries

The database, not the user, determines how to hash the key values input by the user.

A limitation of hash clusters is the unavailability of range scans on nonindexed cluster
keys (see "Index Range Scan" on page 3-7). Assume that no separate index exists for the
hash cluster created in Example 2-9. A query for departments with IDs between 20 and 100
cannot use the hashing algorithm because it cannot hash every possible value between 20
and 100. Because no index exists, the database must perform a full scan.

**** Hash Cluster Variations

A single-table hash cluster is an optimized version of a hash cluster that supports only
one table at a time. A one-to-one mapping exists between hash keys and rows. A
single-table hash cluster can be beneficial when users require rapid access to a table by
primary key. For example, users often look up an employee record in the employees table by
employee_id.

A sorted hash cluster stores the rows corresponding to each value of the hash function in
such a way that the database can efficiently return them in sorted order. The database
performs the optimized sort internally. For applications that always consume data in
sorted order, this technique can mean faster retrieval of data. For example, an
application might always sort on the order_date column of the orders table.

See Also:

  - Oracle Database Administrator's Guide to learn how to create single-table and sorted
    hash clusters

**** Hash Cluster Storage

For cluster storage, one declares the number of keys, which should be a reasonable guess
as to the maximum number of keys this table will store, and the size of each row, like
this:

  CREATE CLUSTER employees_departments_cluster
      (department_id NUMBER(4))
  SIZE 8192 HASHKEYS 100;

Here we declare each row to take 8k, and a projected maximum of 100 keys.

Just as in a standard hash function, chaining is done when there is a hash collision.


* Chapter 3 Indexes and Index-Organized Tables

** Overview of Indexes

In general consider creating an index on a column in any of these situations:

  - The indexed columns are queried frequently and return a small percentage of the total
    number of rows in the table.

  - A referential integrity constraint exists on the indexed column or columns. The index
    is a means to avoid a full table lock that would otherwise be required if you update
    the parent table primary key, merge into the parent table, or delete from the parent
    table.

  - A unique key constraint will be placed on the table and you want to manually specify
    the index and all index options.

See Also:

  - Chapter 5: Data Integrity

*** Index Characteristics

Indexes have the following properties:

  - Usability

    Indexes are usable (default) or unusable. An unusable index is not maintained by DML
    operations and is ignored by the optimizer. An unusable index can improve the
    performance of bulk loads. Instead of dropping an index and later re-creating it, you
    can make the index unusable and then rebuild it. Unusable indexes and index partitions
    do not consume space. When you make a usable index unusable, the database drops its
    index segment.

  - Visibility

    Indexes are visible (default) or invisible. An invisible index is maintained by DML
    operations and is not used by default by the optimizer. Making an index invisible is
    an alternative to making it unusable or dropping it. Invisible indexes are especially
    useful for testing the removal of an index before dropping it or using indexes
    temporarily without affecting the overall application.

See Also:

  - "Overview of the Optimizer" on page 7-10

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn how to
    manage indexes

  - Oracle Database Performance Tuning Guide to learn how to tune indexes

**** Keys and Columns

A key is a set of columns or expressions on which you can build an index. Although the
terms are often used interchangeably, indexes and keys are different. Indexes are
structures stored in the database that users manage using SQL statements. Keys are
strictly a logical concept.

  NB: Primary and unique keys automatically have indexes, but you might want to create
      an index on a foreign key.

See Also:

  - Oracle Database SQL Language Reference CREATE INDEX syntax and semantics

**** Composite Indexes

A composite index, also called a concatenated index, is an index on multiple columns in a
table. Columns in a composite index should appear in the order that makes the most sense
for the queries that will retrieve data and need not be adjacent in the table.

Composite indexes can speed retrieval of data for SELECT statements in which the WHERE
clause references all or the leading portion of the columns in the composite
index. Therefore, the order of the columns used in the definition is important. In
general, the most commonly accessed columns go first.

For example, suppose an application frequently queries the last_name, job_id, and salary
columns in the employees table. Also assume that last_name has high cardinality, which
means that the number of distinct values is large compared to the number of table
rows. You create an index with the following column order:

  CREATE INDEX employees_ix ON employees (last_name, job_id, salary);

Queries that access all three columns, only the last_name column, or only the last_ name
and job_id columns use this index. In this example, queries that do not access the
last_name column do not use the index.

  NB: In some cases, such as when the leading column has very low cardinality, the
      database may use a skip scan of this index (see "Index Skip Scan" on page 3-8).

Multiple indexes can exist for the same table if the permutation of columns differs for
each index. You can create multiple indexes using the same columns if you specify
distinctly different permutations of the columns. For example, the following SQL
statements specify valid permutations:

  CREATE INDEX employee_idx1 ON employees (last_name, job_id);
  CREATE INDEX employee_idx2 ON employees (job_id, last_name);


See Also:

  - Oracle Database Performance Tuning Guide for more information about using composite
    indexes

**** Unique and Nonunique Indexes

Indexes can be unique or nonunique. Unique indexes guarantee that no two rows of a table
have duplicate values in the key column or columns. For example, no two employees can have
the same employee ID. Thus, in a unique index, one rowid exists for each data value. The
data in the leaf blocks is sorted only by key.

Nonunique indexes permit duplicates values in the indexed column or columns. For example,
the first_name column of the employees table may contain multiple Mike values. For a
nonunique index, the rowid is included in the key in sorted order, so nonunique indexes
are sorted by the index key and rowid (ascending).

Oracle Database does not index table rows in which all key columns are null, except for
bitmap indexes or when the cluster key column value is null.

**** Types of Indexes

Oracle Database provides several indexing schemes, which provide complementary performance
functionality. The indexes can be categorized as follows:

  - B-tree indexes

    These indexes are the standard index type. They are excellent for primary key and
    highly-selective indexes. Used as concatenated indexes, B-tree indexes can retrieve
    data sorted by the indexed columns. B-tree indexes have the following subtypes:

    - Index-organized tables

      An index-organized table differs from a heap-organized because the data is itself
      the index. See "Overview of Index-Organized Tables" on page 3-20.

    - Reverse key indexes

      In this type of index, the bytes of the index key are reversed, for example, 103 is
      stored as 301. The reversal of bytes spreads out inserts into the index over many
      blocks. See "Reverse Key Indexes" on page 3-11.

    - Descending indexes

      This type of index stores data on a particular column or columns in descending
      order. See "Ascending and Descending Indexes" on page 3-11.

    - B-tree cluster indexes

      This type of index is used to index a table cluster key. Instead of pointing to a
      row, the key points to the block that contains rows related to the cluster key. See
      "Overview of Indexed Clusters" on page 2-23.

  - Bitmap and bitmap join indexes

    In a bitmap index, an index entry uses a bitmap to point to multiple rows. In
    contrast, a B-tree index entry points to a single row. A bitmap join index is a bitmap
    index for the join of two or more tables. See "Bitmap Indexes" on page 3-13.

  - Function-based indexes

    This type of index includes columns that are either transformed by a function, such as
    the UPPER function, or included in an expression. B-tree or bitmap indexes can be
    function-based. See "Function-Based Indexes" on page 3-17.

  - Application domain indexes

    This type of index is created by a user for data in an application-specific
    domain. The physical index need not use a traditional index structure and can be
    stored either in the Oracle database as tables or externally as a file. See
    "Application Domain Indexes" on page 3-19.

See Also:

  - Oracle Database Performance Tuning Guide to learn about different index types

*** B-Tree Indexes

B-trees, short for balanced trees, are the most common type of database index. A B-tree
index is an ordered list of values divided into ranges. By associating a key with a row or
range of rows, B-trees provide excellent retrieval performance for a wide range of
queries, including exact match and range searches.

**** Branch Blocks and Leaf Blocks

A B-tree index has two types of blocks: branch blocks for searching and leaf blocks that
store values. The upper-level branch blocks of a B-tree index contain index data that
points to lower-level index blocks. In Figure 3-1, the root branch block has an entry
0-40, which points to the leftmost block in the next branch level. This branch block
contains entries such as 0-10 and 11-19. Each of these entries points to a leaf block that
contains key values that fall in the range.

A B-tree index is balanced because all leaf blocks automatically stay at the same
depth. Thus, retrieval of any record from anywhere in the index takes approximately the
same amount of time. The height of the index is the number of blocks required to go from
the root block to a leaf block. The branch level is the height minus 1. In Figure 3-1, the
index has a height of 3 and a branch level of 2.

Branch blocks store the minimum key prefix needed to make a branching decision between two
keys. This technique enables the database to fit as much data as possible on each branch
block. The branch blocks contain a pointer to the child block containing the key. The
number of keys and pointers is limited by the block size.

The leaf blocks contain every indexed data value and a corresponding rowid used to locate
the actual row. Each entry is sorted by (key, rowid). Within a leaf block, a key and rowid
is linked to its left and right sibling entries. The leaf blocks themselves are also
doubly linked. In Figure 3-1 the leftmost leaf block (0-10) is linked to the second leaf
block (11-19).

**** Index Scans

In an index scan, the database retrieves a row by traversing the index, using the indexed
column values specified by the statement. If the database scans the index for a value,
then it will find this value in n I/Os where n is the height of the B-tree index. This is
the basic principle behind Oracle Database indexes.

If a SQL statement accesses only indexed columns, then the database reads values directly
from the index rather than from the table. If the statement accesses columns in addition
to the indexed columns, then the database uses rowids to find the rows in the
table. Typically, the database retrieves table data by alternately reading an index block
and then a table block.

See Also:

  - Oracle Database Performance Tuning Guide for detailed information about index scans

***** Full Index Scan

In a full index scan, the database reads the entire index in order. A full index scan is
available if a predicate (WHERE clause) in the SQL statement references a column in the
index, and in some circumstances when no predicate is specified. A full scan can eliminate
sorting because the data is ordered by index key.

***** Fast Full Index Scan

A fast full index scan is a full index scan in which the database accesses the data in the
index itself without accessing the table, and the database reads the index blocks in no
particular order.

Fast full index scans are an alternative to a full table scan when both of the following
conditions are met:

  - The index must contain all columns needed for the query.

  - A row containing all nulls must not appear in the query result set. For this result to
    be guaranteed, at least one column in the index must have either:

    - A NOT NULL constraint

    - A predicate applied to it that prevents nulls from being considered in the query
      result set

***** Index Range Scan

An index range scan is an ordered scan of an index that has the following characteristics:

  - One or more leading columns of an index are specified in conditions. A condition
    specifies a combination of one or more expressions and logical (Boolean) operators and
    returns a value of TRUE, FALSE, or UNKNOWN.

  - 0, 1, or more values are possible for an index key.

The database commonly uses an index range scan to access selective data. The selectivity
is the percentage of rows in the table that the query selects, with 0 meaning no rows and
1 meaning all rows. Selectivity is tied to a query predicate, such as WHERE last_name LIKE
'A%', or a combination of predicates. A predicate becomes more selective as the value
approaches 0 and less selective (or more unselective) as the value approaches 1.

An index range scan can be bounded on both sides, as in a query for departments with IDs
between 10 and 40, or bounded on only one side, as in a query for IDs over 40. To scan the
index, the database moves backward or forward through the leaf blocks. For example, a scan
for IDs between 10 and 40 locates the first index leaf block that contains the lowest key
value that is 10 or greater. The scan then proceeds horizontally through the linked list
of leaf nodes until it locates a value greater than 40.

***** Index Unique Scan

In contrast to an index range scan, an index unique scan must have either 0 or 1 rowid
associated with an index key. The database performs a unique scan when a predicate
references all of the columns in a UNIQUE index key using an equality operator. An index
unique scan stops processing as soon as it finds the first record because no second record
is possible.

***** Index Skip Scan

An index skip scan uses logical subindexes of a composite index. The database "skips"
through a single index as if it were searching separate indexes. Skip scanning is
beneficial if there are few distinct values in the leading column of a composite index and
many distinct values in the nonleading key of the index.

The database may choose an index skip scan when the leading column of the composite index
is not specified in a query predicate.

***** Index Clustering Factor

The index clustering factor measures row order in relation to an indexed value such as
employee last name. The more order that exists in row storage for this value, the lower
the clustering factor.

The clustering factor is useful as a rough measure of the number of I/Os required to read
an entire table by means of an index:

  - If the clustering factor is high, then Oracle Database performs a relatively high
    number of I/Os during a large index range scan. The index entries point to random
    table blocks, so the database may have to read and reread the same blocks over and
    over again to retrieve the data pointed to by the index.

  - If the clustering factor is low, then Oracle Database performs a relatively low number
    of I/Os during a large index range scan. The index keys in a range tend to point to
    the same data block, so the database does not have to read and reread the same blocks
    over and over.

The clustering factor is relevant for index scans because it can show:

  - Whether the database will use an index for large range scans

  - The degree of table organization in relation to the index key

  - Whether you should consider using an index-organized table, partitioning, or table
    cluster if rows must be ordered by the index key

The index clustering factor can be read from the ALL_INDEXES table:

  SELECT INDEX_NAME, CLUSTERING_FACTOR
    FROM ALL_INDEXES
   WHERE INDEX_NAME IN ('EMP_NAME_IX','EMP_EMP_ID_PK');

  INDEX_NAME           CLUSTERING_FACTOR
  -------------------- -----------------
  EMP_EMP_ID_PK                       19
  EMP_NAME_IX                          2


See Also:

  - Oracle Database Reference to learn about ALL_INDEXES

**** Reverse Key Indexes

A reverse key index is a type of B-tree index that physically reverses the bytes of each
index key while keeping the column order. For example, if the index key is 20, and if the
two bytes stored for this key in hexadecimal are C1,15 in a standard B-tree index, then a
reverse key index stores the bytes as 15,C1.

Reversing the key solves the problem of contention for leaf blocks in the right side of a
B-tree index. This problem can be especially acute in an Oracle Real Application Clusters
(Oracle RAC) database in which multiple instances repeatedly modify the same block. For
example, in an orders table the primary keys for orders are sequential. One instance in
the cluster adds order 20, while another adds 21, with each instance writing its key to
the same leaf block on the right-hand side of the index.

In a reverse key index, the reversal of the byte order distributes inserts across all leaf
keys in the index. For example, keys such as 20 and 21 that would have been adjacent in a
standard key index are now stored far apart in separate blocks. Thus, I/O for insertions
of sequential keys is more evenly distributed.

Because the data in the index is not sorted by column key when it is stored, the reverse
key arrangement eliminates the ability to run an index range scanning query in some
cases. For example, if a user issues a query for order IDs greater than 20, then the
database cannot start with the block containing this ID and proceed horizontally through
the leaf blocks.

See Also:

  - Oracle Database Performance Tuning Guide to learn about design considerations for
    reverse key indexes

**** Ascending and Descending Indexes

In an ascending index, Oracle Database stores data in ascending order. By default,
character data is ordered by the binary values contained in each byte of the value,
numeric data from smallest to largest number, and date from earliest to latest value.

For an example of an ascending index, consider the following SQL statement:

  CREATE INDEX emp_deptid_ix ON hr.employees(department_id);

Oracle Database sorts the hr.employees table on the department_id column. It loads the
ascending index with the department_id and corresponding rowid values in ascending order,
starting with 0. When it uses the index, Oracle Database searches the sorted department_id
values and uses the associated rowids to locate rows having the requested department_id
value.

By specifying the DESC keyword in the CREATE INDEX statement, you can create a descending
index. In this case, the index stores data on a specified column or columns in descending
order. If the index in Figure 3-1 on the employees.department_id column were descending,
then the leaf blocking containing 250 would be on the left side of the tree and block with
0 on the right. The default search through a descending index is from highest to lowest
value.

Descending indexes are useful when a query sorts some columns ascending and others
descending. For an example, assume that you create a composite index on the last_ name and
department_id columns as follows:

  CREATE INDEX emp_name_dpt_ix ON hr.employees(last_name ASC, department_id DESC);

If a user queries hr.employees for last names in ascending order (A to Z) and department
IDs in descending order (high to low), then the database can use this index to retrieve
the data and avoid the extra step of sorting it.

See Also:

  - Oracle Database Performance Tuning Guide to learn more about ascending and descending
    index searches

  - Oracle Database SQL Language Reference for descriptions of the ASC and DESC options of
    CREATE INDEX

**** Key Compression

Oracle Database can use key compression to compress portions of the primary key column
values in a B-tree index or an index-organized table.

*** Bitmap Indexes

In a bitmap index, the database stores a bitmap for each index key. In a conventional
B-tree index, one index entry points to a single row. In a bitmap index, each index key
stores pointers to multiple rows.

Bitmap indexes are primarily designed for data warehousing or environments in which
queries reference many columns in an ad hoc fashion. Situations that may call for a bitmap
index include:

  - The indexed columns have low cardinality, that is, the number of distinct values is
    small compared to the number of table rows.

  - The indexed table is either read-only or not subject to significant modification by
    DML statements.

For a data warehouse example, the sh.customer table has a cust_gender column with only two
possible values: M and F. Suppose that queries for the number of customers of a particular
gender are common. In this case, the customer.cust_gender column would be a candidate for
a bitmap index.

Each bit in the bitmap corresponds to a possible rowid. If the bit is set, then the row
with the corresponding rowid contains the key value. A mapping function converts the bit
position to an actual rowid, so the bitmap index provides the same functionality as a
B-tree index although it uses a different internal representation.

If the indexed column in a single row is updated, then the database locks the index key
entry (for example, M or F) and not the individual bit mapped to the updated row. Because
a key points to many rows, DML on indexed data typically locks all of these rows. For this
reason, bitmap indexes are not appropriate for many OLTP applications.

See Also:

  - Oracle Database Performance Tuning Guide to learn how to use bitmap indexes for
    performance

  - Oracle Database Data Warehousing Guide to learn how to use bitmap indexes in a data
    warehouse

**** Bitmap Indexes on a Single Table

Bitmap indexing efficiently merges indexes that correspond to several conditions in a
WHERE clause. Rows that satisfy some, but not all, conditions are filtered out before the
table itself is accessed. This technique improves response time, often dramatically.

**** Bitmap Join Indexes

A bitmap join index is a bitmap index for the join of two or more tables. For each value
in a table column, the index stores the rowid of the corresponding row in the indexed
table. In contrast, a standard bitmap index is created on a single table.

A bitmap join index is an efficient means of reducing the volume of data that must be
joined by performing restrictions in advance.

**** Bitmap Storage Structure

Oracle Database uses a B-tree index structure to store bitmaps for each indexed key. For
example, if jobs.job_title is the key column of a bitmap index, then the index data is
stored in one B-tree. The individual bitmaps are stored in the leaf blocks.

*** Function-Based Indexes

You can create indexes on functions and expressions that involve one or more columns in
the table being indexed. A function-based index computes the value of a function or
expression involving one or more columns and stores it in the index. A function-based
index can be either a B-tree or a bitmap index.

The function used for building the index can be an arithmetic expression or an expression
that contains a SQL function, user-defined PL/SQL function, package function, or C
callout.

See Also

  - Oracle Database Administrator's Guide to learn how to create function-based indexes

  - Oracle Database Performance Tuning Guide for more information about using
    function-based indexes

  - Oracle Database SQL Language Reference for restrictions and usage notes for
    function-based indexes

**** Uses of Function-Based Indexes

Function-based indexes are efficient for evaluating statements that contain functions in
their WHERE clauses. The database only uses the function-based index when the function is
included in a query. When the database processes INSERT and UPDATE statements, however, it
must still evaluate the function to process the statement.

Function-based indexes defined on the SQL functions UPPER(column_name) or
LOWER(column_name) facilitate case-insensitive searches. For example, suppose that the
first_name column in employees contains mixed-case characters. You create the following
function-based index on the hr.employees table:

  CREATE INDEX emp_fname_uppercase_idx ON employees ( UPPER(first_name) );

The emp_fname_uppercase_idx index can facilitate queries such as the following:

  SELECT * FROM employees WHERE UPPER(first_name) = 'AUDREY';

A function-based index is also useful for indexing only specific rows in a table. For
example, the cust_valid column in the sh.customers table has either I or A as a value. To
i ndex only t he A rows, you could write a function that returns a null value for any rows
other than the A rows. You could create the index as follows:

  CREATE INDEX cust_valid_idx 
  ON customers ( CASE cust_valid WHEN 'A' THEN 'A' END );

See Also:

  - Oracle Database Globalization Support Guide for information about linguistic indexes

  - Oracle Database SQL Language Reference to learn more about SQL functions

**** Optimization with Function-Based Indexes

The optimizer can use an index range scan on a function-based index for queries with
expressions in WHERE clause. The range scan access path is especially beneficial when the
predicate (WHERE clause) has low selectivity. In Example 3-6 the optimizer can use an
index range scan if an index is built on the expression 12*salary*commission_pct.

A virtual column is useful for speeding access to data derived from expressions. For
example, you could define virtual column annual_sal as 12*salary*commission_pct and create
a function-based index on annual_sal.

The optimizer performs expression matching by parsing the expression in a SQL statement
and then comparing the expression trees of the statement and the function-based
index. This comparison is case-insensitive and ignores blank spaces.

See Also:

  - "Overview of the Optimizer" on page 7-10

  - Oracle Database Performance Tuning Guide for more information about gathering
    statistics

  - Oracle Database Administrator's Guide to learn how to add virtual columns to a table

*** Application Domain Indexes

An application domain index is a customized index specific to an application. Oracle
Database provides extensible indexing to do the following:

  - Accommodate indexes on customized, complex data types such as documents, spatial data,
    images, and video clips (see "Unstructured Data" on page 19-11)

  - Make use of specialized indexing techniques

You can encapsulate application-specific index management routines as an indextype schema
object and define a domain index on table columns or attributes of an object
type. Extensible indexing can efficiently process application-specific operators.

The application software, called the cartridge, controls the structure and content of a
domain index. The database interacts with the application to build, maintain, and search
the domain index. The index structure itself can be stored in the database as an
index-organized table or externally as a file.

See Also:

  - Oracle Database Data Cartridge Developer's Guide for information about using data
    cartridges within the Oracle Database extensibility architecture

*** Index Storage

Oracle Database stores index data in an index segment. Space available for index data in a
data block is the data block size minus block overhead, entry overhead, rowid, and one
length byte for each value indexed.

The tablespace of an index segment is either the default tablespace of the owner or a
tablespace specifically named in the CREATE INDEX statement. For ease of administration
you can store an index in a separate tablespace from its table. For example, you may
choose not to back up tablespaces containing only indexes, which can be rebuilt, and so
decrease the time and storage required for backups.

See Also:

  - Chapter 12, "Logical Storage Structures"

** Overview of Index-Organized Tables

An index-organized table is a table stored in a variation of a B-tree index structure. In
a heap-organized table, rows are inserted where they fit. In an index-organized table,
rows are stored in an index defined on the primary key for the table. Each index entry in
the B-tree also stores the non-key column values. Thus, the index is the data, and the
data is the index. Applications manipulate index-organized tables just like heap-organized
tables, using SQL statements.

Index-organized tables provide faster access to table rows by primary key or a valid
prefix of the key. The presence of non-key columns of a row in the leaf block avoids an
additional data block I/O. For example, the salary of employee 100 is stored in the index
row itself. Also, because rows are stored in primary key order, range access by the
primary key or prefix involves minimal block I/Os. Another benefit is the avoidance of the
space overhead of a separate primary key index

Index-organized tables are useful when related pieces of data must be stored together or
data must be physically stored in a specific order. This type of table is often used for
information retrieval, spatial (see "Overview of Oracle Spatial" on page 19-14), and OLAP
applications (see "OLAP" on page 17-19).

See Also:

  - Oracle Database Administrator's Guide to learn how to manage index-organized tables

  - Oracle Database Performance Tuning Guide to learn how to use index-organized tables to
    improve performance

  - Oracle Database SQL Language Reference for CREATE TABLE ... ORGANIZATION INDEX syntax
    and semantics

*** Index-Organized Table Characteristics

  The database system performs all operations on index-organized tables by manipulating
  the B-tree index structure. Table 3-4 summarizes the differences between index-organized
  tables and heap-organized tables.

  Heap-Organized Table                          Index-Organized Table
  ============== =====                          =============== =====

  The rowid uniquely identifies a row.          Primary key uniquely identifies a   
  Primary key constraint may optionally be      row. Primary key constraint must be 
  defined.                                      defined.

  Physical rowid in ROWID pseudocolumn          Logical rowid in ROWID pseudocolumn allows
  allows building secondary indexes.            building secondary indexes.

  Individual rows may be accessed directly      Access to individual rows may be achieved
  by rowid.                                     indirectly by primary key.

  Sequential full table scan returns all        A full index scan or fast full index scan
  rows in some order.                           returns all rows in some order.

  Can be stored in a table cluster with         Cannot be stored in a table cluster.
  other tables.

  Can contain a column of the LONG data type    Can contain LOB columns but not LONG
  and columns of LOB data types.                columns.

  Can contain virtual columns (only             Cannot contain virtual columns.
  relational heap tables are supported).

See Also:

  - "Introduction to Logical Storage Structures" on page 12-1

*** Index-Organized Tables with Row Overflow Area

When creating an index-organized table, you can specify a separate segment as a row
overflow area. In index-organized tables, B-tree index entries can be large because they
contain an entire row, so a separate segment to contain the entries is useful. In
contrast, B-tree entries are usually small because they consist of the key and rowid.

If a row overflow area is specified, then the database can divide a row in an
index-organized table into the following parts:

  - The index entry

  - The overflow part

*** Secondary Indexes on Index-Organized Tables

A secondary index is an index on an index-organized table. In a sense, it is an index on
an index. The secondary index is an independent schema object and is stored separately
from the index-organized table.

As explained in "Rowid Data Types" on page 2-13, Oracle Database uses row identifiers
called logical rowids for index-organized tables. A logical rowid is a base64-encoded
representation of the table primary key. The logical rowid length depends on the primary
key length.

Rows in index leaf blocks can move within or between blocks because of insertions. Rows in
index-organized tables do not migrate as heap-organized rows do (see "Chained and Migrated
Rows" on page 12-16). Because rows in index-organized tables do not have permanent
physical addresses, the database uses logical rowids based on primary key.

See Also:

  - Oracle Database Administrator's Guide to learn how to create secondary indexes on an
    index-organized table

  - Oracle Database VLDB and Partitioning Guide to learn about creating secondary indexes
    on indexed-organized table partitions

**** Logical Rowids and Physical Guesses

Secondary indexes use the logical rowids to locate table rows. A logical rowid includes a
physical guess, which is the physical rowid of the index entry when it was first
made. Oracle Database can use physical guesses to probe directly into the leaf block of
the index-organized table, bypassing the primary key search. When the physical location of
a row changes, the logical rowid remains valid even if it contains a physical guess that
is stale.

For a heap-organized table, access by a secondary index involves a scan of the secondary
index and an additional I/O to fetch the data block containing the row. For
index-organized tables, access by a secondary index varies, depending on the use and
accuracy of physical guesses:

  - Without physical guesses, access involves two index scans: a scan of the secondary
    index followed by a scan of the primary key index.

  - With physical guesses, access depends on their accuracy: 

    - With accurate physical guesses, access involves a secondary index scan and an
      additional I/O to fetch the data block containing the row.

    - With inaccurate physical guesses, access involves a secondary index scan and an I/O
      to fetch the wrong data block (as indicated by the guess), followed by an index
      unique scan of the index organized table by primary key value.

**** Bitmap Indexes on Index-Organized Tables

A secondary index on an index-organized table can be a bitmap index. As explained in
"Bitmap Indexes" on page 3-13, a bitmap index stores a bitmap for each index key.

When bitmap indexes exist on an index-organized table, all the bitmap indexes use a
heap-organized mapping table. The mapping table stores the logical rowids of the
index-organized table. Each mapping table row stores one logical rowid for the
corresponding index-organized table row.

The database accesses a bitmap index using a search key. If the database finds the key,
then the bitmap entry is converted to a physical rowid. With heap-organized tables, the
database uses the physical rowid to access the base table. With index-organized tables,
the database uses the physical rowid to access the mapping table, which in turn yields a
logical rowid that the database uses to access the index-organized table.

  NB: Movement of rows in an index-organized table does not leave the bitmap indexes built
      on that index-organized table unusable.

* Chapter 4 Partitions, Views, and Other Schema Objects

** Overview of Partitions

Partitioning enables you to decompose very large tables and indexes into smaller and more
manageable pieces called partitions. Each partition is an independent object with its own
name and optionally its own storage characteristics.

From the perspective of an application, only one schema object exists. DML statements
require no modification to access partitioned tables. Partitioning is useful for many
different types of database applications, particularly those that manage large volumes of
data. Benefits include:

  - Increased availability

    The unavailability of a partition does not entail the unavailability of the
    object. The query optimizer automatically removes unreferenced partitions from the
    query plan so queries are not affected when the partitions are unavailable.

  - Easier administration of schema objects

    A partitioned object has pieces that can be managed either collectively or
    individually. DDL statements can manipulate partitions rather than entire tables or
    indexes. Thus, you can break up resource-intensive tasks such as rebuilding an index
    or table. For example, you can move one table partition at a time. If a problem
    occurs, then only the partition move must be redone, not the table move. Also,
    dropping a partition avoids executing numerous DELETE statements.

  - Reduced contention for shared resources in OLTP systems

    In some OLTP systems, partitions can decrease contention for a shared resource.  For
    example, DML is distributed over many segments rather than one segment.

  - Enhanced query performance in data warehouses

    In a data warehouse, partitioning can speed processing of ad hoc queries. For
    example, a sales table containing a million rows can be partitioned by quarter.


See Also: Oracle Database VLDB and Partitioning Guide for an introduction to partitioning

*** Partition Characteristics

Each partition of a table or index must have the same logical attributes, such as column
names, data types, and constraints. For example, all partitions in a table share the same
column and constraint definitions, and all partitions in an index share the same indexed
columns. However, each partition can have separate physical attributes, such as the
tablespace to which it belongs.

**** Partition Key

The partition key is a set of one or more columns that determines the partition in which
each row in a partitioned table should go. Each row is unambiguously assigned to a single
partition.

In the sales table, you could specify the time_id column as the key of a range
partition. The database assigns rows to partitions based on whether the date in this
column falls in a specified range. Oracle Database automatically directs insert, update,
and delete operations to the appropriate partition by using the partition key.

**** Partitioning Strategies

Oracle Partitioning offers several partitioning strategies that control how the
database places data into partitions. The basic strategies are range, list, and hash
partitioning.

A single-level partitioning strategy uses only one method of data distribution, for
example, only list partitioning or only range partitioning. In composite
partitioning, a table is partitioned by one data distribution method and then each
partition is further divided into subpartitions using a second data distribution
method. For example, you could use a list partition for channel_id and a range
subpartition for time_id.

***** Range Partitioning

In range partitioning, the database maps rows to partitions based on ranges of values of
the partitioning key. Range partitioning is the most common type of partitioning and is
often used with dates.

***** List Partitioning

In list partitioning, the database uses a list of discrete values as the partition key for
each partition. You can use list partitioning to control how individual rows map to
specific partitions. By using lists, you can group and organize related sets of data when
the key used to identify them is not conveniently ordered.

The example shows partitioning on statically defined even and odd id numbers.

***** Hash Partitioning

In hash partitioning, the database maps rows to partitions based on a hashing algorithm
that the database applies to the user-specified partitioning key. The destination of a row
is determined by the internal hash function applied to the row by the database. The
hashing algorithm is designed to evenly distributes rows across devices so that each
partition contains about the same number of rows.

Hash partitioning is useful for dividing large tables to increase manageability. Instead
of one large table to manage, you have several smaller pieces. The loss of a single hash
partition does not affect the remaining partitions and can be recovered
independently. Hash partitioning is also useful in OLTP systems with high update
contention.

See Also:

  - Oracle Database VLDB and Partitioning Guide to learn how to create partitions

  - Oracle Database SQL Language Reference for CREATE TABLE ... PARTITION BY examples

*** Partitioned Tables

A partitioned table consists of one or more partitions, which are managed individually and
can operate independently of the other partitions. A table is either partitioned or
nonpartitioned. Even if a partitioned table consists of only one partition, this table is
different from a nonpartitioned table, which cannot have partitions added to it.

A partitioned table is made up of one or more table partition segments. If you create a
partitioned table named hash_products, then no table segment is allocated for this
table. Instead, the database stores data for each table partition in its own partition
segment. Each table partition segment contains a portion of the table data.

Some or all partitions of a heap-organized table can be stored in a compressed
format. Compression saves space and can speed query execution. Thus, compression can be
useful in environments such as data warehouses, where the amount of insert and update
operations is small, and in OLTP environments.

The attributes for table compression can be declared for a tablespace, table, or table
partition. If declared at the tablespace level, then tables created in the tablespace are
compressed by default. You can alter the compression attribute for a table, in which case
the change only applies to new data going into that table. Consequently, a single table or
partition may contain compressed and uncompressed blocks, which guarantees that data size
will not increase because of compression. If compression could increase the size of a
block, then the database does not apply it to the block.


See Also:

  - "Table Compression" on page 2-19 and "Overview of Segments" on page 12-21

  - Oracle Database Data Warehousing Guide to learn about table compression in a data
    warehouse

*** Partitioned Indexes

A partitioned index is an index that, like a partitioned table, has been decomposed into
smaller and more manageable pieces. Global indexes are partitioned independently of the
table on which they are created, whereas local indexes are automatically linked to the
partitioning method for a table. Like partitioned tables, partitioned indexes improve
manageability, availability, performance, and scalability.

See Also:

  - "Overview of Indexes" on page 3-1

  - Oracle Database VLDB and Partitioning Guide and Oracle Database Performance Tuning
    Guide for more information about partitioned indexes and how to decide which type to
    use

**** Local Partitioned Indexes

In a local partitioned index, the index is partitioned on the same columns, with the same
number of partitions and the same partition bounds as its table. Each index partition is
associated with exactly one partition of the underlying table, so that all keys in an
index partition refer only to rows stored in a single table partition. In this way, the
database automatically synchronizes index partitions with their associated table
partitions, making each table-index pair independent.

Local partitioned indexes are common in data warehousing environments. Local indexes offer
the following advantages:

- Availability is increased because actions that make data invalid or unavailable in a
  partition affect this partition only.

- Partition maintenance is simplified. When moving a table partition, or when data ages
  out of a partition, only the associated local index partition must be rebuilt or
  maintained. In a global index, all index partitions must be rebuilt or maintained.

- If point-in-time recovery of a partition occurs, then the indexes can be recovered to
  the recovery time (see "Data File Recovery" on page 18-14). The entire index does not
  need to be rebuilt.

You cannot explicitly add a partition to a local index. Instead, new partitions are added
to local indexes only when you add a partition to the underlying table. Likewise, you
cannot explicitly drop a partition from a local index. Instead, local index partitions are
dropped only when you drop a partition from the underlying table.

Like other indexes, you can create a bitmap index on partitioned tables. The only
restriction is that bitmap indexes must be local to the partitioned tableâ€”they cannot be
global indexes. Global bitmap indexes are supported only on nonpartitioned tables.

***** Local Prefixed and Nonprefixed Indexes

Local partitioned indexes are divided into the following subcategories:

- Local prefixed indexes

  In this case, the partition keys are on the leading edge of the index definition. In
  Example 4-2 on page 4-3, the table is partitioned by range on time_id. A local prefixed
  index on this table would have time_id as the first column in its list.

- Local nonprefixed indexes

  In this case, the partition keys are not on the leading edge of the indexed column list
  and need not be in the list at all. In Example 4-5 on page 4-8, the index is local
  nonprefixed because the partition key product_id is not on the leading edge.

Both types of indexes can take advantage of partition elimination (also called partition
pruning), which occurs when the optimizer speeds data access by excluding partitions from
consideration. Whether a query can eliminate partitions depends on the query predicate. A
query that uses a local prefixed index always allows for index partition elimination,
whereas a query that uses a local nonprefixed index might not.

See Also: Oracle Database VLDB and Partitioning Guide to learn how to use prefixed and
          nonprefixed indexse

***** Local Partitioned Index Storage

Like a table partition, a local index partition is stored in its own segment. Each segment
contains a portion of the total index data. Thus, a local index made up of four partitions
is not stored in a single index segment, but in four separate segments.

See Also: Oracle Database SQL Language Reference for CREATE INDEX ... LOCAL examples

**** Global Partitioned Indexes

A global partitioned index is a B-tree index that is partitioned independently of the
underlying table on which it is created. A single index partition can point to any or all
table partitions, whereas in a locally partitioned index, a one-to-one parity exists
between index partitions and table partitions.

In general, global indexes are useful for OLTP applications, where rapid access, data
integrity, and availability are important. In an OLTP system, a table may be partitioned
by one key, for example, the employees.department_id column, but an application may need
to access the data with many different keys, for example, by employee_id or job_id. Global
indexes can be useful in this scenario.

You can partition a global index by range or by hash. If partitioned by range, then the
database partitions the global index on the ranges of values from the table columns you
specify in the column list. If partitioned by hash, then the database assigns rows to the
partitions using a hash function on values in the partitioning key columns.

See Also:

  - Oracle Database VLDB and Partitioning Guide to learn how to use global partitioned
    indexes

  - Oracle Database SQL Language Reference for CREATE INDEX ... GLOBAL examples

*** Partitioned Index-Organized Tables

You can partition an index-organized table (IOT) by range, list, or hash. Partitioning is
useful for providing improved manageability, availability, and performance for IOTs. In
addition, data cartridges that use IOTs can take advantage of the ability to partition
their stored data.

Note the following characteristics of partitioned IOTs:

  - Partition columns must be a subset of primary key columns.

  - Secondary indexes can be partitioned locally and globally.

  - OVERFLOW data segments are always equipartitioned with the table partitions.

Oracle Database supports bitmap indexes on partitioned and nonpartitioned index-organized
tables. A mapping table is required for creating bitmap indexes on an index-organized
table.

See Also: "Overview of Index-Organized Tables" on page 3-20

** Overview of Views

A view is a logical representation of one or more tables. In essence, a view is a stored
query. A view derives its data from the tables on which it is based, called base
tables. Base tables can be tables or other views. All operations performed on a view
actually affect the base tables. You can use views in most places where tables are used.

  NB: Materialized views use a different data structure from standard views. See "Overview
      of Materialized Views" on page 4-16.

Views enable you to tailor the presentation of data to different types of users. Views are
often used to:

  - Provide an additional level of table security by restricting access to a predetermined
    set of rows or columns of a table

  - Hide data complexity

    For example, a single view can be defined with a join, which is a collection of
    related columns or rows in multiple tables. However, the view hides the fact that this
    information actually originates from several tables. A query might also perform
    extensive calculations with table information. Thus, users can query a view without
    knowing how to perform a join or calculations.

  - Present the data in a different perspective from that of the base table

    For example, the columns of a view can be renamed without affecting the tables on
    which the view is based.

  - Isolate applications from changes in definitions of base tables

    For example, if the defining query of a view references three columns of a four column
    table, and a fifth column is added to the table, then the definition of the view is
    not affected, and all applications using the view are not affected.

For an example of the use of views, consider the hr.employees table, which has several
columns and numerous rows. To allow users to see only five of these columns or only
specific rows, you could create a view as follows:

  CREATE VIEW staff AS
    SELECT employee_id, last_name, job_id, manager_id, department_id
    FROM employees;

As with all subqueries, the query that defines a view cannot contain the FOR UPDATE
clause.

  See Also:

  - Oracle Database Administrator's Guide to learn how to manage views

  - Oracle Database SQL Language Reference for CREATE VIEW syntax and semantics

*** Characteristics of Views

Unlike a table, a view is not allocated storage space, nor does a view contain
data. Rather, a view is defined by a query that extracts or derives data from the base
tables referenced by the view. Because a view is based on other objects, it requires no
storage other than storage for the query that defines the view in the data dictionary.

A view has dependencies on its referenced objects, which are automatically handled by the
database. For example, if you drop and re-create a base table of a view, then the database
determines whether the new base table is acceptable to the view definition.

**** Data Manipulation in Views

Because views are derived from tables, they have many similarities. For example, a view
can contain up to 1000 columns, just like a table. Users can query views, and with some
restrictions they can perform DML on views. Operations performed on a view affect data in
some base table of the view and are subject to the integrity constraints and triggers of
the base tables.

The following example creates a view of the hr.employees table:

  CREATE VIEW staff_dept_10 AS
  SELECT employee_id, last_name, job_id, manager_id, department_id
  FROM employees
  WHERE department_id = 10
  WITH CHECK OPTION CONSTRAINT staff_dept_10_cnst;

The defining query references only rows for department 10. The CHECK OPTION creates the
view with a constraint so that INSERT and UPDATE statements issued against the view cannot
result in rows that the view cannot select. Thus, rows for employees in department 10 can
be inserted, but not rows for department 30.

See Also:

  - Oracle Database SQL Language Reference to learn about subquery restrictions in CREATE
    VIEW statements

**** How Data Is Accessed in Views

Oracle Database stores a view definition in the data dictionary as the text of the query
that defines the view. When you reference a view in a SQL statement, Oracle Database
performs the following tasks:

  - Merges a query (whenever possible) against a view with the queries that define the
    view and any underlying views

    Oracle Database optimizes the merged query as if you issued the query without
    referencing the views. Therefore, Oracle Database can use indexes on any referenced
    base table columns, whether the columns are referenced in the view definition or in
    the user query against the view.

    Sometimes Oracle Database cannot merge the view definition with the user query. In
    such cases, Oracle Database may not use all indexes on referenced columns.

  - Parses the merged statement in a shared SQL area

    Oracle Database parses a statement that references a view in a new shared SQL area
    only if no existing shared SQL area contains a similar statement. Thus, views provide
    the benefit of reduced memory use associated with shared SQL.

  - Executes the SQL statement

See Also

  - "Overview of the Optimizer" on page 7-10 and Oracle Database Performance Tuning Guide
    to learn about query optimization

  - "Shared SQL Areas" on page 14-16

*** Updatable Join Views

A join view is defined as a view that has multiple tables or views in its FROM clause. In
Example 4-7, the staff_dept_10_30 view joins the employees and departments tables,
including only employees in departments 10 or 30.

  CREATE VIEW staff_dept_10_30 AS 
  SELECT employee_id, last_name, job_id, e.department_id 
  FROM   employees e, departments d 
  WHERE  e.department_id IN (10, 30)
  AND    e.department_id = d.department_id;

An updatable join view, also called a modifiable join view, involves two or more base
tables or views and permits DML operations. An updatable view contains multiple tables in
the top-level FROM clause of the SELECT statement and is not restricted by the WITH READ
ONLY clause.

To be inherently updatable, a view must meet several criteria. For example, a general rule
is that an INSERT, UPDATE, or DELETE operation on a join view can modify only one base
table at a time. The following query of the USER_UPDATABLE_COLUMNS data dictionary view
shows that the view created in Example 4-7 is updatable:

  SQL> SELECT TABLE_NAME, COLUMN_NAME, UPDATABLE
     2 FROM USER_UPDATABLE_COLUMNS
     3 WHERE TABLE_NAME = 'STAFF_DEPT_10_30';

  TABLE_NAME           COLUMN_NAME                    UPD
  -------------------- ------------------------------ ---
  STAFF_DEPT_10_30     EMPLOYEE_ID                    YES
  STAFF_DEPT_10_30     LAST_NAME                      YES
  STAFF_DEPT_10_30     JOB_ID                         YES
  STAFF_DEPT_10_30     DEPARTMENT_ID                  YES

All updatable columns of a join view must map to columns of a key-preserved table. A
key-preserved table in a join query is a table in which each row of the underlying table
appears at most one time in the output of the query. In Example 4-7, department_id is the
primary key of the departments table, so each row from the employees table appears at most
once in the result set, making the employees table key-preserved. The departments table is
not key-preserved because each of its rows may appear many times in the result set.

See Also:

  - Oracle Database Administrator's Guide to learn how to update join views

*** Object Views

Just as a view is a virtual table, an object view is a virtual object table. Each row in
the view is an object, which is an instance of an object type. An object type is a
user-defined data type.

You can retrieve, update, insert, and delete relational data as if it was stored as an
object type. You can also define views with columns that are object data types, such as
objects, REFs, and collections (nested tables and VARRAYs).

Like relational views, object views can present only the data that you want users to
see. For example, an object view could present data about IT programmers but omit
sensitive data about salaries. The following example creates an employee_type object and
then the view it_prog_view based on this object:

  CREATE TYPE employee_type AS OBJECT
  (
    employee_id NUMBER (6),
    last_name VARCHAR2 (25),
    job_id   VARCHAR2 (10)
  );
  /

  CREATE VIEW it_prog_view OF employee_type
    WITH OBJECT IDENTIFIER (employee_id) AS
  SELECT e.employee_id, e.last_name, e.job_id
  FROM   employees e
  WHERE  job_id = 'IT_PROG';

Object views are useful in prototyping or transitioning to object-oriented applications
because the data in the view can be taken from relational tables and accessed as if the
table were defined as an object table. You can run object-oriented applications without
converting existing tables to a different physical structure.

See Also:

  - Oracle Database Object-Relational Developer's Guide to learn about object types and
    object views

  - Oracle Database SQL Language Reference to learn about the CREATE TYPE command

** Overview of Materialized Views

Materialized views are query results that have been stored or "materialized" in advance as
schema objects. The FROM clause of the query can name tables, views, and materialized
views. Collectively these objects are called master tables (a replication term) or detail
tables (a data warehousing term).

Materialized views are used to summarize, compute, replicate, and distribute data. They
are suitable in various computing environments, such as the following:

  - In data warehouses, you can use materialized views to compute and store data generated
    from aggregate functions such as sums and averages.

    A summary is an aggregate view that reduces query time by precalculating joins and
    aggregation operations and storing the results in a table. Materialized views are
    equivalent to summaries (see "Data Warehouse Architecture (Basic)" on page 17-16). You
    can also use materialized views to compute joins with or without aggregations. If
    compatibility is set to Oracle9i or higher, then materialized views are usable for
    queries that include filter selections.

  - In materialized view replication, the view contains a complete or partial copy of a
    table from a single point in time. Materialized views replicate data at distributed
    sites and synchronize updates performed at several sites. This form of replication is
    suitable for environments such as field sales when databases are not always connected
    to the network.

  - In mobile computing environments, you can use materialized views to download a data
    subset from central servers to mobile clients, with periodic refreshes from the
    central servers and propagation of updates by clients to the central servers.

In a replication environment, a materialized view shares data with a table in a different
database, called a master database. The table associated with the materialized view at the
master site is the master table.

See Also:

  - "Information Sharing" on page 17-21 to learn about replication with Oracle Streams

  - Oracle Database 2 Day + Data Replication and Integration Guide and Oracle Database
    Advanced Replication to learn how to use materialized views

  - Oracle Database SQL Language Reference to learn about the CREATE MATERIALIZED VIEW
    statement

*** Characteristics of Materialized Views

Materialized views share some characteristics of nonmaterialized views and
indexes. Materialized views are similar to indexes in the following ways:

  - They contain actual data and consume storage space.

  - They can be refreshed when the data in their master tables changes.

  - They can improve performance of SQL execution when used for query rewrite operations.

  - Their existence is transparent to SQL applications and users.

A materialized view is similar to a nonmaterialized view because it represents data in
other tables and views. Unlike indexes, users can query materialized views directly using
SELECT statements. Depending on the types of refresh that are required, the views can also
be updated with DML statements.

The following example creates and populates a materialized aggregate view based on three
master tables in the sh sample schema:

  CREATE MATERIALIZED VIEW sales_mv AS
  SELECT t.calendar_year, p.prod_id, SUM(s.amount_sold) AS sum_sales
  FROM   times t, products p, sales s
  WHERE  t.time_id = s.time_id
  AND    p.prod_id = s.prod_id
  GROUP BY t.calendar_year, p.prod_id;

The following example drops table sales, which is a master table for sales_mv, and then
queries sales_mv. The query selects data because the rows are stored (materialized)
separately from the data in the master tables.

  SQL> DROP TABLE sales;
  Table dropped.

  SQL> SELECT * FROM sales_mv WHERE ROWNUM < 4;
  CALENDAR_YEAR    PROD_ID  SUM_SALES
  ------------- ---------- ----------
           1998         13  936197.53
           1998         26  567533.83
           1998         27  107968.24

A materialized view can be partitioned. You can define a materialized view on a
partitioned table and one or more indexes on the materialized view.

See Also:

  - Oracle Database Data Warehousing Guide to learn how to use materialized views in a
    data warehouse

*** Refresh Methods for Materialized Views

The database maintains data in materialized views by refreshing them after changes to
their master tables. The refresh method can be incremental, known as fast refresh, or a
complete refresh.

A complete refresh occurs when the materialized view is initially defined as BUILD
IMMEDIATE, unless the materialized view references a prebuilt table. The refresh involves
executing the query that defines the materialized view. This process can be slow,
especially if the database must read and process huge amounts of data.

A fast refresh eliminates the need to rebuild materialized views from scratch. Thus,
processing only the changes can result in a very fast refresh time. Materialized views can
be refreshed either on demand or at regular time intervals. Alternatively, materialized
views in the same database as their master tables can be refreshed whenever a transaction
commits its changes to the master tables.

For materialized views that use the fast refresh method, a materialized view log or direct
loader log keeps a record of changes to the master tables. A materialized view log is a
schema object that records changes to master table data so that a materialized view
defined on the master table can be refreshed incrementally. Each materialized view log is
associated with a single master table. The materialized view log resides in the same
database and schema as its master table.


See Also:

  - Oracle Database Data Warehousing Guide to learn how to refresh materialized views

  - Oracle Database Advanced Replication to learn about materialized view logs

*** Query Rewrite

Query rewrite is an optimization technique that transforms a user request written in terms
of master tables into a semantically equivalent request that includes materialized
views. When base tables contain large amounts of data, computing an aggregate or join is
expensive and time-consuming. Because materialized views contain precomputed aggregates
and joins, query rewrite can quickly answer queries using materialized views.

The optimizer query transformer transparently rewrites the request to use the materialized
view, requiring no user intervention and no reference to the materialized view in the SQL
statement. Because query rewrite is transparent, materialized views can be added or
dropped without invalidating the SQL in the application code.

In general, rewriting queries to use materialized views rather than detail tables improves
response time.

See Also:

  - "Overview of the Optimizer" on page 7-10

  - Oracle Database Data Warehousing Guide to learn how to use query rewrite

** Overview of Sequences

A sequence is a schema object from which multiple users can generate unique integers. A
sequence generator provides a highly scalable and well-performing method to generate
surrogate keys for a number data type.

*** Sequence Characteristics

A sequence definition indicates general information, such as the following:

  - The name of the sequence

  - Whether the sequence ascends or descends

  - The interval between numbers

  - Whether the database should cache sets of generated sequence numbers in memory

  - Whether the sequence should cycle when a limit is reached

The following example creates the sequence customers_seq in the sample schema oe.

  CREATE SEQUENCE customers_seq
  START WITH 1000
  INCREMENT BY 1
  NOCACHE
  NOCYCLE; 

See Also:

  - Oracle Database 2 Day Developer's Guide and Oracle Database Administrator's Guide to
    learn how to manage sequences

  - Oracle Database SQL Language Reference for CREATE SEQUENCE syntax and semantics

*** Concurrent Access to Sequences

The same sequence generator can generate numbers for multiple tables. In this way, the
database can generate primary keys automatically and coordinate keys across multiple rows
or tables. For example, a sequence can generate primary keys for an orders table and a
customers table.

The sequence generator is useful in multiuser environments for generating unique numbers
without the overhead of disk I/O or transaction locking. For example, two users
simultaneously insert new rows into the orders table. By using a sequence to generate
unique numbers for the order_id column, neither user has to wait for the other to enter
the next available order number. The sequence automatically generates the correct values
for each user.

Each user that references a sequence has access to his or her current sequence number,
which is the last sequence generated in the session. A user can issue a statement to
generate a new sequence number or use the current number last generated by the
session. After a statement in a session generates a sequence number, it is available only
to this session. Individual sequence numbers can be skipped if they were generated and
used in a transaction that was ultimately rolled back.

  N.B.: If your application requires a gap-free set of numbers, then you cannot use Oracle
        sequences. You must serialize activities in the database using your own developed
        code.

See Also:

  - Chapter 9, "Data Concurrency and Consistency"

** Overview of Dimensions

A typical data warehouse has two important components: dimensions and facts. A dimension
is any category used in specifying business questions, for example, time, geography,
product, department, and distribution channel. A fact is an event or entity associated
with a particular set of dimension values, for example, units sold or profits.

Examples of multidimensional requests include the following:

  - Show total sales across all products at increasing aggregation levels for a geography
    dimension, from state to country to region, for 2007 and 2008.

  - Create a cross-tabular analysis of our operations showing expenses by territory in
    South America for 2007 and 2008. Include all possible subtotals.

  - List the top 10 sales representatives in Asia according to 2008 sales revenue for
    automotive products, and rank their commissions.

Many multidimensional questions require aggregated data and comparisons of data sets,
often across time, geography or budgets.

Creating a dimension permits the broader use of the query rewrite feature. By
transparently rewriting queries to use materialized views, the database can improve query
performance.

See Also:

  - "Overview of Data Warehousing and Business Intelligence" on page 17-14

*** Hierarchical Structure of a Dimension

A dimension table is a logical structure that defines hierarchical relationships between
pairs of columns or column sets. A dimension has no data storage assigned to
it. Dimensional information is stored in dimension tables, whereas fact information is
stored in a fact table.

Within a customer dimension, customers could roll up to city, state, country, subregion,
and region. Data analysis typically starts at higher levels in the dimensional hierarchy
and gradually drills down if the situation warrants such analysis.

Each value at the child level is associated with one and only one value at the parent
level. A hierarchical relationship is a functional dependency from one level of a
hierarchy to the next level in the hierarchy.

See Also:

  - Oracle Database Data Warehousing Guide to learn about dimensions

  - Oracle OLAP User's Guide to learn how to create dimensions

*** Creation of Dimensions

Dimensions are created with SQL statements. The CREATE DIMENSION statement specifies:

  - Multiple LEVEL clauses, each of which identifies a column or column set in the
    dimension
  
  - One or more HIERARCHY clauses that specify the parent/child relationships between
    adjacent levels
  
  - Optional ATTRIBUTE clauses, each of which identifies an additional column or column
    set associated with an individual level

The following statement was used to create the customers_dim dimension in the sample
schema sh:

  CREATE DIMENSION customers_dim
    LEVEL customer    IS (customers.cust_id)            
    LEVEL city        IS (customers.cust_city)          
    LEVEL state       IS (customers.cust_state_province)
    LEVEL country     IS (countries.country_id)         
    LEVEL subregion   IS (countries.country_subregion)  
    LEVEL region      IS (countries.country_region)     
    HIERARCHY geog_rollup (
      customer   CHILD OF
      city       CHILD OF
      state      CHILD OF
      country    CHILD OF
      subregion  CHILD OF
      region     
    JOIN KEY (customers.country_id) REFERENCES country )
    ATTRIBUTE customer DETERMINES
      (cust_first_name, cust_last_name, cust_gender,
       cust_marital_status, cust_year_of_birth,
       cust_income_level, cust_credit_limit)
    ATTRIBUTE country DETERMINES (countries.country_name);

The columns in a dimension can come either from the same table (denormalized) or from
multiple tables (fully or partially normalized). For example, a normalized time dimension
can include a date table, a month table, and a year table, with join conditions that
connect each date row to a month row, and each month row to a year row. In a fully
denormalized time dimension, the date, month, and year columns are in the same
table. Whether normalized or denormalized, the hierarchical relationships among the
columns must be specified in the CREATE DIMENSION statement.

See Also:

  - Oracle Warehouse Builder Data Modeling, ETL, and Data Quality Guide for information
    about how dimensions are used in a warehousing environment

  - Oracle Database SQL Language Reference for CREATE DIMENSION syntax and semantics

** Overview of Synonyms

A synonym is an alias for a schema object. For example, you can create a synonym for a
table or view, sequence, PL/SQL program unit, user-defined object type, or another
synonym. Because a synonym is simply an alias, it requires no storage other than its
definition in the data dictionary.

Synonyms can simplify SQL statements for database users. Synonyms are also useful for
hiding the identity and location of an underlying schema object. If the underlying object
must be renamed or moved, then only the synonym must be redefined. Applications based on
the synonym continue to work without modification.

You can create both private and public synonyms. A private synonym is in the schema of a
specific user who has control over its availability to others. A public synonym is owned
by the user group named PUBLIC and is accessible by every database user.

In Example 4-9, a database administrator creates a public synonym named people for the
hr.employees table. The user then connects to the oe schema and counts the number of rows
in the table referenced by the synonym.

Example 4-8  Public Synonym

  SQL> CREATE PUBLIC SYNONYM people FOR hr.employees;
  Synonym created.

  SQL> CONNECT oe
  Enter password: password
  Connected.

  SQL> SELECT COUNT(*) FROM people;
    COUNT(*)
  ----------
         107

Use public synonyms sparingly because they make database consolidation more difficult. As
shown in Example 4-9, if another administrator attempts to create the public synonym
people, then the creation fails because only one public synonym people can exist in the
database. Overuse of public synonyms causes namespace conflicts between applications.

Example 4-9 Public Synonym

  SQL> CREATE PUBLIC SYNONYM people FOR oe.customers;
  CREATE PUBLIC SYNONYM people FOR oe.customers
                        *
  ERROR at line 1:
  ORA-00955: name is already used by an existing object

  SQL> SELECT OWNER, SYNONYM_NAME, TABLE_OWNER, TABLE_NAME
       FROM DBA_SYNONYMS
       WHERE SYNONYM_NAME = 'PEOPLE';

  OWNER      SYNONYM_NAME TABLE_OWNER TABLE_NAME 
  ---------- ------------ ----------- ----------
  PUBLIC     PEOPLE       HR          EMPLOYEES

Synonyms themselves are not securable. When you grant object privileges on a synonym, you
are really granting privileges on the underlying object. The synonym is acting only as an
alias for the object in the GRANT statement.

See Also:

  - Oracle Database Administrator's Guide to learn how to manage synonyms

  - Oracle Database SQL Language Reference for CREATE SYNONYM syntax and semantics

* Chapter 5: Data Integrity

  This chapter explains how integrity constraints enforce the business rules associated
  with a database and prevent the entry of invalid information into tables.

** Introduction to Data Integrity

*** Techniques for Guaranteeing Data Integrity

When designing a database application, developers have various options for guaranteeing
the integrity of data stored in the database. These options include:

  - Enforcing business rules with triggered stored database procedures, as described in
    "Overview of Triggers" on page 8-16

  - Using stored procedures to completely control access to data, as described in
    "Introduction to Server-Side Programming" on page 8-1

  - Enforcing business rules in the code of a database application

  - Using Oracle Database integrity constraints, which are rules defined at the column or
    object level that restrict values in the database

*** Advantages of Integrity Constraints

An integrity constraint is a schema object that is created and dropped using SQL. To
enforce data integrity, use integrity constraints unless it is not possible. Advantages of
integrity constraints over alternatives for enforcing data integrity include:

  - Declarative ease

    Because you define integrity constraints using SQL statements, no additional
    programming is required when you define or alter a table. The SQL statements are easy
    to write and eliminate programming errors.

  - Centralized rules

    Integrity constraints are defined for tables and are stored in the data dictionary
    (see "Overview of the Data Dictionary" on page 6-1). Thus, data entered by all
    applications must adhere to the same integrity constraints. If the rules change at the
    table level, then applications need not change. Also, applications can use metadata in
    the data dictionary to immediately inform users of violations, even before the
    database checks the SQL statement.

  - Flexibility when loading data

    You can disable integrity constraints temporarily to avoid performance overhead when
    loading large amounts of data. When the data load is complete, you can re-enable the
    integrity constraints.

See Also

  - Oracle Database 2 Day Developer's Guide and Oracle Database 2 Day Developer's Guide to
    learn how to maintain data integrity

  - Oracle Database 2 Day DBAand Oracle Database Administrator's Guide to learn how to
    manage integrity constraints

** Types of Integrity Constraints

Oracle Database enables you to apply constraints both at the table and column level. A
constraint specified as part of the definition of a column or attribute is called an
inline specification. A constraint specified as part of the table definition is called an
out-of-line specification.

The term key is used in the definitions of several types of integrity constraints. A key
is the column or set of columns included in the definition of certain types of integrity
constraints. Keys describe the relationships between the tables and columns of a
relational database. Individual values in a key are called key values.

Types of Constraints:

  - NOT NULL

  - Unique key

  - Primary key

  - Foreign key

  - Check

  - REF

See Also:

  - Oracle Database SQL Language Reference to learn more about the types of constraints

*** NOT NULL Integrity Constraints

A NOT NULL constraint requires that a column of a table contain no null values. A null is
the absence of a value. By default, all columns in a table allow nulls.

See Also:

  - Oracle Database 2 Day Developer's Guide for examples of adding NOT NULL constraints to
    a table

  - Oracle Database SQL Language Reference for restrictions on using NOT NULL constraints

  - Oracle Database Advanced Application Developer's Guide to learn when to use the NOT
    NULL constraint

*** Unique Constraints

A unique key constraint requires that every value in a column or set of columns be
unique. No rows of a table may have duplicate values in a column (the unique key) or set
of columns (the composite unique key) with a unique key constraint.

  NB: The term key refers only to the columns defined in the integrity constraint. Because
      the database enforces a unique constraint by implicitly creating or reusing an index
      on the key columns, the term unique key is sometimes incorrectly used as a synonym
      for unique key constraint or unique index.

Unique key constraints are appropriate for any column where duplicate values are not
allowed. Unique constraints differ from primary key constraints, whose purpose is to
identify each table row uniquely, and typically contain values that have no significance
other than being unique. Examples of unique keys include:

  - A customer phone number, where the primary key is the customer number

  - A department name, where the primary key is the department number

Example SQL:

CREATE TABLE employees
       ( ...
         email VARCHAR2(25)
             CONSTRAINT emp_email_nn NOT NULL ... 
             CONSTRAINT emp_email_uk UNIQUE (email) ... );

Unless a NOT NULL constraint is also defined, a null always satisfies a unique key
constraint. Thus, columns with both unique key constraints and NOT NULL constraints are
typical. This combination forces the user to enter values in the unique key and eliminates
the possibility that new row data conflicts with existing row data.

  NB: Because of the search mechanism for unique key constraints on multiple columns, you
      cannot have identical values in the non-null columns of a partially null composite
      unique key constraint.

See Also:

  - "Unique and Nonunique Indexes" on page 3-4

  - Oracle Database 2 Day Developer's Guide for examples of adding UNIQUE constraints to a
    table

*** Primary Key Constraints

In a primary key constraint, the values in the group of one or more columns subject to the
constraint uniquely identify the row. Each table can have one primary key, which in effect
names the row and ensures that no duplicate rows exist.

A primary key can be natural or a surrogate. A natural key is a meaningful identifier made
of existing attributes in a table. For example, a natural key could be a postal code in a
lookup table. In contrast, a surrogate key is a system-generated incrementing identifier
that ensures uniqueness within a table. Typically, surrogate keys are generated by a
sequence.

The Oracle Database implementation of the primary key constraint guarantees that the
following statements are true:

  - No two rows have duplicate values in the specified column or set of columns.

  - The primary key columns do not allow nulls.

The database enforces primary key constraints with an index. Usually, a primary key
constraint created for a column implicitly creates a unique index and a NOT NULL
constraint. Note the following exceptions to this rule:

  - In some cases, as when you create a primary key with a deferrable constraint, the
    generated index is not unique.

    NB: You can explicitly create a unique index with the CREATE UNIQUE INDEX statement.

  - If a usable index exists when a primary key constraint is created, then the constraint
    reuses this index and does not implicitly create a new one.

By default the name of the implicitly created index is the name of the primary key
constraint. You can also specify a user-defined name for an index. You can specify storage
options for the index by including the ENABLE clause in the CREATE TABLE or ALTER TABLE
statement used to create the constraint.

See Also:

  - Oracle Database 2 Day Developer's Guide and Oracle Database Advanced Application
    Developer's Guide to learn how to add primary key constraints to a table

*** Foreign Key Constraints

Whenever two tables contain one or more common columns, Oracle Database can enforce the
relationship between the two tables through a foreign key constraint, also called a
referential integrity constraint. The constraint requires that for each value in the
column on which the constraint is defined, the value in the other specified other table
and column must match. An example of a referential integrity rule is an employee can work
for only an existing department.

Referential Integrity Terms Defined

  - Foreign key

    The column or set of columns included in the definition of the constraint that
    reference a referenced key. For example, the department_id column in employees is a
    foreign key that references the department_id column in departments.

    Foreign keys may be defined as multiple columns. However, a composite foreign key must
    reference a composite primary or unique key with the same number of columns and the
    same data types.

    The value of foreign keys can match either the referenced primary or unique key value,
    or be null. If any column of a composite foreign key is null, then the non-null
    portions of the key do not have to match any corresponding portion of a parent key.

  - Referenced key

    The unique key or primary key of the table referenced by a foreign key. For example,
    the department_id column in departments is the referenced key for the department_id
    column in employees.

  - Dependent or child table

    The table that includes the foreign key. This table is dependent on the values present
    in the referenced unique or primary key. For example, the employees table is a child
    of departments.

  - Referenced or parent table

    The table that is referenced by the foreign key of the child table. It is this table's
    referenced key that determines whether specific inserts or updates are allowed in the
    child table. For example, the departments table is a parent of employees.

See Also

  - Oracle Database 2 Day Developer's Guide and Oracle Database Advanced Application
    Developer's Guide to learn how to add foreign key constraints to a table

**** Self-Referential Integrity Constraints

Figure 5-2 shows a self-referential integrity constraint. In this case, a foreign key
references a parent key in the same table.

The example shows a manager_id column that references the employee_id column of the same
table.

**** Nulls and Foreign Keys

The relational model permits the value of foreign keys to match either the referenced
primary or unique key value, or be null. For example, a user could insert a row into
hr.employees without specifying a department ID.

If any column of a composite foreign key is null, then the non-null portions of the key do
not have to match any corresponding portion of a parent key.

**** Parent Key Modifications and Foreign Keys

The relationship between foreign key and parent key has implications for deletion of
parent keys. For example, if a user attempts to delete the record for this department,
then what happens to the records for employees in this department?

When a parent key is modified, referential integrity constraints can specify the following
actions to be performed on dependent rows in a child table:

  - No action on deletion or update

    In the normal case, users cannot modify referenced key values if the results would
    violate referential integrity. For example, if employees.department_id is a foreign
    key to departments, and if employees belong to a particular department, then an
    attempt to delete the row for this department violates the constraint.

  - Cascading deletions

    A deletion cascades (DELETE CASCADE) when rows containing referenced key values are
    deleted, causing all rows in child tables with dependent foreign key values to also be
    deleted. For example, the deletion of a row in departments causes rows for all
    employees in this department to be deleted.

  - Deletions that set null

    A deletion sets null (DELETE SET NULL) when rows containing referenced key values are
    deleted, causing all rows in child tables with dependent foreign key values to set
    those values to null. For example, the deletion of a department row sets the
    department_id column value to null for employees in this department.

The following outlines the DML statements allowed by the different referential actions on
the key values in the parent table, and the foreign key values in the child table.

  - INSERT

    - Issued Against Parent Table

      Always OK if the parent key value is unique

    - Issued Against Child Table

      OK only if the foreign key value exists in the parent key or is partially or all
      null

  - UPDATE NO ACTION

    - Issued Against Parent Table

      Allowed if the statement does not leave any rows in the child table without a
      referenced parent key value

    - Issued Against Child Table

      Allowed if the new foreign key value still references a referenced key value

  - DELETE NO ACTION

    - Issued Against Parent Table

      Allowed if no rows in the child table reference the parent key value

    - Issued Against Child Table

      Always OK

  - DELETE CASCADE

    - Issued Against Parent Table

      Always OK

    - Issued Against Child Table

      Always OK

  - DELETE SET NULL

    - Issued Against Parent Table

      Always OK

    - Issued Against Child Table

      Always OK

  NB: Other referential actions not supported by FOREIGN KEY integrity constraints of
      Oracle Database can be enforced using database triggers. See "Overview of Triggers"

See Also

  - Oracle Database SQL Language Reference to learn about the ON DELETE clause


**** Indexes and Foreign Keys

As a rule, foreign keys should be indexed. The only exception is when the matching unique
or primary key is never updated or deleted. Indexing the foreign keys in child tables
provides the following benefits:

  - Prevents a full table lock on the child table. Instead, the database acquires a row
    lock on the index.

  - Removes the need for a full table scan of the child table. As an illustration, assume
    that a user removes the record for department 10 from the departments table. If
    employees.department_id is not indexed, then the database must scan employees to see
    if any employees exist in department 10.

See Also

  - "Locks and Foreign Keys" on page 9-21 and "Overview of Indexes" on page 3-1

*** Check Constraints

A check constraint on a column or set of columns requires that a specified condition be
true or unknown for every row. If DML results in the condition of the constraint
evaluating to false, then the SQL statement is rolled back.

The chief benefit of check constraints is the ability to enforce very specific integrity
rules. For example, you could use check constraints to enforce the following rules in the
hr.employees table:

  - The salary column must not have a value greater than 10000.

  - The commission column must have a value that is not greater than the salary.

E.g.:

  SQL> ALTER TABLE employees ADD CONSTRAINT max_emp_sal CHECK (salary < 10001);
  SQL> INSERT INTO employees (employee_id,last_name,email,hire_date,job_id,salary)
       VALUES (999,'Green','BGREEN',SYSDATE,'ST_CLERK',20000);
     ...
       ERROR at line 1: ORA-02290: check constraint (HR.MAX_EMP_SAL) violated

A single column can have multiple check constraints that reference the column in its
definition. For example, the salary column could have one constraint that prevents values
over 10000 and a separate constraint that prevents values less than 500.

If multiple check constraints exist for a column, then they must be designed so their
purposes do not conflict. No order of evaluation of the conditions can be assumed. The
database does not verify that check conditions are not mutually exclusive.

See Also: 

  - Oracle Database SQL Language Reference to learn about restrictions for check
    constraints

** States of Integrity Constraints

As part of constraint definition, you can specify how and when Oracle Database should
enforce the constraint, thereby determining the constraint state.

*** Checks for Modified and Existing Data

The database enables you to specify whether a constraint applies to existing data or
future data. If a constraint is enabled, then the database checks new data as it is
entered or updated. Data that does not conform to the constraint cannot enter the
database. For example, enabling a NOT NULL constraint on employees.department_id
guarantees that every future row has a department ID. If a constraint is disabled, then
the table can contain rows that violate the constraint.

You can set constraints to validate (VALIDATE) or not validate (NOVALIDATE) existing
data. If VALIDATE is specified, then existing data must conform to the constraint. For
example, enabling a NOT NULL constraint on employees.department_id and setting it to
VALIDATE checks that every existing row has a department ID. If NOVALIDATE is specified,
then existing data need not conform to the constraint.

The behavior of VALIDATE and NOVALIDATE always depends on whether the constraint is
enabled or disabled. Table 5-4 summarizes the relationships of Modified Data and Exsiting
Data:

    Modified Data / Existing Data

  - ENABLE / VALIDATE

    Existing and future data must obey the constraint. An attempt to apply a new
    constraint to a populated table results in an error if existing rows violate the
    constraint.

  - ENABLE / NOVALIDATE

    The database checks the constraint, but it need not be true for all rows. Thus,
    existing rows can violate the constraint, but new or modified rows must conform to the
    rules.

  - DISABLE / VALIDATE

    The database disables the constraint, drops its index, and prevents modification of
    the constrained columns.

  - DISABLE / NOVALIDATE

    The constraint is not checked and is not necessarily true

See Also:

  - Oracle Database SQL Language Reference to learn about constraint states



*** Deferrable Constraints

Every constraint is either in a not deferrable (default) or deferrable state. This state
determines when Oracle Database checks the constraint for validity.

**** Nondeferrable Constraints

If a constraint is not deferrable, then Oracle Database never defers the validity check of
the constraint to the end of the transaction. Instead, the database checks the constraint
at the end of each statement. If the constraint is violated, then the statement rolls
back.

For example, assume that you create a nondeferrable NOT NULL constraint for the
employees.last_name column. If a user attempts to insert a row with no last name, then the
database immediately rolls back the statement because the NOT NULL constraint is
violated. No row is inserted.

**** Deferrable Constraints

A deferrable constraint permits a transaction to use the SET CONSTRAINT clause to defer
checking of this constraint until a COMMIT statement is issued. If you make changes to the
database that might violate the constraint, then this setting effectively lets you disable
the constraint until all the changes are complete.

You can set the default behavior for when the database checks the deferrable
constraint. You can specify either of the following attributes:

  - INITIALLY IMMEDIATE

    The database checks the constraint immediately after each statement executes. If the
    constraint is violated, then the database rolls back the statement.

  - INITIALLY DEFERRED

    The database checks the constraint when a COMMIT is issued. If the constraint is
    violated, then the database rolls back the transaction.

Assume that a deferrable NOT NULL constraint on employees.last_name is set to INITIALLY
DEFERRED. A user creates a transaction with 100 INSERT statements, some of which have null
values for last_name. When the user attempts to commit, the database rolls back all 100
statements. However, if this constraint were set to INITIALLY IMMEDIATE, then the database
would not roll back the transaction.

If a constraint causes an action, then the database considers this action as part of the
statement that caused it, whether the constraint is deferred or immediate. For example,
deleting a row in departments causes the deletion of all rows in employees that reference
the deleted department row. In this case, the deletion from employees is considered part
of the DELETE statement executed against departments.

See Also: 

  - Oracle Database SQL Language Reference for information about constraint attributes and
    their default values

*** Examples of Constraint Checking

Some examples may help illustrate when Oracle Database performs the checking of
constraints. Assume the following:

  - The employees table has the structure shown in Figure 5-2 on page 5-8.

  - The self-referential constraint makes entries in the manager_id column dependent on
    the values of the employee_id column.

**** Insertion of a Value in a Foreign Key Column When No Parent Key Value Exists

Consider the insertion of the first row into the employees table. No rows currently exist,
so how can a row be entered if the value in the manager_id column cannot reference any
existing value in the employee_id column? Some possibilities are:

  - A null can be entered for the manager_id column of the first row, if the manager_id
    column does not have a NOT NULL constraint defined on it.

    Because nulls are allowed in foreign keys, this row is inserted into the table.

  - The same value can be entered in the employee_id and manager_id columns, specifying
    that the employee is his or her own manager.

    This case reveals that Oracle Database performs its constraint checking after the
    statement has been completely run. To allow a row to be entered with the same values
    in the parent key and the foreign key, the database must first run the statement (that
    is, insert the new row) and then determine whether any row in the table has an
    employee_id that corresponds to the manager_id of the new row.

  - A multiple row INSERT statement, such as an INSERT statement with nested SELECT
    statement, can insert rows that reference one another.

    For example, the first row might have 200 for employee ID and 300 for manager ID,
    while the second row has 300 for employee ID and 200 for manager. Constraint checking
    is deferred until the complete execution of the statement. All rows are inserted
    first, and then all rows are checked for constraint violations.

Default values are included as part of an INSERT statement before the statement is
parsed. Thus, default column values are subject to all integrity constraint checking.

**** An Update of All Foreign Key and Parent Key Values

Consider the same self-referential integrity constraint in a different scenario. The
company has been sold. Because of this sale, all employee numbers must be updated to be
the current value plus 5000 to coordinate with the employee numbers of the new
company. Because manager numbers are really employee numbers (see Figure 5-3), the manager
numbers must also increase by 5000.

You could execute the following SQL statement to update the values:

  UPDATE employees
  SET employee_id = employee_id + 5000,
       manager_id = manager_id + 5000;

Although a constraint is defined to verify that each manager_id value matches an
employee_id value, the preceding statement is legal because the database effectively
checks constraints after the statement completes.

The examples in this section illustrate the constraint checking mechanism during INSERT
and UPDATE statements, but the database uses the same mechanism for all types of DML
statements. The same mechanism is used for all types of constraints, not just
self-referential constraints.

  NB: Operations on a view or synonym are subject to the integrity constraints defined on
      the base tables.

* Chapter 6: Data Dictionary and Dynamic Performance Views

This chapter describes the central set of read-only reference tables and views of each
Oracle database, known collectively as the data dictionary. The chapter also describes the
dynamic performance views, which are special views that are continuously updated while a
database is open and in use.

** Overview of the Data Dictionary

An important part of an Oracle database is its data dictionary, which is a read-only set
of tables that provides administrative metadata about the database. A data dictionary
contains information such as the following:

  - The definitions of every schema object in the database, including default values for
    columns and integrity constraint information

  - The amount of space allocated for and currently used by the schema objects

  - The names of Oracle Database users, privileges and roles granted to users, and
    auditing information related to users (see "User Accounts" on page 17-1)

The data dictionary is a central part of data management for every Oracle database.  For
example, the database performs the following actions:

  - Accesses the data dictionary to find information about users, schema objects, and
    storage structures

  - Modifies the data dictionary every time that a DDL statement is issued (see "Data
    Definition Language (DDL) Statements" on page 7-3)

Because Oracle Database stores data dictionary data in tables, just like other data, users
can query the data with SQL. For example, users can run SELECT statements to determine
their privileges, which tables exist in their schema, which columns are in these tables,
whether indexes are built on these columns, and so on

See Also:

  - "Introduction to Schema Objects" on page 2-1

*** Contents of the Data Dictionary

The data dictionary consists of the following types of objects:

  - Base tables

    These underlying tables store information about the database. Only Oracle Database
    should write to and read these tables. Users rarely access the base tables directly
    because they are normalized and most data is stored in a cryptic format.

  - Views

    These views decode the base table data into useful information, such as user or table
    names, using joins and WHERE clauses to simplify the information. These views contain
    the names and description of all objects in the data dictionary. Some views are
    accessible to all database users, whereas others are intended for administrators only.

Typically, data dictionary views are grouped in sets. In many cases, a set consists of
three views containing similar information and distinguished from each other by their
prefixes, as shown in Table 6-1. By querying the appropriate views, you can access only
the information relevant for you.

Table 6-1 Data Dictionary View Sets

Prefix   User    Contents                 Notes
        Access

DBA_      DB     All Objects              Some DBA_ views have additional columns 
        Admins                            containing information useful to the    
                                          administrator.

ALL_     All     Objects to which         Includes objects owned by user. These views obey 
         Users   user has privileges      the current set of enabled roles.

USER_    All     Objects owned by         Views with the prefix USER_ usually exclude the
         Users   user                     column OWNER. This column is implied in the    
                                          USER_ views to be the user issuing the query.

Not all views sets have three members. For example, the data dictionary contains a
DBA_LOCK view but no ALL_LOCK view.

The system-supplied DICTIONARY view contains the names and abbreviated descriptions of all
data dictionary views. The following query of this view includes partial sample output:

  SELECT * FROM DICTIONARY ORDER BY TABLE_NAME;

    ...

  USER_UNUSED_COL_TABS
  User tables with unused columns

  USER_UPDATABLE_COLUMNS
  Description of updatable columns

  USER_USERS
  Information about the current user

  USER_USTATS
  All statistics on tables or indexes owned by the user

See Also:

  - Oracle Database Reference for a complete list of data dictionary views and their
    columns

  - "Overview of Views" on page 4-12

**** Views with the Prefix DBA_

Views with the prefix DBA_ show all relevant information in the entire database. DBA_
views are intended only for administrators.

For example, the following query shows information about all objects in the database:

  SELECT OWNER, OBJECT_NAME, OBJECT_TYPE
  FROM DBA_OBJECTS
  ORDER BY OWNER, OBJECT_NAME;

See Also:

  - Oracle Database Administrator's Guide for detailed information on administrative
    privileges

**** Views with the Prefix ALL_

Views with the prefix ALL_ refer to the user's overall perspective of the database. These
views return information about schema objects to which the user has access through public
or explicit grants of privileges and roles, in addition to schema objects that the user
owns.

For example, the following query returns information about all the objects to which you
have access:

  SELECT OWNER, OBJECT_NAME, OBJECT_TYPE
  FROM ALL_OBJECTS
  ORDER BY OWNER, OBJECT_NAME;

  NB: The only difference from the admin query is the view prefix: DBA_ to ALL_

Because the ALL_ views obey the current set of enabled roles, query results depend on
which roles are enabled, as shown in the following example:

SQL> SET ROLE ALL;

Role set.

SQL> SELECT COUNT(*) FROM ALL_OBJECTS;

COUNT(*)
----------
68295

SQL> SET ROLE NONE;

Role set.

SQL> SELECT COUNT(*) FROM ALL_OBJECTS;

COUNT(*)
----------
53771

Application developers should be cognizant of the effect of roles when using ALL_ views in
a stored procedure, where roles are not enabled by default.

See Also:

  - "PL/SQL Subprograms" on page 8-3

**** Views with the Prefix USER_

The views most likely to be of interest to typical database users are those with the
prefix USER_. These views:

  - Refer to the user's private environment in the database, including metadata about
    schema objects created by the user, grants made by the user, and so on

  - Display only rows pertinent to the user, returning a subset of the information in the
    ALL_ views

  - Has columns identical to the other views, except that the column OWNER is implied

  - Can have abbreviated PUBLIC synonyms for convenience

For example, the following query returns all the objects contained in your schema:

  SELECT OBJECT_NAME, OBJECT_TYPE
  FROM USER_OBJECTS
  ORDER BY OBJECT_NAME;

**** The DUAL Table

DUAL is a small table in the data dictionary that Oracle Database and user-written
programs can reference to guarantee a known result. The dual table is useful when a value
must be returned only once, for example, the current date and time. All database users
have access to DUAL.

The DUAL table has one column called DUMMY and one row containing the value X. The
following example queries DUAL to perform an arithmetical operation:

  SQL> SELECT ((3*4)+5)/3 FROM DUAL;

See Also:

  - Oracle Database SQL Language Reference for more information about the DUAL table


*** Storage of the Data Dictionary

The data dictionary base tables are the first objects created in any Oracle database. All
data dictionary tables and views for a database are stored in the SYSTEM
tablespace. Because the SYSTEM tablespace is always online when the database is open, the
data dictionary is always available when the database is open.

See Also:

  - "The SYSTEM Tablespace" on page 12-32 for more information about the SYSTEM tablespace

*** How Oracle Database Uses the Data Dictionary

The Oracle Database user SYS owns all base tables and user-accessible views of the data
dictionary. Data in the base tables of the data dictionary is necessary for Oracle
Database to function. Therefore, only Oracle Database should write or change data
dictionary information. No Oracle Database user should ever alter rows or schema objects
contained in the SYS schema because such activity can compromise data integrity. The
security administrator must keep strict control of this central account.

During database operation, Oracle Database reads the data dictionary to ascertain that
schema objects exist and that users have proper access to them. Oracle Database also
updates the data dictionary continuously to reflect changes in database structures,
auditing, grants, and data.

See Also:

  - "SYS and SYSTEM Schemas" on page 2-5


**** Public Synonyms for Data Dictionary Views

Oracle Database creates public synonyms for many data dictionary views so users can access
them conveniently. The security administrator can also create additional public synonyms
for schema objects that are used systemwide. Users should avoid naming their own schema
objects with the same names as those used for public synonyms.

See Also:

  - "Overview of Synonyms" on page 4-22

**** Cache the Data Dictionary for Fast Access

Much of the data dictionary information is in the data dictionary cache because the
database constantly requires the information to validate user access and verify the state
of schema objects. Parsing information is typically kept in the caches. The COMMENTS
columns describing the tables and their columns are not cached in the dictionary cache,
but may be cached in the database buffer cache.

See Also:

  - "Data Dictionary Cache" on page 14-19

**** Other Programs and the Data Dictionary

Other Oracle Database products can reference existing views and create additional data dictionary tables or views of their own. Application developers who write programs that refer to the data dictionary should refer to the public synonyms rather than the underlying tables. Synonyms are less likely to change between releases.

** Overview of the Dynamic Performance Views

Throughout its operation, Oracle Database maintains a set of virtual tables that record
current database activity. These views are called dynamic performance views because they
are continuously updated while a database is open and in use. The views, also sometimes
called V$ views, contain information such as the following:

  - System and session parameters

  - Memory usage and allocation

  - File states (including RMAN backup files)

  - Progress of jobs and tasks

  - SQL execution

  - Statistics and metrics

The dynamic performance views have the following primary uses:

  - Oracle Enterprise Manager uses the views to obtain information about the database (see
    "Oracle Enterprise Manager" on page 18-2).

  - Administrators can use the views for performance monitoring and debugging.

See Also: 

  - Oracle Database Reference for a complete list of the dynamic performance views

*** Contents of the Dynamic Performance Views

Dynamic performance views are sometimes called fixed views because they cannot be altered
or removed by a database administrator. However, database administrators can query and
create views on the tables and grant access to these views to other users.

SYS owns the dynamic performance tables, whose names begin with V_$. Views are created on
these tables, and then public synonyms prefixed with V$. For example, the V$DATAFILE view
contains information about data files. The V$FIXED_TABLE view contains information about
all of the dynamic performance tables and views.

For almost every V$ view, a corresponding GV$ view exists. In Oracle Real Application
Clusters (Oracle RAC), querying a GV$ view retrieves the V$ view information from all
qualified database instances (see "Database Server Grid" on page 17-12).

When you use the Database Configuration Assistant (DBCA) to create a database, Oracle
automatically creates the data dictionary. Oracle Database automatically runs the
catalog.sql script, which contains definitions of the views and public synonyms for the
dynamic performance views. You must run catalog.sql to create these views and synonyms.

See Also:

  - "Tools for Database Installation and Configuration" on page 18-4 to learn about DBCA

  - Oracle Database Administrator's Guide to learn how to run catalog.sql manually

  - Oracle Real Application Clusters Administration and Deployment Guide to learn about
    using performance views in Oracle RAC

*** Storage of the Dynamic Performance Views

Dynamic performance views are based on virtual tables built from database memory
structures. Thus, they are not conventional tables stored in the database. Read
consistency is not guaranteed for the views because the data is updated dynamically.

Because the dynamic performance views are not true tables, the data is dependent on the
state of the database and instance. For example, you can query V$INSTANCE and V$BGPROCESS
when the database is started but not mounted. However, you cannot query V$DATAFILE until
the database has been mounted.

See Also:

  - Chapter 9, "Data Concurrency and Consistency"

** Database Object Metadata

The DBMS_METADATA package provides interfaces for extracting complete definitions of
database objects. The definitions can be expressed either as XML or as SQL DDL. Two styles
of interface are provided: a flexible, sophisticated interface for programmatic control,
and a simplified interface for ad hoc querying.

See Also:

  - Oracle Database PL/SQL Packages and Types Reference for more information about
    DBMS_METADATA

* Part II  Oracle Data Access

* Chapter 7: SQL

** Introduction to SQL

See Also:

  - Oracle Database SQL Language Reference for an introduction to SQL

  - "Introduction to Server-Side Programming" on page 8-1 and "Client-Side Database
    Programming" on page 19-5

*** SQL Data Access

SQL is declarative

SQL works with sets

See Also:

  - Oracle Database SQL Language Reference for detailed information about SQL statements
    and other parts of SQL (such as operators, functions, and format models)

*** SQL Standards

... ANSI and ISO standards bodies

The latest SQL standard was adopted in July 2003 and is often called SQL:2003. One part of
the SQL standard, Part 14, SQL/XML (ISO/IEC 9075-14) was revised in 2006 and is often
referred to as SQL/XML:2006.

Oracle SQL includes many extensions to the ANSI/ISO standard SQL language, and Oracle
Database tools and applications provide additional statements. The tools SQL*Plus, SQL
Developer, and Oracle Enterprise Manager enable you to run any ANSI/ISO standard SQL
statement against an Oracle database and any additional statements or functions available
for those tools.

See Also:

  - Oracle Database SQL Language Reference for an explanation of the differences between
    Oracle SQL and standard SQL

  - SQL*Plus User's Guide and Reference for SQL*Plus commands, including their distinction
    from SQL statements

  - "Tools for Database Administrators" on page 18-2 and "Tools for Database Developers"
    on page 19-1

** Overview of SQL Statements

All operations performed on the information in an Oracle database are run using SQL
statements. A SQL statement is a computer program or instruction that consists of
identifiers, parameters, variables, names, data types, and SQL reserved words.

Oracle Database only runs complete SQL statements. A fragment such as the following
generates an error indicating that more text is required:

  SELECT last_name;

Oracle SQL statements are divided into the following categories:

  - Data Definition Language (DDL) Statements

  - Data Manipulation Language (DML) Statements

  - Transaction Control Statements

  - Session Control Statements

  - System Control Statement

  - Embedded SQL Statements

*** Data Definition Language (DDL) Statements

Data definition language (DDL) statements define, structurally change, and drop schema
objects. For example, DDL statements enable you to:

  - Create, alter, and drop schema objects and other database structures, including the
    database itself and database users. Most DDL statements start with the keywords
    CREATE, ALTER, or DROP.

  - Delete all the data in schema objects without removing the structure of these objects
    (TRUNCATE).

    NB: Unlike DELETE, TRUNCATE generates no undo data, which makes it faster than
        DELETE. Also, TRUNCATE does not invoke delete triggers.

  - Grant and revoke privileges and roles (GRANT, REVOKE).

  - Turn auditing options on and off (AUDIT, NOAUDIT).

  - Add a comment to the data dictionary (COMMENT).

DDL enables you to alter attributes of an object without altering the applications that
access the object. For example, you can add a column to a table accessed by a human
resources application without rewriting the application. You can also use DDL to alter the
structure of objects while database users are performing work in the database.

E.g.: 

  CREATE TABLE plants
    ( plant_id    NUMBER PRIMARY KEY,
      common_name VARCHAR2(15) );

  INSERT INTO plants VALUES (1, 'African Violet'); # DML statement

  INSERT INTO plants VALUES (2, 'Amaryllis'); # DML statement

  ALTER TABLE plants ADD ( latin_name VARCHAR2(40) );

  GRANT SELECT ON plants TO scott;

  REVOKE SELECT ON plants FROM scott;

  DROP TABLE plants;

An implicit COMMIT occurs immediately before the database executes a DDL statement and a
COMMIT or ROLLBACK occurs immediately afterward. In Example 7-1, two INSERT statements are
followed by an ALTER TABLE statement, so the database commits the two INSERT
statements. If the ALTER TABLE statement succeeds, then the database commits this
statement; otherwise, the database rolls back this statement. In either case the two
INSERT statements have already been committed.

See Also:

  - "Overview of Database Security" on page 17-1 to learn about privileges and roles

  - Oracle Database 2 Day Developer's Guide and Oracle Database Administrator's Guide to
    learn how to create schema objects

  - Oracle Database SQL Language Reference for a list of DDL statements

*** Data Manipulation Language (DML) Statements

Data manipulation language (DML) statements query or manipulate data in existing schema
objects. Whereas DDL statements enable you to change the structure of the database, DML
statements enable you to query or change the contents. For example, ALTER TABLE changes
the structure of a table, whereas INSERT adds one or more rows to the table.

DML statements are the most frequently used SQL statements and enable you to:

  - Retrieve or fetch data from one or more tables or views (SELECT).

  - Add new rows of data into a table or view (INSERT) by specifying a list of column
    values or using a subquery to select and manipulate existing data.

  - Change column values in existing rows of a table or view (UPDATE).

  - Update or insert rows conditionally into a table or view (MERGE).

  - Remove rows from tables or views (DELETE).

  - View the execution plan for a SQL statement (EXPLAINPLAN). See "How Oracle Database
    Processes DML" on page 7-22.

  - Lock a table or view, temporarily limiting access by other users (LOCKTABLE).

A collection of DML statements that forms a logical unit of work is called a
transaction. For example, a transaction to transfer money could involve three discrete
operations: decreasing the savings account balance, increasing the checking account
balance, and recording the transfer in an account history table. Unlike DDL statements,
DML statements do not implicitly commit the current transaction.

See Also:

  - "Introduction to Transactions" on page 10-1

  - Oracle Database 2 Day Developer's Guide to learn how to query and manipulate data

  - Oracle Database SQL Language Reference for a list of DML statements

**** SELECT Statements


SELECT FROM  is required. 

SELECT   is projection
FROM     is joining
WHERE    is selection
ORDER BY 

**** Joins

A join is a query that combines rows from two or more tables, views, or materialized
views. Example 7-2 joins the employees and departments tables (FROM clause), selects only
rows that meet specified criteria (WHERE clause), and uses projection to retrieve data
from two columns (SELECT).

  SELECT email, department_name
  FROM   employees JOIN departments
  ON     employees.department_id = departments.department_id
  WHERE  employee_id IN (100,103)
  ORDER BY email;

Most joins have at least one join condition, either in the FROM clause or in the WHERE
clause, that compares two columns, each from a different table. The database combines
pairs of rows, each containing one row from each table, for which the join condition
evaluates to TRUE. The optimizer determines the order in which the database joins tables
based on the join conditions, indexes, and any available statistics for the tables.

Join types include the following: 

  - Inner joins

    An inner join is a join of two or more tables that returns only rows that satisfy the
    join condition. For example, if the join condition is employees.department_id =
    departments.department_id, then rows that do not satisfy this condition are not
    returned.

  - Outer joins

    An outer join returns all rows that satisfy the join condition and also returns rows
    from one table for which no rows from the other table satisfy the condition. For
    example, a left outer join of employees and departments retrieves all rows in the
    employees table even if there is no match in departments. A right outer join retrieves
    all rows in departments even if there is no match in employees.

  - Cartesian products

    If two tables in a join query have no join condition, then the database returns their
    Cartesian product. Each row of one table combines with each row of the other. For
    example, if employees has 107 rows and departments has 27, then the Cartesian product
    contains 107*27 rows. A Cartesian product is rarely useful.

See Also:

  - Oracle Database SQL Language Reference for detailed descriptions and examples of joins

**** Subqueries and Implicit Queries

A subquery is a SELECT statement nested within another SQL statement. Subqueries are
useful when you must execute multiple queries to solve a single problem.

Each query portion of a statement is called a query block. In Example 7-3, the subquery in
parentheses is the inner query block. The inner SELECT statement retrieves the IDs of
departments with location ID 1800. These department IDs are needed by the outer query
block, which retrieves names of employees in the departments whose IDs were supplied by
the subquery.

Example 7-3	Subquery

  SELECT first_name, last_name
  FROM employees
  WHERE department_id
  IN    (SELECT department_id FROM departments WHERE location_id = 1800);

The structure of the SQL statement does not force the database to execute the inner query
first. For example, the database could rewrite the entire query as a join of employees and
departments, so that the subquery never executes by itself. As another example, the
Virtual Private Database (VPD) feature could restrict the query of employees using a WHERE
clause, so that the database decides to query the employees first and then obtain the
department IDs. The optimizer determines the best sequence of steps to retrieve the
requested rows.

An implicit query is a component of a DML statement that retrieves data without using a
subquery. An UPDATE, DELETE, or MERGE statement that does not explicitly include a SELECT
statement uses an implicit query to retrieve rows to be modified. For example, the
following statement includes an implicit query for the Baer record:

  UPDATE employees
  SET salary = salary*1.1
  WHERE last_name = 'Baer';

The only DML statement that does not necessarily include a query component is an INSERT
statement with a VALUES clause. For example, an INSERT INTO TABLE mytable VALUES (1)
statement does not retrieve rows before inserting a row.

See Also:

  - "Virtual Private Database (VPD)" on page 17-4

*** Transaction Control Statements

Transaction control statements manage the changes made by DML statements and group DML
statements into transactions. These statements enable you to:

  - Make changes to a transaction permanent (COMMIT).

  - Undo the changes in a transaction, since the transaction started (ROLLBACK) or since a
    savepoint (ROLLBACK TO SAVEPOINT). A savepoint is a user-declared intermediate marker
    within the context of a transaction.

    NB: The ROLLBACK command ends a transaction, but ROLLBACK TO SAVEPOINT does not.

  - Set a point to which you can roll back (SAVEPOINT).

  - Establish properties for a transaction (SET TRANSACTION).

  - Specify whether a deferrable integrity constraint is checked following each DML
    statement or when the transaction is committed (SET CONSTRAINT).

The following example starts a transaction named Update salaries. The example creates a
savepoint, updates an employee salary, and then rolls back the transaction to the
savepoint. The example updates the salary to a different value and commits.

  SET TRANSACTION NAME 'Update salaries';

  SAVEPOINT before_salary_update;

  UPDATE employees SET salary=9100 WHERE employee_id=1234 # DML

  ROLLBACK TO SAVEPOINT before_salary_update;

  UPDATE employees SET salary=9200 WHERE employee_id=1234 # DML

  COMMIT COMMENT 'Updated salaries';

See Also:

  - "Introduction to Transactions" on page 10-1

  - "Deferrable Constraints" on page 5-11

  - Oracle Database SQL Language Reference

*** Session Control Statements

Session control statements dynamically manage the properties of a user session. As
explained in "Connections and Sessions" on page 15-4, a session is a logical entity in the
database instance memory that represents the state of a current user login to a
database. A session lasts from the time the user is authenticated by the database until
the user disconnects or exits the database application.

Session control statements enable you to:

  - Alter the current session by performing a specialized function, such as enabling and
    disabling SQL tracing (ALTER SESSION).

  - Enable and disable roles, which are groups of privileges, for the current session (SET
    ROLE).

The following example turns on SQL tracing for the session and then enables all roles
granted in the current session except dw_manager:

  ALTER SESSION SET SQL_TRACE = TRUE;

  SET ROLE ALL EXCEPT dw_manager;

Session control statements do not implicitly commit the current transaction.

See Also:

  - Oracle Database SQL Language Reference for ALTER SESSION syntax and semantics

*** System Control Statement

System control statements change the properties of the database instance. The only system
control statement is ALTER SYSTEM. It enables you to change settings such as the minimum
number of shared servers, terminate a session, and perform other system-level tasks.





System control statements change the properties of the database instance. The only system
control statement is ALTER SYSTEM. It enables you to change settings such as the minimum
number of shared servers, terminate a session, and perform other system-level tasks.

Following are examples of system control statements:

  ALTER SYSTEM SWITCH LOGFILE;

  ALTER SYSTEM KILL SESSION '39, 23';

The ALTER SYSTEM statement does not implicitly commit the current transaction.

See Also:

  - Oracle Database SQL Language Reference for ALTER SYSTEM syntax and semantics

*** Embedded SQL Statements

Embedded SQL statements incorporate DDL, DML, and transaction control statements within a
procedural language program. They are used with the Oracle precompilers. Embedded SQL is
one approach to incorporating SQL in your procedural language applications. Another
approach is to use a procedural API such as Open Database Connectivity (ODBC) or Java
Database Connectivity (JDBC).

Embedded SQL statements enable you to:

  - Define, allocate, and release cursors (DECLARE CURSOR, OPEN, CLOSE).

  - Specify a database and connect to it (DECLARE DATABASE, CONNECT).

  - Assign variable names (DECLARE STATEMENT).

  - Initialize descriptors (DESCRIBE).

  - Specify how error and warning conditions are handled (WHENEVER).

  - Parse and run SQL statements (PREPARE, EXECUTE, EXECUTE IMMEDIATE).

  - Retrieve data from the database (FETCH).

See Also:

  - "Introduction to Server-Side Programming" on page 8-1 and "Client-Side APIs" on page
    19-7

** Overview of the Optimizer

To understand how Oracle Database processes SQL statements, it is necessary to understand
the part of the database called the optimizer (also known as the query optimizer or
cost-based optimizer). All SQL statements use the optimizer to determine the most
efficient means of accessing the specified data.

*** Use of the Optimizer

To execute a DML statement, Oracle Database may have to perform many steps. Each step
either retrieves rows of data physically from the database or prepares them for the user
issuing the statement.

Many different ways of processing a DML statement are often possible. For example, the
order in which tables or indexes are accessed can vary. The steps that the database uses
to execute a statement greatly affect how quickly the statement runs. The optimizer
generates execution plans describing possible methods of execution.

The optimizer determines which execution plan is most efficient by considering several
sources of information, including query conditions, available access paths, statistics
gathered for the system, and hints. For any SQL statement processed by Oracle, the
optimizer performs the following operations:

  - Evaluation of expressions and conditions

  - Inspection of integrity constraints to learn more about the data and optimize based on
    this metadata

  - Statement transformation

  - Choice of optimizer goals

  - Choice of access paths

  - Choice of join orders

The optimizer generates most of the possible ways of processing a query and assigns a cost
to each step in the generated execution plan. The plan with the lowest cost is chosen as
the query plan to be executed.

  NB: You can obtain an execution plan for a SQL statement without executing the
  plan. Only an execution plan that the database actually uses to execute a query is
  correctly termed a query plan.

You can influence optimizer choices by setting the optimizer goal and by gathering
representative statistics for the optimizer. For example, you may set the optimizer goal
to either of the following:

  - Total throughput

    The ALL_ROWS hint instructs the optimizer to get the last row of the result to the
    client application as fast as possible.

  - Initial response time

    The FIRST_ROWS hint instructs the optimizer to get the first row to the client as fast
    as possible.

A typical end-user, interactive application would benefit from initial response time
optimization, whereas a batch-mode, non-interactive application would benefit from total
throughput optimization.

See Also:

  - Oracle Database PL/SQL Packages and Types Reference for information about using
    DBMS_STATS

  - Oracle Database Performance Tuning Guide for more information about the optimizer and
    using hints


*** Optimizer Components

The optimizer contains 3 main components:

  - Query Transformer

  - Estimator

  - Plan Generator

The input to the optimizer is a parsed query (see "SQL Parsing" on page 7-16). The
optimizer performs the following operations:

  1. The optimizer receives the parsed query and generates a set of potential plans for
     the SQL statement based on available access paths and hints.

  2. The optimizer estimates the cost of each plan based on statistics in the data
     dictionary. The cost is an estimated value proportional to the expected resource use
     needed to execute the statement with a particular plan.

  3. The optimizer compares the costs of plans and chooses the lowest-cost plan, known as
     the query plan, to pass to the row source generator (see "SQL Row Source Generation"
     on page 7-19).

**** Query Transformer

The query transformer determines whether it is helpful to change the form of the query so
that the optimizer can generate a better execution plan. The input to the query
transformer is a parsed query, which is represented by a set of query blocks.

See Also:

  - "Query Rewrite" on page 4-19

**** Estimator

The estimator determines the overall cost of a given execution plan. The estimator
generates three different types of measures to achieve this goal:

  - Selectivity

    This measure represents a fraction of rows from a row set. The selectivity is tied to
    a query predicate, such as last_name='Smith', or a combination of predicates.

  - Cardinality

    This measure represents the number of rows in a row set.

  - Cost

    This measure represents units of work or resource used. The query optimizer uses disk
    I/O, CPU usage, and memory usage as units of work.

If statistics are available, then the estimator uses them to compute the measures. The
statistics improve the degree of accuracy of the measures.

**** Plan Generator

The plan generator tries out different plans for a submitted query and picks the plan with
the lowest cost. The optimizer generates subplans for each of the nested subqueries and
unmerged views, which is represented by a separate query block. The plan generator
explores various plans for a query block by trying out different access paths, join
methods, and join orders.

The optimizer automatically manages plans and ensures that only verified plans are
used. SQL Plan Management (SPM) allows controlled plan evolution by only using a new plan
after it has been verified to perform better than the current plan.

Diagnostic tools such as the EXPLAIN PLAN statement enable you to view execution plans
chosen by the optimizer. EXPLAIN PLAN shows the query plan for the specified SQL query if
it were executed now in the current session. Other diagnostic tools are Oracle Enterprise
Manager and the SQL*Plus AUTOTRACE command. Example 7-6 on page 7-20 shows the execution
plan of a query when AUTOTRACE is enabled.

See Also:

  - "Tools for Database Administrators" on page 18-2

  - Oracle Database SQL Language Reference to learn about EXPLAIN PLAN

  - Oracle Database Performance Tuning Guide to learn about the optimizer components



*** Access Paths

An access path is the way in which data is retrieved from the database. For example, a
query that uses an index has a different access path from a query that does not. In
general, index access paths are best for statements that retrieve a small subset of table
rows. Full scans are more efficient for accessing a large portion of a table.

The database can use several different access paths to retrieve data from a table. The
following is a representative list:

  - Full table scans

    This type of scan reads all rows from a table and filters out those that do not meet
    the selection criteria. The database sequentially scans all data blocks in the
    segment, including those under the high water mark that separates used from unused
    space (see "Segment Space and the High Water Mark" on page 12-27).

  - Rowid scans

    The rowid of a row specifies the data file and data block containing the row and the
    location of the row in that block. The database first obtains the rowids of the
    selected rows, either from the statement WHERE clause or through an index scan, and
    then locates each selected row based on its rowid.

  - Index scans

    This scan searches an index for the indexed column values accessed by the SQL
    statement (see "Index Scans" on page 3-6). If the statement accesses only columns of
    the index, then Oracle Database reads the indexed column values directly from the
    index.

  - Cluster scans

    A cluster scan is used to retrieve data from a table stored in an indexed table
    cluster, where all rows with the same cluster key value are stored in the same data
    block (see "Overview of Indexed Clusters" on page 2-23). The database first obtains
    the rowid of a selected row by scanning the cluster index. Oracle Database locates the
    rows based on this rowid.

  - Hash scans

    A hash scan is used to locate rows in a hash cluster, where all rows with the same
    hash value are stored in the same data block (see "Overview of Hash Clusters" on page
    2-25. The database first obtains the hash value by applying a hash function to a
    cluster key value specified by the statement. Oracle Database then scans the data
    blocks containing rows with this hash value.

The optimizer chooses an access path based on the available access paths for the statement
and the estimated cost of using each access path or combination of paths.

See Also:

  - Oracle Database 2 Day + Performance Tuning Guide and Oracle Database Performance
    Tuning Guide to learn about access paths




*** Optimizer Statistics

Optimizer statistics are a collection of data that describe details about the database and
the objects in the database. The statistics provide a statistically correct picture of
data storage and distribution usable by the optimizer when evaluating access paths.

Optimizer statistics include the following:

  - Table statistics

    These include the number of rows, number of blocks, and average row length.

  - Column statistics

    These include the number of distinct values and nulls in a column and the distribution
    of data.

  - Index statistics

    These include the number of leaf blocks and index levels.

  - System statistics

    These include CPU and I/O performance and utilization.

Oracle Database gathers optimizer statistics on all database objects automatically and
maintains these statistics as an automated maintenance task. You can also gather
statistics manually using the DBMS_STATS package. This PL/SQL package can modify, view,
export, import, and delete statistics.

Optimizer statistics are created for the purposes of query optimization and are stored in
the data dictionary. These statistics should not be confused with performance statistics
visible through dynamic performance views.

See Also:

  - Oracle Database 2 Day + Performance Tuning Guide and Oracle Database Performance
    Tuning Guide to learn how to gather and manage statistics

  - Oracle Database PL/SQL Packages and Types Reference to learn about DBMS_STATS




*** Optimizer Hints

A hint is a comment in a SQL statement that acts as an instruction to the
optimizer. Sometimes the application designer, who has more information about a particular
application's data than is available to the optimizer, can choose a more effective way to
run a SQL statement. The application designer can use hints in SQL statements to specify
how the statement should be run.

For example, suppose that your interactive application runs a query that returns 50
rows. This application initially fetches only the first 25 rows of the query to present to
the end user. You want the optimizer to generate a plan that gets the first 25 records as
quickly as possible so that the user is not forced to wait. You can use a hint to pass
this instruction to the optimizer as shown in the SELECT statement and AUTOTRACE output below:

  SELECT /*+ FIRST_ROWS(25) */ employee_id, department_id
  FROM hr.employees
  WHERE department_id > 50;

  ------------------------------------------------------------------------
  | Id | Operation                   | Name              | Rows | Bytes
  ------------------------------------------------------------------------
  |  0 | SELECT STATEMENT            |                   | 26   | 182
  |  1 | TABLE ACCESS BY INDEX ROWID | EMPLOYEES         | 26   | 182
  |* 2 |  INDEX RANGE SCAN           | EMP_DEPARTMENT_IX |
  ------------------------------------------------------------------------

The execution plan in Example 7-4 shows that the optimizer chooses an index on the
employees.department_id column to find the first 25 rows of employees whose department ID
is over 50. The optimizer uses the rowid retrieved from the index to retrieve the record
from the employees table and return it to the client. Retrieval of the first record is
typically almost instantaneous.

Here is the same without the optimizer hint:

  SELECT employee_id, department_id
  FROM hr.employees
  WHERE department_id > 50;

  ------------------------------------------------------------------------
  | Id | Operation               | Name              | Rows | Bytes | Cos
  ------------------------------------------------------------------------
  |  0 | SELECT STATEMENT        |                   | 50   | 350   |
  |* 1 |  VIEW                   | index$_join$_001  | 50   | 350   |
  |* 2 |   HASHJOIN              |                   |      |       |
  |* 3 |    INDEX RANGE SCAN     | EMP_DEPARTMENT_IX | 50   | 350   |
  |  4 |    INDEX FAST FULL SCAN | EMP_EMP_ID_PK     | 50   | 350   |
  ------------------------------------------------------------------------

The execution plan in Example 7-5 joins two indexes to return the requested records as
fast as possible. Rather than repeatedly going from index to table as in Example 7-4, the
optimizer chooses a range scan of EMP_DEPARTMENT_IX to find all rows where the department
ID is over 50 and place these rows in a hash table. The optimizer then chooses to read the
EMP_EMP_ID_PK index. For each row in this index, it probes the hash table to find the
department ID.

In this case, the database cannot return the first row to the client until the index range
scan of EMP_DEPARTMENT_IX completes. Thus, this generated plan would take longer to return
the first record. Unlike the plan in Example 7-4, which accesses the table by index rowid,
the plan in Example 7-5 uses multiblock I/O, resulting in large reads. The reads enable
the last row of the entire result set to be returned more rapidly.

See Also:

  - Oracle Database Performance Tuning Guide to learn how to use optimizer hints





** Overview of SQL Processing

This section explains how Oracle Database processes SQL statements. Specifically, the
section explains the way in which the database processes DDL statements to create objects,
DML to modify data, and queries to retrieve data.

*** Stages of SQL Processing

./oracle-concepts-figure-sql-processing.png

**** SQL Parsing

As shown in ./oracle-concepts-figure-sql-processing.png , the first stage of SQL
processing is parsing. This stage involves separating the pieces of a SQL statement into a
data structure that can be processed by other routines. The database parses a statement
when instructed by the application, which means that only the application, and not the
database itself, can reduce the number of parses.

When an application issues a SQL statement, the application makes a parse call to the
database to prepare the statement for execution. The parse call opens or creates a cursor,
which is a handle for the session-specific private SQL area that holds a parsed SQL
statement and other processing information. The cursor and private SQL area are in the
PGA.

During the parse call, the database performs the following checks:

  - Syntax Check

  - Semantic Check

  - Shared Pool Check

The preceding checks identify the errors that can be found before statement execution.
Some errors cannot be caught by parsing. For example, the database can encounter deadlocks
or errors in data conversion only during statement execution (see "Locks and Deadlocks" on
page 9-16).

***** Syntax Check

Oracle Database must check each SQL statement for syntactic validity. A statement that
breaks a rule for well-formed SQL syntax fails the check.

***** Semantic Check

The semantics of a statement are its meaning. Thus, a semantic check determines whether a
statement is meaningful, for example, whether the objects and columns in the statement
exist. A syntactically correct statement can fail a semantic check.

***** Shared Pool Check

During the parse, the database performs a shared pool check to determine whether it can
skip resource-intensive steps of statement processing. To this end, the database uses a
hashing algorithm to generate a hash value for every SQL statement. The statement hash
value is the SQL ID shown in V$SQL.SQL_ID.

When a user submits a SQL statement, the database searches the shared SQL area to see if
an existing parsed statement has the same hash value. The hash value of a SQL statement is
distinct from the following values:

  - Memory address for the statement

    Oracle Database uses the SQL ID to perform a keyed read in a lookup table. In this
    way, the database obtains possible memory addresses of the statement.

  - Hash value of an execution plan for the statement

    A SQL statement can have multiple plans in the shared pool. Each plan has a different
    hash value. If the same SQL ID has multiple plan hash values, then the database knows
    that multiple plans exist for this SQL ID.

Parse operations fall into the following categories, depending on the type of statement
submitted and the result of the hash check:

  - Hard parse

    If Oracle Database cannot reuse existing code, then it must build a new executable
    version of the application code. This operation is known as a hard parse, or a library
    cache miss. The database always perform a hard parse of DDL.

    During the hard parse, the database accesses the library cache and data dictionary
    cache numerous times to check the data dictionary. When the database accesses these
    areas, it uses a serialization device called a latch on required objects so that their
    definition does not change (see "Latches" on page 9-25). Latch contention increases
    statement execution time and decreases concurrency.

  - Soft parse

    A soft parse is any parse that is not a hard parse. If the submitted statement is the
    same as a reusable SQL statement in the shared pool, then Oracle Database reuses the
    existing code. This reuse of code is also called a library cache hit.

    Soft parses can vary in the amount of work they perform. For example, configuring the
    session shared SQL area can sometimes reduce the amount of latching in the soft
    parses, making them "softer."

    In general, a soft parse is preferable to a hard parse because the database skips the
    optimization and row source generation steps, proceeding straight to execution.

If a check determines that a statement in the shared pool has the same hash value, then
the database performs semantic and environment checks to determine whether the statements
mean the same. Identical syntax is not sufficient. For example, suppose two different
users log in to the database and issue the following SQL statements:

  CREATE TABLE my_table ( some_col INTEGER );
  SELECT * FROM my_table;

The SELECT statements for the two users are syntactically identical, but two separate
schema objects are named my_table. This semantic difference means that the second
statement cannot reuse the code for the first statement.

Even if two statements are semantically identical, an environmental difference can force a
hard parse. In this case, the environment is the totality of session settings that can
affect execution plan generation, such as the work area size or optimizer
settings. Consider the following series of SQL statements executed by a single user:

  ALTER SYSTEM FLUSH SHARED_POOL;
  SELECT * FROM my_table;

  ALTER SESSION SET OPTIMIZER_MODE=FIRST_ROWS;
  SELECT * FROM my_table;

  ALTER SESSION SET SQL_TRACE=TRUE;
  SELECT * FROM my_table;

In the preceding example, the same SELECT statement is executed in three different
optimizer environments. Consequently, the database creates three separate shared SQL areas
for these statements and forces a hard parse of each statement.

See Also:

  - "Private SQL Area" on page 14-5 and "Shared SQL Areas" on page 14-16

  - Oracle Database Performance Tuning Guide to learn how to configure the shared pool




**** SQL Optimization

As explained in "Overview of the Optimizer" on page 7-10, query optimization is the
process of choosing the most efficient means of executing a SQL statement. The database
optimizes queries based on statistics collected about the actual data being accessed. The
optimizer uses the number of rows, the size of the data set, and other factors to generate
possible execution plans, assigning a numeric cost to each plan. The database uses the
plan with the lowest cost.

The database must perform a hard parse at least once for every unique DML statement and
performs optimization during this parse. DDL is never optimized unless it includes a DML
component such as a subquery that requires optimization.

See Also:

  - Oracle Database Performance Tuning Guide for detailed information about the query
    optimizer

**** SQL Row Source Generation

The row source generator is software that receives the optimal execution plan from the
optimizer and produces an iterative plan, called the query plan, that is usable by the
rest of the database. The iterative plan is a binary program that, when executed by the
SQL virtual machine, produces the result set.

The query plan takes the form of a combination of steps. Each step returns a row set. The
rows in this set are either used by the next step or, in the last step, are returned to
the application issuing the SQL statement.

A row source is a row set returned by a step in the execution plan along with a control
structure that can iteratively process the rows. The row source can be a table, view, or
result of a join or grouping operation.

The row source generator produces a row source tree, which is a collection of row
sources. The row source tree shows the following information:

  - An ordering of the tables referenced by the statement

  - An access method for each table mentioned in the statement

  - A join method for tables affected by join operations in the statement

  - Data operations such as filter, sort, or aggregation

Example 7-6 shows the execution plan of a SELECT statement when AUTOTRACE is enabled. The
statement selects the last name, job title, and department name for all employees whose
last names begin with the letter A. The execution plan for this statement is the output of
the row source generator.

  SELECT e.last_name, j.job_title, d.department_name
  FROM   hr.employees e, hr.departments d, hr.jobs j
  WHERE  e.department_id = d.department_id
  AND    e.job_id = j.job_id
  AND    e.last_name LIKE 'A%' ;

  Execution Plan
  ----------------------------------------------------------
  Plan hash value: 975837011

  -------------------------------------------------------------------------------------------
  | Id | Operation                    | Name          | Rows | Bytes | Cost (%CPU)| Time    |
  -------------------------------------------------------------------------------------------
  | 0 | SELECT STATEMENT              |               |    3 |   189 |     7 (15)| 00:00:01 |
  |* 1|  HASH JOIN                    |               |    3 |   189 |     7 (15)| 00:00:01 |
  |* 2|   HASH JOIN                   |               |    3 |   141 |     5 (20)| 00:00:01 |
  |  3|    TABLE ACCESS BY INDEX ROWID| EMPLOYEES     |    3 |    60 |     2  (0)| 00:00:01 |
  |* 4|     INDEX RANGE SCAN          | EMP_NAME_IDX  |    3 |       |     1  (0)| 00:00:01 |
  |  5|    TABLE ACCESS FULL          | JOBS          |   19 |   513 |     2  (0)| 00:00:01 |
  |  6|   TABLE ACCESS FULL           | DEPARTMENTS   |   27 |   432 |     2  (0)| 00:00:01 |
  -------------------------------------------------------------------------------------------

  Predicate Information (identified by operation id):
  ---------------------------------------------------

     1 - access("E"."DEPARTMENT_ID"="D"."DEPARTMENT_ID")
     2 - access("E"."JOB_ID"="J"."JOB_ID")
     4 - access("E"."LAST_NAME" LIKE 'A%')
         filter("E"."LAST_NAME" LIKE 'A%')




**** SQL Execution

During execution, the SQL engine executes each row source in the tree produced by the row
source generator. This step is the only mandatory step in DML processing.

./oracle-concepts-figure-row-source-tree.png is an execution tree, also called a parse
tree, that shows the flow of row sources from one step to another. In general, the order
of the steps in execution is the reverse of the order in the plan, so you read the plan
from the bottom up. Initial spaces in the Operation column indicate hierarchical
relationships. For example, if the name of an operation is preceded by two spaces, then
this operation is a child of an operation preceded by one space. Operations preceded by
one space are children of the SELECT statement itself.

./oracle-concepts-figure-row-source-tree.png

In Figure row-source-tree.png, each node of the tree acts as a row source, which means
that each step of the execution plan either retrieves rows from the database or accepts
rows from one or more row sources as input. The SQL engine executes each row source as
follows:

  - Steps indicated by the black boxes physically retrieve data from an object in the
    database. These steps are the access paths, or techniques for retrieving data from the
    database.

    - Step 6 uses a full table scan to retrieve all rows from the departments table.

    - Step 5 uses a full table scan to retrieve all rows from the jobs table.

    - Step 4 scans the emp_name_ix index in order, looking for each key that begins with
      the letter A and retrieving the corresponding rowid (see "Index Range Scan" on page
      3-7). For example, the rowid corresponding to Atkinson is AAAPzRAAFAAAABSAAe.

    - Step 3 retrieves from the employees table the rows whose rowids were returned by
      Step 4. For example, the database uses rowid AAAPzRAAFAAAABSAAe to retrieve the row
      for Atkinson.

  - Steps indicated by the clear boxes operate on row sources.

    - Step 2 performs a hash join, accepting row sources from Steps 3 and 5, joining each
      row from the Step 5 row source to its corresponding row in Step 3, and returning the
      resulting rows to Step 1.

      For example, the row for employee Atkinson is associated with the job name Stock
      Clerk.

    Step 1 performs another hash join, accepting row sources from Steps 2 and 6, joining
    each row from the Step 6 source to its corresponding row in Step 2, and returning the
    result to the client.

    For example, the row for employee Atkinson is associated with the department named
    Shipping.

In some execution plans the steps are iterative and in others sequential. The plan shown
in Example 7-6 is iterative because the SQL engine moves from index to table to client and
then repeats the steps.

During execution, the database reads the data from disk into memory if the data is not in
memory. The database also takes out any locks and latches necessary to ensure data
integrity and logs any changes made during the SQL execution. The final stage of
processing a SQL statement is closing the cursor.

See Also:

  - Oracle Database Performance Tuning Guide for detailed information about execution
    plans and the EXPLAIN PLAN statement


*** How Oracle Database Processes DML

Most DML statements have a query component. In a query, execution of a cursor places the
results of the query into a set of rows called the result set.

Result set rows can be fetched either a row at a time or in groups. In the fetch stage,
the database selects rows and, if requested by the query, orders the rows. Each successive
fetch retrieves another row of the result until the last row has been fetched.

In general, the database cannot determine for certain the number of rows to be retrieved
by a query until the last row is fetched. Oracle Database retrieves the data in response
to fetch calls, so that the more rows the database reads, the more work it performs. For
some queries the database returns the first row as quickly as possible, whereas for others
it creates the entire result set before returning the first row.

**** Read Consistency

In general, a query retrieves data by using the Oracle Database read consistency
mechanism. This mechanism, which uses undo data to show past versions of data, guarantees
that all data blocks read by a query are consistent to a single point in time.

For an example of read consistency, suppose a query must read 100 data blocks in a full
table scan. The query processes the first 10 blocks while DML in a different session
modifies block 75. When the first session reaches block 75, it realizes the change and
uses undo data to retrieve the old, unmodified version of the data and construct a
noncurrent version of block 75 in memory.

See Also:

  - "Multiversion Read Consistency" on page 9-2

**** Data Changes

DML statements that must change data use the read consistency mechanism to retrieve only
the data that matched the search criteria when the modification began. Afterward, these
statements retrieve the data blocks as they exist in their current state and make the
required modifications. The database must perform other actions related to the
modification of the data such as generating redo and undo data.

See Also:

  - "Overview of the Online Redo Log" on page 11-12

*** How Oracle Database Processes DDL

Oracle Database processes DDL differently from DML. For example, when you create a table,
the database does not optimize the CREATE TABLE statement. Instead, Oracle Database parses
the DDL statement and carries out the command.

The database process DDL differently because it is a means of defining an object in the
data dictionary. Typically, Oracle Database must parse and execute many recursive SQL
statements to execute a DDL command. Suppose you create a table as follows:

  CREATE TABLE mytable (mycolumn INTEGER);

Typically, the database would run dozens of recursive statements to execute the preceding
statement. The recursive SQL would perform actions such as the following:

  - Issue a COMMIT before executing the CREATE TABLE statement

  - Verify that user privileges are sufficient to create the table

  - Determine which tablespace the table should reside in

  - Ensure that the tablespace quota has not been exceeded

  - Ensure that no object in the schema has the same name

  - Insert rows that define the table into the data dictionary

  - Issue a COMMIT if the DDL statement succeeded or a ROLLBACK if it did not

See Also:

  - Oracle Database Advanced Application Developer's Guide to learn about SQL processing
    for application developers

* Chapter 8: Server-Side Programming: PL/SQL and Java

Chapter 7, "SQL" explains the Structured Query Language (SQL) language and how the
database processes SQL statements. This chapter explains how Procedural Language/SQL
(PL/SQL) or Java programs stored in the database can use SQL.

This chapter includes the following topics:

  - Introduction to Server-Side Programming

  - Overview of PL/SQL

  - Overview of Java in Oracle Database

  - Overview of Triggers

** Introduction to Server-Side Programming

In a nonprocedural language such as SQL, the set of data to be operated on is specified,
but not the operations to be performed or the manner in which they are to be carried
out. In a procedural language program, most statement execution depends on previous or
subsequent statements and on control structures, such as loops or conditional branches,
that are not available in SQL.

The problem is how procedural database applications requiring conditional logic and
program flow control can use SQL. The basic development approaches are as follows:

  - Use client-side programming to embed SQL statements in applications written in
    procedural languages such as C, C++, or Java

    You can place SQL statements in source code and submit it to a precompiler or Java
    translator before compilation. Alternatively, you can eliminate the precompilation
    step and use an API such as Java Database Connectivity (JDBC) or Oracle Call Interface
    (OCI) to enable the application to interact with the database.

  - Use server-side programming to develop data logic that resides in the database

    An application can explicitly invoke stored subprograms (procedures and functions),
    written in PL/SQL (pronounced P L sequel) or Java. You can also create a trigger,
    which is named program unit that is stored in the database and invoked in response to
    a specified event.

This chapter explains the second approach. The principal benefit of server-side
programming is that functionality built into the database can be deployed anywhere. The
database and not the application determines the best way to perform tasks on a given
operating system. Also, subprograms increase scalability by centralizing application
processing on the server, enabling clients to reuse code. Because subprogram calls are
quick and efficient, a single call can start a compute-intensive stored subprogram,
reducing network traffic.

You can use the following languages to store data logic in Oracle Database:

  - PL/SQL

    PL/SQL is the Oracle Database procedural extension to SQL. PL/SQL is integrated with
    the database, supporting all Oracle SQL statements, functions, and data
    types. Applications written in database APIs can invoke PL/SQL stored subprograms and
    send PL/SQL code blocks to the database for execution.

  - Java

    Oracle Database also provides support for developing, storing, and deploying Java
    applications. Java stored subprograms run in the database and are independent of
    programs that run in the middle tier. Java stored subprograms interface with SQL using
    a similar execution model to PL/SQL.

See Also:

  - "Client-Side Database Programming" on page 19-5 to learn about embedding SQL with
    precompilers and APIs

  - Oracle Database 2 Day Developer's Guide for an introduction to Oracle Database
    application development

  - Oracle Database Advanced Application Developer's Guide to learn how to choose a
    programming environment

** Overview of PL/SQL

PL/SQL provides a server-side, stored procedural language that is easy-to-use, seamless
with SQL, robust, portable, and secure. You can access and manipulate database data using
procedural schema objects called PL/SQL program units.

PL/SQL program units generally are categorized as follows:

  - A subprogram is a PL/SQL block that is stored in the database and can be called by
    name from an application. When you create a subprogram, the database parses the
    subprogram and stores its parsed representation in the database. You can declare a
    subprogram as a procedure or a function.

  - An anonymous block is a PL/SQL block that appears in your application and is not named
    or stored in the database. In many applications, PL/SQL blocks can appear wherever SQL
    statements can appear.

The PL/SQL compiler and interpreter are embedded in Oracle SQL Developer, giving
developers a consistent and leveraged development model on both client and server.

Also, PL/SQL stored procedures can be called from several database clients, such as Pro*C,
JDBC, ODBC, or OCI, and from Oracle Reports and Oracle Forms.

See Also:

  - "Tools for Database Developers" on page 19-1

  - Oracle Database PL/SQL Language Reference for complete information about PL/SQL,
    including packages

*** PL/SQL Subprograms

A PL/SQL subprogram is a named PL/SQL block that permits the caller to supply parameters
that can be input only, output only, or input and output values. A subprogram solves a
specific problem or performs related tasks and serves as a building block for modular,
maintainable database applications.

A subprogram is either a procedure or a function. Procedures and functions are identical
except that functions always return a single value to the caller, whereas procedures do
not. The term procedure in this chapter means procedure or function.

See Also:

  - Pro*C/C++ Programmer's Guide and Pro*COBOL Programmer's Guide to learn about stored
    procedures in these languages

  - Oracle Database PL/SQL Language Reference

**** Advantages of PL/SQL Subprograms

As explained in "Introduction to Server-Side Programming" on page 8-1, server-side
programming has many advantages over client-side programming. PL/SQL subprograms provide
the following advantages:

  - Improved Performance

    - The amount of information that an application must send over a network is small
      compared with issuing individual SQL statements or sending the text of an entire
      PL/SQL block to Oracle Database, because the information is sent only once and
      thereafter invoked when it is used.

    - The compiled form of a procedure is readily available in the database, so no
      compilation is required at execution time.

    - If the procedure is present in the shared pool of the SGA, then the database need
      not retrieve it from disk and can begin execution immediately.

  - Memory Allocation

    Because stored procedures take advantage of the shared memory capabilities of Oracle
    Database, it must load only a single copy of the procedure into memory for execution
    by multiple users. Sharing code among users results in a substantial reduction in
    database memory requirements for applications.

  - Improved productivity

    Stored procedures increase development productivity. By designing applications around
    a common set of procedures, you can avoid redundant coding. For example, you can write
    procedures to manipulate rows in the employees table. Any application can call these
    procedures without requiring SQL statements to be rewritten. If the methods of data
    management change, then only the procedures must be modified, not the applications
    that use the procedures.

    Stored procedures are perhaps the best way to achieve code reuse. Because any client
    application written in any language that connects to the database can invoke stored
    procedures, they provide maximum code reuse in all environments.

  - Integrity

    Stored procedures improve the integrity and consistency of your applications. By
    developing applications around a common group of procedures, you reduce the likelihood
    of coding errors.

    For example, you can test a subprogram to guarantee that it returns an accurate result
    and, after it is verified, reuse it in any number of applications without
    retesting. If the data structures referenced by the procedure are altered, then you
    must only recompile the procedure. Applications that call the procedure do not
    necessarily require modifications.

  - Security with definer's rights procedures

    Stored procedures can help enforce data security (see "Overview of Database Security"
    on page 17-1). A definer's rights procedure executes with the privileges of its owner,
    not its current user. Thus, you can restrict the database operations that users
    perform by allowing them to access data only through procedures and functions that run
    with the definer's privileges.

    For example, you can grant users access to a procedure that updates a table but not
    grant access to the table itself. When a user invokes the procedure, it runs with the
    privileges of its owner. Users who have only the privilege to run the procedure (but
    not privileges to query, update, or delete from the underlying tables) can invoke the
    procedure but not manipulate table data in any other way.

  - Inherited privileges and schema context with invoker's rights procedures

    An invoker's rights procedure executes in the current user's schema with the current
    user's privileges. In other words, an invoker's rights procedure is not tied to a
    particular user or schema. Invoker's rights procedures make it easy for application
    developers to centralize application logic, even when the underlying data is divided
    among user schemas.

    For example, an hr_manager user who runs an update procedure on the hr.employees table
    can update salaries, whereas an hr_clerk who runs the same procedure is restricted to
    updating address data.

See Also:

  - Oracle Database PL/SQL Language Reference for an overview of PL/SQL subprograms

  - Oracle Database Security Guide to learn more about definer's and invoker's rights

**** Creation of PL/SQL Subprograms

A subprogram created at the schema level with the CREATE PROCEDURE or CREATE FUNCTION
statement is a standalone stored subprogram. Subprograms defined in a package are called
package subprograms and are considered a part of the package. The database stores
subprograms in the data dictionary as schema objects.

A subprogram has a specification, which includes descriptions of any parameters, and a
body. Example 8-1 shows part of a creation statement for the standalone PL/SQL procedure
hire_employees. The procedure inserts a row into the employees table.

  CREATE PROCEDURE hire_employees
    (p_last_name VARCHAR2, p_job_id VARCHAR2, p_manager_id NUMBER, p_hire_date DATE,
     p_salary NUMBER, p_commission_pct NUMBER, p_department_id NUMBER)
  IS
  BEGIN
    ...
    INSERT INTO employees (employee_id, last_name, job_id, manager_id,
                           hire_date, salary, commission_pct, department_id)
    VALUES (emp_sequence.NEXTVAL, p_last_name, p_job_id, p_manager_id,
            p_hire_date, p_salary, p_commission_pct, p_department_id);
    ...
  END

See Also:

  - Oracle Database 2 Day Developer's Guide to learn how to create subprograms

  - Oracle Database PL/SQL Language Reference to learn about the CREATE PROCEDURE command

**** Execution of PL/SQL Subprograms

Users can execute a subprogram interactively by:

  - Using an Oracle tool, such as SQL*Plus or SQL Developer (see "Tools for Database
    Developers" on page 19-1)

  - Calling it explicitly in the code of a database application, such as an Oracle Forms
    or precompiler application (see "Client-Side Database Programming" on page 19-5)

  - Calling it explicitly in the code of another procedure or trigger

Alternatively, a privileged user can use Oracle Enterprise Manager or SQL*Plus to run the
hire_employees procedure using a statement such as the following:

  EXECUTE hire_employees ('TSMITH', 'CLERK', 1037, SYSDATE, 500, NULL, 20);

The preceding statement inserts a new record for TSMITH in the employees table.

A stored procedure depends on the objects referenced in its body. The database
automatically tracks and manages these dependencies. For example, if you alter the
definition of the employees table referenced by the hire_employees procedure in a manner
that would affect this procedure, then the procedure must be recompiled to validate that
it still works as designed. Usually, the database automatically administers such
dependency management.

See Also:

  - Oracle Database PL/SQL Language Reference to learn how to use PL/SQL subprograms

  - SQL*Plus User's Guide and Reference to learn about the EXECUTE command

*** PL/SQL Packages

A PL/SQL package is a group of related subprograms, along with the cursors and variables
they use, stored together in the database for continued use as a unit. Packaged
subprograms can be called explicitly by applications or users.

Oracle Database includes many supplied packages that extend database functionality and
provide PL/SQL access to SQL features. For example, the UTL_HTTP package enables HTTP
callouts from PL/SQL and SQL to access data on the Internet or to call Oracle Web Server
Cartridges. You can use the supplied packages when creating applications or as a source of
ideas when creating your own stored procedures.

**** Advantages of PL/SQL Packages

PL/SQL packages provide the following advantages:

  - Encapsulation

    Packages enable you to encapsulate or group stored procedures, variables, data types,
    and so on in a named, stored unit. Encapsulation provides better organization during
    development and also more flexibility. You can create specifications and reference
    public procedures without actually creating the package body. Encapsulation simplifies
    privilege management. Granting the privilege for a package makes package constructs
    accessible to the grantee.

  - Data security

    The methods of package definition enable you to specify which variables, cursors, and
    procedures are public and private. Public means that it is directly accessible to the
    user of a package. Private means that it is hidden from the user of a package.

    For example, a package can contain 10 procedures. You can define the package so that
    only three procedures are public and therefore available for execution by a user of
    the package. The remaining procedures are private and can only be accessed by the
    procedures within the package. Do not confuse public and private package variables
    with grants to PUBLIC.

  - Better Performance

    An entire package is loaded into memory in small chunks when a procedure in the
    package is called for the first time. This load is completed in one operation, as
    opposed to the separate loads required for standalone procedures. When calls to
    related packaged procedures occur, no disk I/O is needed to run the compiled code in
    memory.

    A package body can be replaced and recompiled without affecting the specification. As
    a result, schema objects that reference a package's constructs (always through the
    specification) need not be recompiled unless the package specification is also
    replaced. By using packages, unnecessary recompilations can be minimized, resulting in
    less impact on overall database performance.

**** Creation of PL/SQL Packages

You create a package in two parts: the specification and the body. The package
specification declares all public constructs of the package, whereas the body defines all
constructs (public and private) of the package.

Example 8-2 shows part of a statement that creates the package specification for
employees_management, which encapsulates several subprograms used to manage an employee
database. Each part of the package is created with a different statement.

  CREATE PACKAGE employees_management AS
    FUNCTION hire_employees (last_name VARCHAR2, job_id VARCHAR2, manager_id NUMBER,
                             salary NUMBER, commission_pct NUMBER, department_id NUMBER)
                             RETURN NUMBER;
    PROCEDURE fire_employees(employee_id NUMBER);
    PROCEDURE salary_raise(employee_id NUMBER, salary_incr NUMBER);
      ...
    no_sal EXCEPTION;
  END employees_management;  

The specification declares the function hire_employees, the procedures fire_ employees and
salary_raise, and the exception no_sal. All of these public program objects are available
to users who have access to the package.

The CREATE PACKAGE BODY command defines objects declared in the specification. The package
body must be created in the same schema as the package. After creating the package, you
can develop applications that call any of these public procedures or functions or raise
any of the public exceptions of the package.

See Also:

  - Oracle Database PL/SQL Language Reference to learn about the CREATE PACKAGE command

**** Execution of PL/SQL Package Subprograms

You can reference package contents from database triggers, stored subprograms, 3GL
application programs, and Oracle tools.

Database applications explicitly call packaged procedures as necessary. After being
granted the privileges for the employees_management package, a user can explicitly run any
of the procedures contained in it. For example, SQL*Plus can issue the following statement
to run the hire_employees package procedure:

  EXECUTE employees_management.hire_employees ('TSMITH', 'CLERK', 1037, SYSDATE, 500, NULL, 20);

See Also:

  - Oracle Database PL/SQL Language Reference for an introduction to PL/SQL packages

  - Oracle Database Advanced Application Developer's Guide to learn how to code PL/SQL
    packages

*** PL/SQL Anonymous Blocks

An anonymous block is an unnamed, nonpersistent PL/SQL unit. Typical uses for anonymous
blocks include:

  - Initiating calls to subprograms and package constructs

  - Isolating exception handling

  - Managing control by nesting code within other PL/SQL blocks

Anonymous blocks do not have the code reuse advantages of stored subprograms.  Table 8-1
summarizes the differences between the two types of program units.

Table 8-1   Differences Between Anonymous Blocks and Subprograms

Is the PL/SQL Unit ...                   Anonymous           Subprograms
                                         Blocks

Specified with a name?                   No                  Yes

Compiled with every reuse?               No                  No

Stored in the database?                  No                  Yes

Invokable by other applications?         No                  Yes

Capable of returning bind values?        Yes                 Yes

Capable of returning function values?    No                  Yes

Capable of accepting parameters?         No                  Yes

An anonymous block consists of an optional declarative part, an executable part, and one
or more optional exception handlers. The following sample anonymous block selects an
employee last name into a variable and prints the name:

  DECLARE
    v_lname VARCHAR2(25);
  BEGIN
    SELECT last_name INTO v_lname
    FROM employees
    WHERE employee_id = 101;
    DBMS_OUTPUT.PUT_LINE('Employee last name is '||v_lname);
  END;

Oracle Database compiles the PL/SQL block and places it in the shared pool of the SGA, but
it does not store the source code or compiled version in the database for reuse beyond the
current instance. Unlike triggers, an anonymous block is compiled each time it is loaded
into memory. Shared SQL allows anonymous PL/SQL blocks in the shared pool to be reused and
shared until they are flushed out of the shared pool.

See Also:

  - Oracle Database Advanced Application Developer's Guide to learn more about anonymous
    PL/SQL blocks

*** PL/SQL Language Constructs

PL/SQL blocks can include a variety of different PL/SQL language constructs. These
constructs including the following:

  - Variables and constants

    You can declare these constructs within a procedure, function, or package. You can use
    a variable or constant in a SQL or PL/SQL statement to capture or provide a value when
    one is needed.

  - Cursors

    You can declare a cursor explicitly within a procedure, function, or package to
    facilitate record-oriented processing of Oracle Database data. The PL/SQL engine can
    also declare cursors implicitly.

  - Exceptions

    PL/SQL lets you explicitly handle internal and user-defined error conditions, called
    exceptions, that arise during processing of PL/SQL code.

PL/SQL can run dynamic SQL statements whose complete text is not known until run
time. Dynamic SQL statements are stored in character strings that are entered into, or
built by, the program at run time. This technique enables you to create general purpose
procedures. For example, you can create a procedure that operates on a table whose name is
not known until run time.

See Also:

  - Oracle Database PL/SQL Language Reference for details about dynamic SQL

  - Oracle Database PL/SQL Packages and Types Reference to learn how to use dynamic SQL in
    the DBMS_SQL package

*** PL/SQL Collections and Records

Many programming techniques use collection types such as arrays, bags, lists, nested
tables, sets, and trees. To support these techniques in database applications, PL/SQL
provides the data types TABLE and VARRAY, which enable you to declare associative arrays,
nested tables, and variable-size arrays.

**** Collections

A collection is an ordered group of elements, all of the same type. Each element has a
unique subscript that determines its position in the collection. To create a collection,
you first define a collection type, and then declare a variable of that type.

Collections work like the arrays found in most third-generation programming
languages. Also, collections can be passed as parameters. So, you can use them to move
columns of data into and out of database tables or between client-side applications and
stored subprograms.

**** Records

A record is a composite variable that can store data values of different types, similar to
a struct type in C, C++, or Java. Records are useful for holding data from table rows, or
certain columns from table rows.

Suppose you have data about an employee such as name, salary, and hire date. These items
are dissimilar in type but logically related. A record containing a field for each item
lets you treat the data as a logical unit.

You can use the %ROWTYPE attribute to declare a record that represents a table row or row
fetched from a cursor. With user-defined records, you can declare your own fields.

See Also:

  - Oracle Database PL/SQL Language Reference for detailed information on using
    collections and records

*** How PL/SQL Runs

PL/SQL supports both native execution and interpreted execution. In interpreted execution,
PL/SQL source code is compiled into a so-called bytecode representation, which is run by a
portable virtual computer implemented as part of Oracle Database. In native execution,
which offers the best performance on computationally intensive program units, the source
code of PL/SQL program units is compiled directly to object code for the given
platform. This object code is linked into Oracle Database.

The PL/SQL engine is the tool used to define, compile, and run PL/SQL program units. This
engine is a special component of many Oracle products, including Oracle Database. While
many Oracle products have PL/SQL components, this section specifically covers the program
units that can be stored in Oracle Database and processed using Oracle Database PL/SQL
engine. The PL/SQL capabilities of each Oracle tool are described in the documentation for
this tool.

./oracle-concepts-figure-plsql-engine.png

The program unit is stored in a database. When an application calls a stored procedure,
the database loads the compiled program unit into the shared pool in the system global
area (SGA) (see "Shared Pool" on page 14-15). The PL/SQL and SQL statement executors work
together to process the statements in the procedure.

You can call a stored procedure from another PL/SQL block, which can be either an
anonymous block or another stored procedure. For example, you can call a stored procedure
from Oracle Forms.

A PL/SQL procedure executing on Oracle Database can call an external procedure or function
written in the C programming language and stored in a shared library. The C routine runs
in a separate address space from that of Oracle Database.

See Also:

  - Oracle Database PL/SQL Language Reference to learn about PL/SQL architecture

  - Oracle Database Advanced Application Developer's Guide to learn more about external
    procedures

** Overview of Java in Oracle Database

Java has emerged as the object-oriented programming language of choice. Java includes the
following features:

  - A Java Virtual Machine (JVM), which provides the basis for platform independence

  - Automated storage management techniques, such as garbage collection

  - Language syntax that borrows from C and enforces strong typing

The database provides Java programs with a dynamic data-processing engine that supports
complex queries and multiple views of data. Client requests are assembled as data queries
for immediate processing. Query results are generated dynamically.

The combination of Java and Oracle Database helps you create component-based,
network-centric applications that can be easily updated as business needs change. In
addition, you can move applications and data stores off the desktop and onto intelligent
networks and network-centric servers. More importantly, you can access these applications
and data stores from any client device.

Figure 8-4 shows a traditional two-tier, client/server configuration in which clients call
Java stored procedures in the same way that they call PL/SQL subprograms.

See Also:

  - Oracle Database 2 Day + Java Developer's Guide for an introduction to using Java with
    Oracle Database

*** Overview of the Java Virtual Machine (JVM)

A JVM is a virtual processor that runs compiled Java code. Java source code compiles to
low-level machine instructions, known as bytecodes, that are platform independent. The
Java bytecodes are interpreted through the JVM into platform-dependent actions.

**** Overview of Oracle JVM

Oracle JVM is a complete, Java2-compliant environment for running pure Java
applications. It is compatible with the JLS and the JVM specifications. It supports the
standard Java binary format and APIs. In addition, Oracle Database adheres to standard
Java language semantics, including dynamic class loading at run time.

./oracle-concepts-figure-java-layering.png illustrates how Oracle Java applications reside
 on top of the Java core class libraries, which reside on top of the Oracle JVM. Because
 the Oracle Java support system is located within the database, the JVM interacts with
 database libraries, instead of directly interacting with the operating system.

./oracle-concepts-figure-java-layering.png

Unlike other Java environments, Oracle JVM is embedded within Oracle Database. Some
important differences exist between Oracle JVM and typical client JVMs. For example, in a
standard Java environment, you run a Java application through the interpreter by issuing
the following command on the command line, where classname is the name of the class that
you want the JVM to interpret first:

  java classname

The preceding command causes the application to run within a process on your operating
system. However, if you are not using the command-line interface, then you must load the
application into the database, publish the interface, and then run the application within
a database data dictionary.

See Also:

  - See Oracle Database Java Developer's Guide for a description of other differences
    between the Oracle JVM and typical client JVMs

**** Main Components of Oracle JVM

Oracle JVM runs in the same process space and address space as the database kernel by
sharing its memory heaps and directly accessing its relational data. This design optimizes
memory use and increases throughput.

Oracle JVM provides a run-time environment for Java objects. It fully supports Java data
structures, method dispatch, exception handling, and language-level threads. It also
supports all the core Java class libraries, including java.lang, java.io, java.net,
java.math, and java.util.

./oracle-concepts-figure-jvm-components.png

Oracle JVM embeds the standard Java namespace in the database schemas. This feature lets
Java programs access Java objects stored in Oracle Database and application servers across
the enterprise.

In addition, Oracle JVM is tightly integrated with the scalable, shared memory
architecture of the database. Java programs use call, session, and object lifetimes
efficiently without user intervention. As a result, Oracle JVM and middle-tier Java
business objects can be scaled, even when they have session-long state.

See Also:

  - Oracle Database Java Developer's Guide for a description of the main components of
    Oracle JVM

*** Java Programming Environment

Oracle furnishes enterprise application developers with an end-to-end Java solution for
creating, deploying, and managing Java applications. The solution consists of client-side
and server-side programmatic interfaces, tools to support Java development, and a Java
Virtual Machine integrated with Oracle Database. All these products are compatible with
Java standards.

The Java programming environment consists of the following additional features:

  - Java stored procedures as the Java equivalent and companion for PL/SQL. Java stored
    procedures are tightly integrated with PL/SQL. You can call Java stored procedures
    from PL/SQL packages and procedures from Java stored procedures.

  - The JDBC and SQLJ programming interfaces for accessing SQL data.

  - Tools and scripts that assist in developing, loading, and managing classes.

**** Java Stored Procedures

A Java stored procedure is a Java method published to SQL and stored in the database. Like
a PL/SQL subprogram, a Java procedure can be invoked directly with products like SQL*Plus
or indirectly with a trigger. You can access it from any Oracle Net client -- OCI,
precompiler, or JDBC.

To publish Java methods, you write call specifications, which map Java method names,
parameter types, and return types to their SQL counterparts. When called by client
applications, a Java stored procedure can accept arguments, reference Java classes, and
return Java result values.

Applications call the Java method by referencing the name of the call
specification. The run-time system looks up the call specification definition in the
Oracle data dictionary and runs the corresponding Java method.

In addition, you can use Java to develop powerful programs independently of PL/SQL. Oracle
Database provides a fully compliant implementation of the Java programming language and
JVM.

See Also:

  - Oracle Database Java Developer's Guide explains how to write stored procedures in
    Java, how to access them from PL/SQL, and how to access PL/SQL functionality from Java

**** Java and PL/SQL Integration

You can call existing PL/SQL programs from Java and Java programs from PL/SQL. This
solution protects and leverages your PL/SQL and Java code.

Oracle Database offers two different approaches for accessing SQL data from Java, JDBC and
SQLJ. Both approaches are available on the client and server. As a result, you can deploy
applications on the client and server without modifying the code.

***** JDBC Drivers

JDBC is a database access protocol that enables you to connect to a database and run SQL
statements and queries to the database. The core Java class libraries provide only one
JDBC API, java.sql. However, JDBC is designed to enable vendors to supply drivers that
offer the necessary specialization for a particular database. Oracle provides the distinct
JDBC drivers shown in the following table.

Driver             Description

JDBC Thin Driver   You can use the JDBC Thin driver to write pure Java applications and   
                   applets that access Oracle SQL data. The JDBC Thin driver is especially
                   well-suited for Web-based applications and applets, because you can    
                   dynamically download it from a Web page, similar to any other Java     
                   applet.

JDBC OCI driver    The JDBC OCI driver accesses Oracle-specific native code, that is,     
                   non-Java code, and libraries on the client or middle tier, providing a 
                   performance boost compared to the JDBC Thin driver, at the cost of     
                   significantly larger size and client-side installation.

JDBC server-side   Oracle Database uses the server-side internal driver when the Java code  
internal driver    runs on the server. It allows Java applications running in Oracle JVM on 
                   the server to access locally defined data, that is, data on the same     
                   system and in the same process, with JDBC. It provides a performance     
                   boost, because of its ability to use the underlying Oracle RDBMS         
                   libraries directly, without the overhead of an intervening network       
                   connection between the Java code and SQL data. By supporting the same    
                   Java-SQL interface on the server, Oracle Database does not require you   
                   to rework code when deploying it.

See Also:

  - "ODBC and JDBC" on page 19-8

  - Oracle Database 2 Day + Java Developer's Guide and Oracle Database JDBC Developer's
    Guide

***** SQLJ

SQLJ is an ANSI standard for embedding SQL statements in Java programs. You can use SQLJ
in stored procedures, triggers, and methods within the Oracle Database environment. In
addition, you can combine SQLJ programs with JDBC.

SQLJ provides a simple, but powerful, way to develop client-side and middle-tier
applications that access databases from Java (see "SQLJ" on page 19-6). A developer writes
a program using SQLJ and then uses the SQLJ translator to translate embedded SQL to pure
JDBC-based Java code. At run time, the program can communicate with multi-vendor databases
using standard JDBC drivers.

The following example shows a simple SQLJ executable statement:

  String name;
  #sql { SELECT first_name INTO :name FROM employees WHERE employee_id=112 };
  System.out.println("Name is " + name + ", employee number = " + employee_id);

Because Oracle Database provides a complete Java environment, you cannot compile SQLJ
programs on a client that will run on the database. Instead, you can compile them directly
on the server.

See Also:

  - Oracle Database SQLJ Developer's Guide

** Overview of Triggers

A database trigger is a compiled stored program unit, written in either PL/SQL or Java,
that Oracle Database invokes ("fires") automatically whenever one of the following
operations occurs:

  - DML statements on a particular table or view, issued by any user

    DML statements modify data in schema objects. For example, inserting and deleting rows
    are DML operations.

  - DDL statements issued either by a particular user or any user

    DDL statements define schema objects. For example, creating a table and adding a
    column are DDL operations.

  - Database events

    User login or logoff, errors, and database startup or shutdown are events that can
    invoke triggers.

Triggers are schema objects that are similar to subprograms but differ in the way they are
invoked. A subprogram is explicitly run by a user, application, or trigger. Triggers are
implicitly invoked by the database when a triggering event occurs.

See Also:

  - "Overview of SQL Statements" on page 7-3 to learn about DML and DDL

  - "Overview of Instance Startup and Shutdown" on page 13-5

*** Advantages of Triggers

The correct use of triggers enables you to build and deploy applications that are more
robust and that use the database more effectively. You can use triggers to:

  - Automatically generate derived column values

  - Prevent invalid transactions

  - Provide auditing and event logging

  - Record information about table access

You can use triggers to enforce low-level business rules common for all client
applications. For example, several applications may access the employees table. If a
trigger on this table ensures the format of inserted data, then this business logic does
not need to be reproduced in every client. Because the trigger cannot be circumvented by
the application, the business logic in the trigger is used automatically.

You can use both triggers and integrity constraints to define and enforce any type of
integrity rule. However, Oracle strongly recommends that you only use triggers to enforce
complex business rules not definable using an integrity constraint

Excessive use of triggers can result in complex interdependencies that can be difficult to
maintain in a large application. For example, when a trigger is invoked, a SQL statement
within its trigger action potentially can fire other triggers, resulting in cascading
triggers that can produce unintended effects.

See Also:

  - Oracle Database 2 Day Developer's Guide and Oracle Database PL/SQL Language Reference
    for guidelines and restrictions when planning triggers for your application

*** Types of Triggers

Triggers can be categorized according to their means of invocation and the type of actions
they perform. Oracle Database supports the following types of triggers:

  - Row triggers

    A row trigger fires each time the table is affected by the triggering statement. For
    example, if a statement updates multiple rows, then a row trigger fires once for each
    row affected by the UPDATE. If a triggering statement affects no rows, then a row
    trigger is not run. Row triggers are useful if the code in the trigger action depends
    on data provided by the triggering statement or rows that are affected.

  - Statement triggers

    A statement trigger is fired once on behalf of the triggering statement, regardless of
    the number of rows affected by the triggering statement. For example, if a statement
    deletes 100 rows from a table, a statement-level DELETE trigger is fired only
    once. Statement triggers are useful if the code in the trigger action does not depend
    on the data provided by the triggering statement or the rows affected.

  - INSTEAD OF triggers

    An INSTEAD OF trigger is fired by Oracle Database instead of executing the triggering
    statement. These triggers are useful for transparently modifying views that cannot be
    modified directly through DML statements.

  - Event triggers

    You can use triggers to publish information about database events to
    subscribers. Event triggers are divided into the following categories:

    - A system event trigger can be caused by events such as database instance startup and
      shutdown or error messages.

    - A user event trigger is fired because of events related to user logon and logoff,
      DDL statements, and DML statements.

See Also:

  - Oracle Database 2 Day Developer's Guide

  - Oracle Database PL/SQL Language Reference

*** Timing for Triggers

You can define the trigger timingâ€”whether the trigger action is to be run before or after
the triggering statement. A simple trigger is a single trigger on a table that enables you
to specify actions for exactly one of the following timing points:

  - Before the firing statement

  - Before each row affected by the firing statement

  - After each row affected by the firing statement

  - After the firing statement

For statement and row triggers, a BEFORE trigger can enhance security and enable business
rules before making changes to the database. The AFTER trigger is ideal for logging
actions.

A compound trigger can fire at multiple timing points. Compound triggers help program an
approach in which the actions that you implement for various timing points share common
data.

See Also:

  - Oracle Database PL/SQL Language Reference to learn about compound triggers

*** Creation of Triggers

The CREATE TRIGGER statement creates or replaces a database trigger. A PL/SQL trigger has
the following general syntactic form:

  CREATE TRIGGER trigger_name
    triggering_statement
    [trigger_restriction]
  BEGIN
    triggered_action;
  END;

A PL/SQL trigger has the following basic components:

  - Trigger Name

    The name must be unique with respect to other triggers in the same schema. For
    example, the name may be part_reorder_trigger.

  - The trigger event or statement

    A triggering event or statement is the SQL statement, database event, or user event
    that causes a trigger to be invoked. For example, a user updates a table.

  - Trigger restriction

    A trigger restriction specifies a Boolean expression that must be true for the trigger
    to fire. For example, the trigger is not invoked unless the number of available parts
    is less than a present reorder amount.

  - Triggered action

    A triggered action is the procedure that contains the SQL statements and code to be
    run when a triggering statement is issued and the trigger restriction evaluates to
    true. For example, a user inserts a row into a pending orders table.

Suppose that you create the orders and lineitems tables as follows:

  CREATE TABLE orders
    ( order_id NUMBER PRIMARY KEY,
      /* other attributes */
      line_items_count NUMBER DEFAULT 0 );

  CREATE TABLE lineitems
    ( order_id REFERENCES orders,
      seq_no NUMBER,
      /* other attributes */
      CONSTRAINT lineitems PRIMARY KEY(order_id,seq_no) );

The orders table contains a row for each unique order, whereas the lineitems table
contains a row for each item in an order. Example 8-3 shows a sample trigger that
automatically updates the orders table with the number of items in an order.

  CREATE OR REPLACE TRIGGER lineitems_trigger
    AFTER INSERT OR UPDATE OR DELETE ON lineitems
    FOR EACH ROW
  BEGIN
    IF (INSERTING OR UPDATING) THEN
      UPDATE orders SET line_items_count = NVL(line_items_count,0)+1
      WHERE order_id = :new.order_id;
    END IF;
    IF (DELETING OR UPDATING) THEN
      UPDATE orders SET line_items_count = NVL(line_items_count,0)-1
      WHERE order_id = :old.order_id;
    END IF;
  END;
  /

In Example 8-3, the triggering statement is an INSERT, UPDATE, or DELETE on the lineitems
table. No triggering restriction exists. The trigger is invoked for each row changed. The
trigger has access to the old and new column values of the current row affected by the
triggering statement. Two correlation names exist for every column of the table being
modified: the old value (:old), and the new value (:new).

If rows in lineitems are inserted or updated for an order, then after the action the
trigger calculates the number of items in this order and updates the orders table with the
count. Table 8-2 illustrates a scenario in which a customer initiates two orders and adds
and removes line items from the orders.

Table 8-2 Row-Level Trigger Scenario

SQL Statement                             Triggered SQL Statement
----------------------------------------  ---------------------------------------
SQL> INSERT INTO orders (order_id) 
     VALUES (78);                  
                                   
1 row created.

The customer creates an order with ID 78. At this point the customer has no items in the
order.
                                      
Because no action is performed on the lineitems table, the trigger is not invoked.

----------------------------------------  ---------------------------------------

SQL> INSERT INTO orders (order_id) 
     VALUES (92);                  
                                   
1 row created.                     

The customer creates a separate order with ID 92. At this point the customer has no items
in the order.
                                      
Because no action is performed on the lineitems table, the trigger is not invoked.

----------------------------------------  ---------------------------------------

SQL> INSERT INTO lineitems                UPDATE orders                          
     (order_id, seq_no)                      SET line_items_count = NVL(NULL,0)+1
     VALUES (78,1);                        WHERE order_id = 78;                  
                      
1 row created.        

The customer adds an item to order 78.

The INSERT invokes the trigger. The triggered statement increases the line item count for
order 78 from 0 to 1.

----------------------------------------  ---------------------------------------

SQL> INSERT INTO lineitems                UPDATE orders                          
     (order_id, seq_no)                      SET line_items_count = NVL(NULL,0)+1
     VALUES (78,2);                        WHERE order_id = 78;                  
                           
1 row created.             

The customer adds an additional item to order 78.

The INSERT invokes the trigger. The triggered statement increases the line item count for
order 78 from 1 to 2.

----------------------------------------  ---------------------------------------

SQL> SELECT * FROM orders;
                          
 ORDER_ID LINE_ITEMS_COUNT
--------- ----------------
       78                2
       92                0

The customer queries the status of the two orders. Order 78 contains two items. Order 92
contains no items.

----------------------------------------  ---------------------------------------

SQL> SELECT * FROM lineitems;
  ORDER_ID     SEQ_NO        
---------- ----------        
        78          1        
        78          2        


The customer queries the status of the line items. Each item is uniquely identified by the
order ID and the sequence number.

----------------------------------------  ---------------------------------------

SQL> UPDATE lineitems                     UPDATE orders                          
     SET order_id = 92;                      SET line_items_count = NVL(NULL,0)+1
                                           WHERE order_id = 92;                  
2 rows updated.                                                                  
                                          UPDATE orders                          
                                             SET line_items_count = NVL(2,0)-1   
                                           WHERE order_id = 78;                  
                                                                                 
                                          UPDATE orders                          
                                             SET line_items_count = NVL(1,0)+1   
                                           WHERE order_id = 92;                  
                                                                                 
                                          UPDATE orders                          
                                             SET line_items_count = NVL(1,0)-1   
                                           WHERE order_id = 78;


The customer moves the line items that were in order 78 to order 92.

The UPDATE statement changes 2 rows in the lineitems tables, which invokes the trigger
once for each row.

Each time the trigger is invoked, both IF conditions in the trigger are met. The first
condition increments the count for order 92, whereas the second condition decreases the
count for order 78. Thus, four total UPDATE statements are run.

----------------------------------------  ---------------------------------------

SQL> SELECT * FROM orders;
                          
 ORDER_ID LINE_ITEMS_COUNT
--------- ----------------
       78                0
       92                2

The customer queries the status of the two orders. The net effect is that the line item
count for order 92 has increased from 0 to 2, whereas the count for order 78 has decreased
from 2 to 0.

----------------------------------------  ---------------------------------------

SQL> SELECT * FROM lineitems;
                             
  ORDER_ID     SEQ_NO        
---------- ----------        
        92          1        
        92          2

The customer queries the status of the line items. Each item is uniquely identified by the
order ID and the sequence number.

----------------------------------------  ---------------------------------------

SQL> DELETE FROM lineitems;               UPDATE orders                       
                                             SET line_items_count = NVL(2,0)-1
2 rows deleted.                            WHERE order_id = 92;               
                                                                              
                                          UPDATE orders                       
                                             SET line_items_count = NVL(1,0)-1
                                           WHERE order_id = 92;               

The customer now removes all line items from all orders.

The DELETE statement changes 2 rows in the lineitems tables, which invokes the trigger
once for each row. For each trigger invocation, only one IF condition in the trigger is
met. Each time the condition decreases the count for order 92 by 1. Thus, two total UPDATE
statements are run.

----------------------------------------  ---------------------------------------

SQL> SELECT * FROM orders;   
                             
 ORDER_ID LINE_ITEMS_COUNT   
--------- ----------------   
       78                0   
       92                0   
                             
SQL> SELECT * FROM lineitems;
                             
no rows selected             

The customer queries the status of the two orders. Neither order contains line items.

The customer also queries the status of the line items. No items exist.

----------------------------------------  ---------------------------------------

See Also:

  - Oracle Database 2 Day Developer's Guide and Oracle Database PL/SQL Language Reference
    to learn how to create triggers

  - Oracle Database PL/SQL Language Reference to learn about the CREATE TRIGGER command

*** Execution of Triggers

Oracle Database executes a trigger internally using the same steps as for subprogram
execution. The only subtle difference is that a user has the right to fire a trigger if he
or she has the privilege to run the triggering statement. With this exception, the
database validates and runs triggers the same way as stored subprograms.

See Also:

  - Oracle Database PL/SQL Language Reference to learn more about trigger execution

*** Storage of Triggers

Oracle Database stores PL/SQL triggers in compiled form in a database schema, just like
PL/SQL stored procedures. When a CREATE TRIGGER statement commits, the compiled PL/SQL
code is stored in the database and the source code of the PL/SQL trigger is removed from
the shared pool.

Figure 8-7 shows a database application with SQL statements that implicitly invoke PL/SQL
triggers. The triggers are stored separately from their associated tables.

Java triggers are stored in the same manner as PL/SQL triggers. However, a Java trigger
references Java code that was separately compiled with a CALL statement. Thus, creating a
Java trigger involves creating Java code and creating the trigger that references this
Java code.

See Also:

  - Oracle Database PL/SQL Language Reference to learn about compiling and storing
    triggers

* Part III Oracle Transaction Management

* Chapter 9: Data Concurrency and Consistency

This chapter explains how Oracle Database maintains consistent data in a multiuser
database environment. This chapter contains the following sections:

  - Introduction to Data Concurrency and Consistency

  - Overview of Oracle Database Transaction Isolation Levels

  - Overview of the Oracle Database Locking Mechanism

  - Overview of Automatic Locks

  - Overview of Manual Data Locks

  - Overview of User-Defined Locks

** Introduction to Data Concurrency and Consistency

In a single-user database, a user can modify data without concern for other users
modifying the same data at the same time. However, in a multiuser database, statements
within multiple simultaneous transactions can update the same data. Transactions executing
simultaneously must produce meaningful and consistent results. Therefore, a multiuser
database must provide the following:

  - Data concurrency, which ensures that users can access data at the same time

  - Data consistency, which ensures that each user sees a consistent view of the data,
    including visible changes made by the user's own transactions and committed
    transactions of other users

To describe consistent transaction behavior when transactions run concurrently, database
researchers have defined a transaction isolation model called serializability.  A
serializable transaction operates in an environment that makes it appear as if no other
users were modifying data in the database.

While this degree of isolation between transactions is generally desirable, running many
applications in serializable mode can seriously compromise application throughput.
Complete isolation of concurrently running transactions could mean that one transaction
cannot perform an insertion into a table being queried by another transaction. In short,
real-world considerations usually require a compromise between perfect transaction
isolation and performance.

Oracle Database maintains data consistency by using a multiversion consistency model and
various types of locks and transactions. In this way, the database can present a view of
data to multiple concurrent users, with each view consistent to a point in time. Because
different versions of data blocks can exist simultaneously, transactions can read the
version of data committed at the point in time required by a query and return results that
are consistent to a single point in time.

See Also:

  - Chapter 5, "Data Integrity" and Chapter 10, "Transactions"

*** Multiversion Read Consistency

In Oracle Database, multiversioning is the ability to simultaneously materialize multiple
versions of data. Oracle Database maintains multiversion read consistency, which means
that database queries have the following characteristics:

  - Read-consistent queries

    The data returned by a query is committed and consistent with respect to a single
    point in time.

    NB: Oracle Database never permits dirty reads, which occur when a transaction reads
        uncommitted data in another transaction.

    To illustrate the problem with dirty reads, suppose one transaction updates a column
    value without committing. A second transaction reads the updated and dirty
    (uncommitted) value. The first session rolls back the transaction so that the column
    has its old value, but the second transaction proceeds using the updated value,
    corrupting the database. Dirty reads compromise data integrity, violate foreign keys,
    and ignore unique constraints.

  - Nonblocking queries

    Readers and writers of data do not block one another (see "Summary of Locking
    Behavior" on page 9-12).

**** Statement-Level Read Consistency

Oracle Database always enforces statement-level read consistency, which guarantees that
data returned by a single query is committed and consistent with respect to a single point
in time. The point in time to which a single SQL statement is consistent depends on the
transaction isolation level and the nature of the query:

  - In the read committed isolation level, this point is the time at which the statement
    was opened. For example, if a SELECT statement opens at SCN 1000, then this statement
    is consistent to SCN 1000.

    NB: SCN == System Change Number.  A database ordering primitive. The value of an SCN
        is the logical point in time at which changes are made to a database.

  - In a serializable or read-only transaction this point is the time the transaction
    began. For example, if a transaction begins at SCN 1000, and if multiple SELECT
    statements occur in this transaction, then each statement is consistent to SCN 1000.

  - In a Flashback Query operation (SELECT ... AS OF), the SELECT statement explicitly
    specifies the point in time. For example, you can query a table as it appeared last
    Thursday at 2 p.m.

See Also:

  - Oracle Database Advanced Application Developer's Guide to learn about Flashback Query

**** Transaction-Level Read Consistency

Oracle Database can also provide read consistency to all queries in a transaction, known
as transaction-level read consistency. In this case, each statement in a transaction sees
data from the same point in time, which is the time at which the transaction began.

Queries made by a serializable transaction see changes made by the transaction itself. For
example, a transaction that updates employees and then queries employees will see the
updates. Transaction-level read consistency produces repeatable reads and does not expose
a query to phantom reads.

**** Read Consistency and Undo Segments

To manage the multiversion read consistency model, the database must create a
read-consistent set of data when a table is simultaneously queried and updated. Oracle
Database achieves this goal through undo data.

Whenever a user modifies data, Oracle Database creates undo entries, which it writes to
undo segments ("Undo Segments" on page 12-24). The undo segments contain the old values of
data that have been changed by uncommitted or recently committed transactions. Thus,
multiple versions of the same data, all at different points in time, can exist in the
database. The database can use snapshots of data at different points in time to provide
read-consistent views of the data and enable nonblocking queries.

Read consistency is guaranteed in single-instance and Oracle Real Application Clusters
(Oracle RAC) environments. Oracle RAC uses a cache-to-cache block transfer mechanism known
as Cache Fusion to transfer read-consistent images of data blocks from one database
instance to another.

See Also:

  - "Internal LOBs" on page 19-12 to learn about read consistency mechanisms for LOBs

  - Oracle Database 2 Day + Real Application Clusters Guide to learn about Cache Fusion

***** Read Consistency: Example

As the database retrieves data blocks on behalf of a query, the database ensures that the
data in each block reflects the contents of the block when the query began. The database
rolls back changes to the block as needed to reconstruct the block to the point in time
the query started processing.

The database uses a mechanism called an SCN to guarantee the order of transactions. As the
SELECT statement enters the execution phase, the database determines the SCN recorded at
the time the query began executing. In Figure 9-1, this SCN is 10023. The query only sees
committed data with respect to SCN 10023.

In Figure 9-1, blocks with SCNs after 10023 indicate changed data, as shown by the two
blocks with SCN 10024. The SELECT statement requires a version of the block that is
consistent with committed changes. The database copies current data blocks to a new buffer
and applies undo data to reconstruct previous versions of the blocks. These reconstructed
data blocks are called consistent read (CR) clones.

In Figure 9-1, the database creates two CR clones: one block consistent to SCN 10006 and
the other block consistent to SCN 10021. The database returns the reconstructed data for
the query. In this way, Oracle Database prevents dirty reads.

See Also:

  - "Database Buffer Cache" on page 14-9 and "System Change Numbers (SCNs)" on page 10-5

***** Read Consistency and Transaction Tables

The database uses a transaction table, also called an interested transaction list (ITL),
to determine if a transaction was uncommitted when the database began modifying the
block. The block header of every segment block contains a transaction table.

Entries in the transaction table describe which transactions have rows locked and which
rows in the block contain committed and uncommitted changes. The transaction table points
to the undo segment, which provides information about the timing of changes made to the
database.

In a sense, the block header contains a recent history of transactions that affected each
row in the block. The INITRANS parameter of the CREATE TABLE and ALTER TABLE statements
controls the amount of transaction history that is kept.

See Also:

  - Oracle Database SQL Language Reference to learn about the INITRANS parameter

*** Locking Mechanisms

In general, multiuser databases use some form of data locking to solve the problems
associated with data concurrency, consistency, and integrity. Locks are mechanisms that
prevent destructive interaction between transactions accessing the same resource.

See Also:

  - "Overview of the Oracle Database Locking Mechanism" on page 9-11

*** ANSI/ISO Transaction Isolation Levels

The SQL standard, which has been adopted by both ANSI and ISO/IEC, defines four levels of
transaction isolation. These levels have differing degrees of impact on transaction
processing throughput.

These isolation levels are defined in terms of phenomena that must be prevented between
concurrently executing transactions. The preventable phenomena are:

  - Dirty reads

    A transaction reads data that has been written by another transaction that has not
    been committed yet.

  - Nonrepeatable (fuzzy) reads

    A transaction rereads data it has previously read and finds that another committed
    transaction has modified or deleted the data. For example, a user queries a row and
    then later queries the same row, only to discover that the data has changed.

  - Phantom reads

    A transaction reruns a query returning a set of rows that satisfies a search condition
    and finds that another committed transaction has inserted additional rows that satisfy
    the condition.

    For example, a transaction queries the number of employees. Five minutes later it
    performs the same query, but now the number has increased by one because another user
    inserted a record for a new hire. More data satisfies the query criteria than before,
    but unlike in a fuzzy read the previously read data is unchanged.

The SQL standard defines four levels of isolation in terms of the phenomena that a
transaction running at a particular isolation level is permitted to experience. Table 9-1
shows the levels.

Table 9-1   Preventable Read Phenomena by Isolation Level

Isolation Level     Dirty Read          Nonrepeatable Read  Phantom Read
------------------  ------------------  ------------------  ------------------

Read uncommitted    Possible            Possible            Possible

Read committed      Not Possible        Possible            Possible

Repeatable read     Not Possible        Not Possible        Possible

Serializable        Not Possible        Not Possible        Not Possible

Oracle Database offers the read committed (default) and serializable isolation
levels. Also, the database offers a read-only mode.

See Also:

  - "Overview of Oracle Database Transaction Isolation Levels" on page 9-6 to learn about
    read committed, serializable, and read-only isolation levels

  - Oracle Database SQL Language Reference for a discussion of Oracle Database conformance
    to SQL standards

** Overview of Oracle Database Transaction Isolation Levels

Table 9-1 (above) summarizes the ANSI standard for transaction isolation levels. The standard is
defined in terms of the phenomena that are either permitted or prevented for each
isolation level. Oracle Database provides the transaction isolation levels:

  - Read Committed Isolation Level

  - Serializable Isolation Level

  - Read-Only Isolation Level

See Also:

  - Oracle Database Advanced Application Developer's Guide to learn more about transaction
    isolation levels

  - Oracle Database SQL Language Reference and Oracle Database PL/SQL Language Reference
    to learn about SET TRANSACTION ISOLATION LEVEL

*** Read Committed Isolation Level

In the read committed isolation level, which is the default, every query executed by a
transaction sees only data committed before the queryâ€”not the transactionâ€”began. This
level of isolation is appropriate for database environments in which few transactions are
likely to conflict.

A query in a read committed transaction avoids reading data that commits while the query
is in progress. For example, if a query is halfway through a scan of a million-row table,
and if a different transaction commits an update to row 950,000, then the query does not
see this change when it reads row 950,000. However, because the database does not prevent
other transactions from modifying data read by a query, other transactions may change data
between query executions. Thus, a transaction that runs the same query twice may
experience fuzzy reads and phantoms.

**** Read Consistency in the Read Committed Isolation Level

A consistent result set is provided for every query, guaranteeing data consistency, with
no action by the user. An implicit query, such as a query implied by a WHERE clause in an
UPDATE statement, is guaranteed a consistent set of results. However, each statement in an
implicit query does not see the changes made by the DML statement itself, but sees the
data as it existed before changes were made.

If a SELECT list contains a PL/SQL function, then the database applies statement-level
read consistency at the statement level for SQL run within the PL/SQL function code,
rather than at the parent SQL level. For example, a function could access a table whose
data is changed and committed by another user. For each execution of the SELECT in the
function, a new read-consistent snapshot is established.

See Also:

  - "Subqueries and Implicit Queries" on page 7-7

**** Conflicting Writes in Read Committed Transactions

In a read committed transaction, a conflicting write occurs when the transaction attempts
to change a row updated by an uncommitted concurrent transaction, sometimes called a
blocking transaction. The read committed transaction waits for the blocking transaction to
end and release its row lock. The options are as follows:

  - If the blocking transaction rolls back, then the waiting transaction proceeds to
    change the previously locked row as if the other transaction never existed.

  - If the blocking transaction commits and releases its locks, then the waiting
    transaction proceeds with its intended update to the newly changed row.

Table 9-2 shows how transaction 1, which can be either serializable or read committed,
interacts with read committed transaction 2. Table 9-2 shows a classic situation known as
a lost update (see "Use of Locks" on page 9-12). The update made by transaction 1 is not
in the table even though transaction 1 committed it. Devising a strategy to handle lost
updates is an important part of application development.

Table 9-2 Conflicting Writes and Lost Updates in a READ COMMITTED Transaction

Session 1                               Session 2
--------------------------------------  --------------------------------------

SQL> SELECT last_name, salary      
     FROM employees                
     WHERE last_name               
     IN ('Banda','Greene','Hintz');
                                   
LAST_NAME         SALARY           
------------- ----------           
Banda               6200           
Greene              9500           

Session 1 queries the salaries for Banda, Greene, and Hintz. No employee named Hintz is
found.

--------------------------------------  --------------------------------------

SQL> UPDATE employees          
     SET salary = 7000         
     WHERE last_name = 'Banda';

Session 1 begins a transaction by updating the Banda salary. The default isolation level
for transaction 1 is READ COMMITTED.

--------------------------------------  --------------------------------------

                                        SQL> SET TRANSACTION           
                                        ISOLATION LEVEL READ COMMITTED;

Session 2 begins transaction 2 and sets the isolation level explicitly to READ COMMITTED.

--------------------------------------  --------------------------------------

                                        SQL> SELECT last_name, salary      
                                             FROM employees                
                                             WHERE last_name               
                                             IN ('Banda','Greene','Hintz');
                                                                           
                                        LAST_NAME         SALARY           
                                        ------------- ----------           
                                        Banda               6200           
                                        Greene              9500           

Transaction 2 queries the salaries for Banda, Greene, and Hintz. Oracle Database uses read
consistency to show the salary for Banda before the uncommitted update made by transaction
1.

--------------------------------------  --------------------------------------

                                        SQL> UPDATE employees           
                                             SET salary = 9900          
                                             WHERE last_name = 'Greene';

Transaction 2 updates the salary for Greene successfully because transaction 1 locked only
the Banda row (see "Row Locks (TX)" on page 9-18).

--------------------------------------  --------------------------------------

SQL> INSERT INTO employees          
     (employee_id, last_name, email,
      hire_date, job_id)            
     VALUES (210, 'Hintz', 'JHINTZ',
            SYSDATE, 'SH_CLERK');   

Transaction 1 inserts a row for employee Hintz, but does not commit.

--------------------------------------  --------------------------------------

                                        SQL> SELECT last_name, salary      
                                             FROM employees                
                                             WHERE last_name               
                                             IN ('Banda','Greene','Hintz');
                                                                           
                                        LAST_NAME         SALARY           
                                        ------------- ----------           
                                        Banda               6200           
                                        Greene              9900


Transaction 2 queries the salaries for employees Banda, Greene, and Hintz.

Transaction 2 sees its own update to the salary for Greene. Transaction 2 does not see the
uncommitted update to the salary for Banda or the insertion for Hintz made by transaction
1.

--------------------------------------  --------------------------------------

                                        SQL> UPDATE employees          
                                             SET salary = 6300         
                                             WHERE last_name = 'Banda';
                                                                       
                                        -- prompt does not return

Transaction 2 attempts to update the row for Banda, which is currently locked by
transaction 1, creating a conflicting write. Transaction 2 waits until transaction 1 ends.

--------------------------------------  --------------------------------------

SQL> COMMIT;

Transaction 1 commits its work, ending the transaction.

--------------------------------------  --------------------------------------

                                        1 row updated.
                                                      
                                        SQL>

The lock on the Banda row is now released, so transaction 2 proceeds with its update to
the salary for Banda.

--------------------------------------  --------------------------------------

                                        SQL> SELECT last_name, salary      
                                             FROM employees                
                                             WHERE last_name               
                                             IN ('Banda','Greene','Hintz');
                                                                           
                                        LAST_NAME         SALARY           
                                        ------------- ----------           
                                        Banda               6300           
                                        Greene              9900           
                                        Hintz

Transaction 2 queries the salaries for employees Banda, Greene, and Hintz. The Hintz
insert committed by transaction 1 is now visible to transaction 2. Transaction 2 sees its
own update to the Banda salary.

--------------------------------------  --------------------------------------

                                        COMMIT;

Transaction 2 commits its work, ending the transaction.

--------------------------------------  --------------------------------------

SQL> SELECT last_name, salary      
     FROM employees                
     WHERE last_name               
     IN ('Banda','Greene','Hintz');
                                   
LAST_NAME         SALARY           
------------- ----------           
Banda               6300           
Greene              9900           
Hintz

Session 1 queries the rows for Banda, Greene, and Hintz. The salary for Banda is 6300,
which is the update made by transaction 2. The update of Banda's salary to 7000 made by
transaction 1 is now "lost."

--------------------------------------  --------------------------------------

**** Serializable Isolation Level

In the serialization isolation level, a transaction sees only changes committed at the
time the transactionâ€”not the queryâ€”began and changes made by the transaction itself. A
serializable transaction operates in an environment that makes it appear as if no other
users were modifying data in the database.

Serializable isolation is suitable for environments:

  - With large databases and short transactions that update only a few rows

  - Where the chance that two concurrent transactions will modify the same rows is
    relatively low

  - Where relatively long-running transactions are primarily read only

In serializable isolation, the read consistency normally obtained at the statement level
extends to the entire transaction. Any row read by the transaction is assured to be the
same when reread. Any query is guaranteed to return the same results for the duration of
the transaction, so changes made by other transactions are not visible to the query
regardless of how long it has been running. Serializable transactions do not experience
dirty reads, fuzzy reads, or phantom reads.

Oracle Database permits a serializable transaction to modify a row only if changes to the
row made by other transactions were already committed when the serializable transaction
began. The database generates an error when a serializable transaction tries to update or
delete data changed by a different transaction that committed after the serializable
transaction began:

  ORA-08177: Cannot serialize access for this transaction

When a serializable transaction fails with the ORA-08177 error, an application can take
several actions, including the following:

  - Commit the work executed to that point

  - Execute additional (but different) statements, perhaps after rolling back to a
    savepoint established earlier in the transaction

  - Roll back the entire transaction

Table 9-3 shows how a serializable transaction interacts with other transactions. If the
serializable transaction does not try to change a row committed by another transaction
after the serializable transaction began, then a serialized access problem is avoided.

Table 9-3  Read Consistency and Serialized Access Problems in Serializable Transactions

Session 1                               Session 2
--------------------------------------  --------------------------------------

SQL> SELECT last_name, salary      
     FROM employees                
     WHERE last_name               
     IN ('Banda','Greene','Hintz');
                                   
                                   
LAST_NAME         SALARY           
------------- ----------           
Banda               6200           
Greene              9500

Session 1 queries the salaries for Banda, Greene, and Hintz. No employee named Hintz is found.

--------------------------------------  --------------------------------------

SQL> UPDATE employees          
     SET salary = 7000         
     WHERE last_name = 'Banda';

Session 1 begins transaction 1 by updating the Banda salary. The default isolation level
for is READ COMMITTED.

--------------------------------------  --------------------------------------

                                        SQL> SET TRANSACTION              
                                             ISOLATION LEVEL SERIALIZABLE;

Session 2 begins transaction 2 and sets it to the SERIALIZABLE isolation level.

--------------------------------------  --------------------------------------

                                        SQL> SELECT last_name, salary      
                                             FROM employees                
                                             WHERE last_name               
                                             IN ('Banda','Greene','Hintz');
                                                                           
                                        LAST_NAME         SALARY           
                                        ------------- ----------           
                                        Banda               6200           
                                        Greene              9500

Transaction 2 queries the salaries for Banda, Greene, and Hintz. Oracle Database uses read
consistency to show the salary for Banda before the uncommitted update made by transaction
1.

--------------------------------------  --------------------------------------

                                        SQL> UPDATE employees           
                                             SET salary = 9900          
                                             WHERE last_name = 'Greene';

Transaction 2 updates the Greene salary successfully because only the Banda row is locked.

--------------------------------------  --------------------------------------

SQL> INSERT INTO employees          
     (employee_id, last_name, email,
      hire_date, job_id)            
     VALUES (210, 'Hintz', 'JHINTZ',
             SYSDATE, 'SH_CLERK');

Transaction 1 inserts a row for employee Hintz.

--------------------------------------  --------------------------------------

SQL> COMMIT;

Transaction 1 commits its work, ending the transaction.

--------------------------------------  --------------------------------------

SQL> SELECT last_name, salary           SQL> SELECT last_name, salary   
     FROM employees                          FROM employees             
     WHERE last_name IN                      WHERE last_name IN         
     ('Banda','Greene','Hintz');             ('Banda','Greene','Hintz');
                                                                        
LAST_NAME         SALARY                LAST_NAME         SALARY        
------------- ----------                ------------- ----------        
Banda               7000                Banda               6200        
Greene              9500                Greene              9500        
Hintz                                   Hintz

Session 1 queries the salaries for employees Banda, Greene, and Hintz and sees changes
committed by transaction 1. Session 1 does not see the uncommitted Greene update made by
transaction 2.

Transaction 2 queries the salaries for employees Banda, Greene, and Hintz. Oracle Database
read consistency ensures that the Hintz insert and Banda update committed by transaction 1
are not visible to transaction 2. Transaction 2 sees its own update to the Greene salary.

--------------------------------------  --------------------------------------

                                        COMMIT;

Transaction 2 commits its work, ending the transaction.

--------------------------------------  --------------------------------------

SQL> SELECT last_name, salary           SQL> SELECT last_name, salary   
     FROM employees                          FROM employees             
     WHERE last_name IN                      WHERE last_name IN         
     ('Banda','Greene','Hintz');             ('Banda','Greene','Hintz');
                                                                        
LAST_NAME         SALARY                LAST_NAME         SALARY        
------------- ----------                ------------- ----------        
Banda               7000                Banda               7000        
Greene              9900                Greene              9500        
Hintz                                   Hintz

Both sessions query the salaries for Banda, Greene, and Hintz. Each session sees all
committed changes made by transaction 1 and transaction 2.

--------------------------------------  --------------------------------------

SQL> UPDATE employees
     SET salary = 7100
     WHERE last_name = 'Hintz';

Session 1 begins transaction 3 by updating the Hintz salary. The default isolation level
for transaction 3 is READ COMMITTED.

--------------------------------------  --------------------------------------

                                        SQL> SET TRANSACTION              
                                             ISOLATION LEVEL SERIALIZABLE;

Session 2 begins transaction 4 and sets it to the SERIALIZABLE isolation level.

--------------------------------------  --------------------------------------

                                        SQL> UPDATE employees          
                                             SET salary = 7200         
                                             WHERE last_name = 'Hintz';

                                        -- prompt does not return

Transaction 4 attempts to update the salary for Hintz, but is blocked because transaction
3 locked the Hintz row (see "Row Locks (TX)" on page 9-18). Transaction 4 queues behind
transaction 3.

--------------------------------------  --------------------------------------

SQL> COMMIT;

Transaction 3 commits its update of the Hintz salary, ending the transaction.

--------------------------------------  --------------------------------------

                                        SQL> UPDATE employees          
                                             SET salary = 7200         
                                             WHERE last_name = 'Hintz';

                                        *                                
                                        ERROR at line 1:                 
                                        ORA-08177: can't serialize access
                                        for this transaction

The commit that ends transaction 3 causes the Hintz update in transaction 4 to fail with
the ORA-08177 error. The problem error occurs because transaction 3 committed the Hintz
update after transaction 4 began.

--------------------------------------  --------------------------------------

                                        SQL> ROLLBACK;

Session 2 rolls back transaction 4, which ends the transaction.

--------------------------------------  --------------------------------------

                                        SQL> SET TRANSACTION              
                                             ISOLATION LEVEL SERIALIZABLE;

Session 2 begins transaction 5 and sets it to the SERIALIZABLE isolation level.

--------------------------------------  --------------------------------------

                                        SQL> SELECT last_name, salary      
                                             FROM employees                
                                             WHERE last_name               
                                             IN ('Banda','Greene','Hintz');
                                                                           
                                        LAST_NAME         SALARY           
                                        ------------- ----------           
                                        Banda               7100           
                                        Greene              9500           
                                        Hintz               7100

Transaction 5 queries the salaries for Banda, Greene, and Hintz. The Hintz salary update
committed by transaction 3 is visible.

--------------------------------------  --------------------------------------

                                        SQL> UPDATE employees          
                                             SET salary = 7200         
                                             WHERE last_name = 'Hintz';
                                                                       
                                        1 row updated.

Transaction 5 updates the Hintz salary to a different value. Because the Hintz update made
by transaction 3 committed before the start of transaction 5, the serialized access
problem is avoided.

Note: If a different transaction updated and committed the Hintz row after transaction
transaction 5 began, then the serialized access problem would occur again.

--------------------------------------  --------------------------------------

                                        SQL> COMMIT;

Session 2 commits the update without any problems, ending the transaction.

--------------------------------------  --------------------------------------

See Also:

  - "Overview of Transaction Control" on page 10-6

**** Read-Only Isolation Level

The read-only isolation level is similar to the serializable isolation level, but
read-only transactions do not permit data to be modified in the transaction unless the
user is SYS. Thus, read-only transactions are not susceptible to the ORA-08177
error. Read-only transactions are useful for generating reports in which the contents must
be consistent with respect to the time when the transaction began.

Oracle Database achieves read consistency by reconstructing data as needed from the undo
segments. Because undo segments are used in a circular fashion, the database can overwrite
undo data. Long-running reports run the risk that undo data required for read consistency
may have been reused by a different transaction, raising a snapshot too old error. Setting
an undo retention period, which is the minimum amount of time that the database attempts
to retain old undo data before overwriting it, appropriately avoids this problem.

See Also:

  - "Undo Segments" on page 12-24

  - Oracle Database Administrator's Guide to learn how to set the undo retention period

** Overview of the Oracle Database Locking Mechanism

A lock is a mechanism that prevents destructive interactions, which are interactions that
incorrectly update data or incorrectly alter underlying data structures, between
transactions accessing shared data. Locks play a crucial role in maintaining database
concurrency and consistency.

*** Summary of Locking Behavior

The database maintains several different types of locks, depending on the operation that
acquired the lock. In general, the database uses two types of locks: exclusive locks and
share locks. Only one exclusive lock can be obtained on a resource such as a row or a
table, but many share locks can be obtained on a single resource.

Locks affect the interaction of readers and writers. A reader is a query of a resource,
whereas a writer is a statement modifying a resource. The following rules summarize the
locking behavior of Oracle Database for readers and writers:


  - A row is locked only when modified by a writer.

    When a statement updates one row, the transaction acquires a lock for this row
    only. By locking table data at the row level, the database minimizes contention for
    the same data. Under normal circumstances (1) the database does not escalate a row lock
    to the block or table level.

    NB (1): When processing a distributed two-phase commit, the database may briefly
            prevent read access in special circumstances. Specifically, if a query starts
            between the prepare and commit phases and attempts to read the data before the
            commit, then the database may escalate a lock from row-level to block-level to
            guarantee read consistency.

  - A writer of a row blocks a concurrent writer of the same row.

    If one transaction is modifying a row, then a row lock prevents a different
    transaction from modifying the same row simultaneously.

  - A reader never blocks a writer.

    Because a reader of a row does not lock it, a writer can modify this row. The only
    exception is a SELECT ... FOR UPDATE statement, which is a special type of SELECT
    statement that does lock the row that it is reading.

  - A writer never blocks a reader.

    When a row is being changed by a writer, the database uses undo data data to provide
    readers with a consistent view of the row.

    NB: Readers of data may have to wait for writers of the same data blocks in very
        special cases of pending distributed transactions.

See Also:

  - Oracle Database SQL Language Reference to learn about SELECT ... FOR UPDATE

  - Oracle Database Administrator's Guide to learn about waits associated with in-doubt
    distributed transactions

*** Use of Locks

In a single-user database, locks are not necessary because only one user is modifying
information. However, when multiple users are accessing and modifying data, the database
must provide a way to prevent concurrent modification of the same data. Locks achieve the
following important database requirements:

  - Consistency

    The data a session is viewing or changing must not be changed by other sessions until
    the user is finished.

  - Integrity

    The data and structures must reflect all changes made to them in the correct sequence.

Oracle Database provides data concurrency, consistency, and integrity among transactions
through its locking mechanisms. Locking is performed automatically and requires no user
action.

The need for locks can be illustrated by a concurrent update of a single row. In the
following example, a simple web-based application presents the end user with an employee
email and phone number. The application uses an UPDATE statement such as the following to
modify the data:

  UPDATE employees
     SET email = ?, phone_number = ?
   WHERE employee_id = ?
     AND email = ?
     AND phone_number = ?

In the preceding UPDATE statement, the email and phone number values in the WHERE clause
are the original, unmodified values for the specified employee. This update ensures that
the row that the application modifies was not changed after the application last read and
displayed it to the user. In this way, the application avoids the lost update database
problem in which one user overwrites changes made by another user, effectively losing the
update by the second user (Table 9-2 on page 9-7 shows an example of a lost update).

Table 9-4 shows the sequence of events when two sessions attempt to modify the same row in
the employees table at roughly the same time.

Table 9-4  Row Locking Example

Time Session 1                               Session 2
---- --------------------------------------  --------------------------------------
t0   SELECT employee_id, email, phone_number
       FROM hr.employees                    
      WHERE last_name = 'Himuro';           
                                            
     EMPLOYEE_ID EMAIL   PHONE_NUMBER       
     ----------- ------- ------------       
             118 GHIMURO 515.127.4565       

In session 1, the hr1 user queries hr.employees for the Himuro record and displays the
employee_id (118), email (GHIMURO), and phone number (515.127.4565) attributes.

---- --------------------------------------  --------------------------------------
t1                                           SELECT employee_id, email, phone_number
                                               FROM hr.employees                    
                                              WHERE last_name = 'Himuro';           
                                                                                    
                                             EMPLOYEE_ID EMAIL   PHONE_NUMBER       
                                             ----------- ------- ------------       
                                                     118 GHIMURO 515.127.4565

In session 2, the hr2 user queries hr.employees for the Himuro record and displays the
same attributes seen by user hr1.

---- --------------------------------------  --------------------------------------
t2   UPDATE hr.employees                
        SET phone_number='515.555.1234' 
      WHERE employee_id=118             
        AND email='GHIMURO'             
        AND phone_number='515.127.4565';
                                        
     1 row updated.

In session 1, the hr1 user updates the phone number in the row to 515.555.1234, which
acquires a lock on the GHIMURO row.

---- --------------------------------------  --------------------------------------
t3                                           UPDATE hr.employees                
                                                SET phone_number='515.555.1235' 
                                              WHERE employee_id=118             
                                                AND email='GHIMURO'             
                                                AND phone_number='515.127.4565';
                                                                                
                                             -- SQL*Plus does not show          
                                             -- a row updated message or        
                                             -- return the prompt.

In session 2, the hr2 user attempts to update the same row, but is blocked because hr1 is
currently processing the row.

The attempted update by hr2 occurs almost simultaneously with the hr1 update.

---- --------------------------------------  --------------------------------------
t4   SQL> COMMIT;

     Commit complete.

In session 1, the hr1 user commits the transaction.

The commit makes the change for Himuro permanent and unblocks session 2, which has been
waiting.

---- --------------------------------------  --------------------------------------
t5                                           0 rows updated.

In session 2, the hr2 user discovers that the GHIMURO row was modified in such a way that
it no longer matches its predicate.

Because the predicates do not match, session 2 updates no records.

---- --------------------------------------  --------------------------------------
t6   UPDATE hr.employees                
        SET phone_number='515.555.1235' 
      WHERE employee_id=118             
        AND email='GHIMURO'             
        AND phone_number='515.555.1234';

In session 1, the hr1 user realizes that it updated the GHIMURO row with the wrong phone
number. The user starts a new transaction and updates the phone number in the row to
515.555.1235, which locks the GHIMURO row.

---- --------------------------------------  --------------------------------------
t7                                           SELECT employee_id, email, phone_number
                                               FROM hr.employees                    
                                              WHERE last_name = 'Himuro';           
                                                                                    
                                             EMPLOYEE_ID EMAIL   PHONE_NUMBER       
                                             ----------- ------- ------------       
                                                     118 GHIMURO 515.555.1234

In session 2, the hr2 user queries hr.employees for the Himuro record. The record shows
the phone number update committed by session 1 at t4. Oracle Database read consistency
ensures that session 2 does not see the uncommitted change made at t6.

---- --------------------------------------  --------------------------------------
t8                                           UPDATE hr.employees                
                                                SET phone_number='515.555.1235' 
                                              WHERE employee_id=118             
                                                AND email='GHIMURO'             
                                                AND phone_number='515.555.1234';

                                             -- SQL*Plus does not show  
                                             -- a row updated message or
                                             -- return the prompt.

In session 2, the hr2 user attempts to update the same row, but is blocked because hr1 is
currently processing the row.

---- --------------------------------------  --------------------------------------
t9   ROLLBACK;

     Rollback complete.

In session 1, the hr1 user rolls back the transaction, which ends it.

---- --------------------------------------  --------------------------------------
t10                                          1 row updated.

In session 2, the update of the phone number succeeds because the session 1 update was
rolled back. The GHIMURO row matches its predicate, so the update succeeds.

---- --------------------------------------  --------------------------------------
t11                                          COMMIT;

                                             Commit complete.

Session 2 commits the update, ending the transaction.

---- --------------------------------------  --------------------------------------

Oracle Database automatically obtains necessary locks when executing SQL statements. For
example, before the database permits a session to modify data, the session must first lock
the data. The lock gives the session exclusive control over the data so that no other
transaction can modify the locked data until the lock is released.

Because the locking mechanisms of Oracle Database are tied closely to transaction control,
application designers need only define transactions properly, and Oracle Database
automatically manages locking. Users never need to lock any resource explicitly, although
Oracle Database also enables users to lock data manually.

The following sections explain concepts that are important for understanding how Oracle
Database achieves data concurrency.

See Also:

  - Oracle Database PL/SQL Packages and Types Reference to learn about the OWA_OPT_LOCK
    package, which contains subprograms that can help prevent lost updates

*** Lock Modes

Oracle Database automatically uses the lowest applicable level of restrictiveness to
provide the highest degree of data concurrency yet also provide fail-safe data
integrity. The less restrictive the level, the more available the data is for access by
other users. Conversely, the more restrictive the level, the more limited other
transactions are in the types of locks that they can acquire.

Oracle Database uses two modes of locking in a multiuser database:

  - Exclusive lock mode

    This mode prevents the associated resource from being shared. A transaction obtains an
    exclusive lock when it modifies data. The first transaction to lock a resource
    exclusively is the only transaction that can alter the resource until the exclusive
    lock is released.

  - Share lock mode

    This mode allows the associated resource to be shared, depending on the operations
    involved. Multiple users reading data can share the data, holding share locks to
    prevent concurrent access by a writer who needs an exclusive lock. Several
    transactions can acquire share locks on the same resource.

Assume that a transaction uses a SELECT ... FOR UPDATE statement to select a single table
row. The transaction acquires an exclusive row lock and a row share table lock. The row
lock allows other sessions to modify any rows other than the locked row, while the table
lock prevents sessions from altering the structure of the table. Thus, the database
permits as many statements as possible to execute.

*** Lock Conversion and Escalation

Oracle Database performs lock conversion as necessary. In lock conversion, the database
automatically converts a table lock of lower restrictiveness to one of higher
restrictiveness.

For example, suppose a transaction issues a SELECT ... FOR UPDATE for an employee and
later updates the locked row. In this case, the database automatically converts the row
share table lock to a row exclusive table lock. A transaction holds exclusive row locks
for all rows inserted, updated, or deleted within the transaction. Because row locks are
acquired at the highest degree of restrictiveness, no lock conversion is required or
performed.

Lock conversion is different from lock escalation, which occurs when numerous locks are
held at one level of granularity (for example, rows) and a database raises the locks to a
higher level of granularity (for example, table). If a user locks many rows in a table,
then some databases automatically escalate the row locks to a single table. The number of
locks decreases, but the restrictiveness of what is locked increases.

Oracle Database never escalates locks. Lock escalation greatly increases the likelihood of
deadlocks. Assume that a system is trying to escalate locks on behalf of transaction 1 but
cannot because of the locks held by transaction 2. A deadlock is created if transaction 2
also requires lock escalation of the same data before it can proceed.

*** Lock Duration

Oracle Database automatically releases a lock when some event occurs so that the
transaction no longer requires the resource. In most cases, the database holds locks
acquired by statements within a transaction for the duration of the transaction. These
locks prevent destructive interference such as dirty reads, lost updates, and destructive
DDL from concurrent transactions.

  NB: A table lock taken on a child table because of an unindexed foreign key is held for
      the duration of the statement, not the transaction. Also, as explained in "Overview
      of User-Defined Locks" on page 9-27, the DBMS_LOCK package enables user-defined
      locks to be released and allocated at will and even held over transaction
      boundaries.

Oracle Database releases all locks acquired by the statements within a transaction when it
commits or rolls back. Oracle Database also releases locks acquired after a savepoint when
rolling back to the savepoint. However, only transactions not waiting for the previously
locked resources can acquire locks on the now available resources. Waiting transactions
continue to wait until after the original transaction commits or rolls back completely
(see Table 10-2 on page 10-9 for an example).

See Also:

  - "Rollback to Savepoint" on page 10-8

*** Locks and Deadlocks

A deadlock is a situation in which two or more users are waiting for data locked by each
other. Deadlocks prevent some transactions from continuing to work.

Oracle Database automatically detects deadlocks and resolves them by rolling back one
statement involved in the deadlock, releasing one set of the conflicting row locks. The
database returns a corresponding message to the transaction that undergoes statement-level
rollback. The statement rolled back belongs to the transaction that detects the
deadlock. Usually, the signalled transaction should be rolled back explicitly, but it can
retry the rolled-back statement after waiting.

Table 9-5 Deadlock Example

Time Session 1                               Session 2
---- --------------------------------------  --------------------------------------
t0   SQL> UPDATE employees                   SQL> UPDATE employees          
             SET salary = salary*1.1                 SET salary = salary*1.1
           WHERE employee_id = 100;                WHERE employee_id = 200; 
                                                                            
     1 row updated.                          1 row updated.                 

Session 1 starts transaction 1 and updates the salary for employee 100. Session 2 starts
transaction 2 and updates the salary for employee 200. No problem exists because each
transaction locks only the row that it attempts to update.

---- --------------------------------------  --------------------------------------
t1   SQL> UPDATE employees                   SQL> UPDATE employees          
             SET salary = salary*1.1                 SET salary = salary*1.1
           WHERE employee_id = 200;                WHERE employee_id = 100; 
                                                                            
     -- prompt does not return               -- prompt does not return

Transaction 1 attempts to update the employee 200 row, which is currently locked by
transaction 2. Transaction 2 attempts to update the employee 100 row, which is currently
locked by transaction 1.

A deadlock results because neither transaction can obtain the resource it needs to proceed
or terminate. No matter how long each transaction waits, the conflicting locks are held.

---- --------------------------------------  --------------------------------------
t2   UPDATE employees                    
            *                            
                                         
     ERROR at line 1: ORA-00060: deadlock
     detected while waiting for resource 
                                         
     SQL>

Transaction 1 signals the deadlock and rolls back the UPDATE statement issued at
t1. However, the update made at t0 is not rolled back. The prompt is returned in session
1.

Note: Only one session in the deadlock actually gets the deadlock error, but either
session could get the error.

---- --------------------------------------  --------------------------------------
t3   SQL> COMMIT;

     Commit complete.

Session 1 commits the update made at t0, ending transaction 1. The update unsuccessfully
attempted at t1 is not committed.

---- --------------------------------------  --------------------------------------
t4                                           1 row updated.
                                                           
                                             SQL>

The update at t1 in transaction 2, which was being blocked by transaction 1, is
executed. The prompt is returned.

---- --------------------------------------  --------------------------------------
t5                                           SQL> COMMIT;    
                                                             
                                             Commit complete.

Session 2 commits the updates made at t0 and t1, which ends transaction 2.

---- --------------------------------------  --------------------------------------

Deadlocks most often occur when transactions explicitly override the default locking of
Oracle Database. Because Oracle Database does not escalate locks and does not use read
locks for queries, but does use row-level (rather than page-level) locking, deadlocks
occur infrequently.

See Also:

  - "Overview of Manual Data Locks" on page 9-26

  - Oracle Database Advanced Application Developer's Guide to learn how to handle
    deadlocks when you lock tables explicitly

** Overview of Automatic Locks

Oracle Database automatically locks a resource on behalf of a transaction to prevent other
transactions from doing something that requires exclusive access to the same resource. The
database automatically acquires different types of locks at different levels of
restrictiveness depending on the resource and the operation being performed.

  NB: The database never locks rows when performing simple reads.

Oracle Database locks are divided into the following categories:

Lock           Description
-------------- ----------------------------------------------------------------------
DML Locks      Protect data. For example, table locks lock entire tables, while row
               locks lock selected rows. See "DML Locks" on page 9-18.

DDL Locks      Protect the structure of schema objectsâ€”for example, the dictionary 
               definitions of tables and views. See "DDL Locks" on page 9-24.      

System Locks   Protect internal database structures such as data files. Latches,     
               mutexes, and internal locks are entirely automatic. See "System Locks"
               on page 9-25.

*** DML Locks

A DML lock, also called a data lock, guarantees the integrity of data accessed
concurrently by multiple users. For example, a DML lock prevents two customers from buying
the last copy of a book available from an online bookseller. DML locks prevent destructive
interference of simultaneous conflicting DML or DDL operations.

DML statements automatically acquire the following types of locks:

  - Row Locks (TX)

  -  TableLocks (TM)

In the following sections, the acronym in parentheses after each type of lock or lock mode
is the abbreviation used in the Locks Monitor of Oracle Enterprise Manager (Enterprise
Manager). Enterprise Manager might display TM for any table lock, rather than indicate the
mode of table lock (such as RS or SRX).

See Also:

  - "Oracle Enterprise Manager" on page 18-2

**** Row Locks (TX)

A row lock, also called a TX lock, is a lock on a single row of table. A transaction
acquires a row lock for each row modified by an INSERT, UPDATE, DELETE, MERGE, or SELECT
... FOR UPDATE statement. The row lock exists until the transaction commits or rolls back.

Row locks primarily serve as a queuing mechanism to prevent two transactions from
modifying the same row. The database always locks a modified row in exclusive mode so that
other transactions cannot modify the row until the transaction holding the lock commits or
rolls back. Row locking provides the finest grain locking possible and so provides the
best possible concurrency and throughput.

  NB: If a transaction terminates because of database instance failure, then block-level
      recovery makes a row available before the entire transaction is recovered.

If a transaction obtains a lock for a row, then the transaction also acquires a lock for
the table containing the row. The table lock prevents conflicting DDL operations that
would override data changes in a current transaction. Figure 9-2 illustrates an update of
the third row in a table. Oracle Database automatically places an exclusive lock on the
updated row and a subexclusive lock on the table.

***** Row Locks and Concurrency

Table 9-6 illustrates how Oracle Database uses row locks for concurrency. Three sessions
query the same rows simultaneously. Session 1 and 2 proceed to make uncommitted updates to
different rows, while session 3 makes no updates. Each session sees its own uncommitted
updates but not the uncommitted updates of any other session.

Time Session 1                   Session 2                   Session 3
---- --------------------------- --------------------------- ---------------------------
t0   SELECT employee_id, salary  SELECT employee_id, salary  SELECT employee_id, salary
       FROM employees              FROM employees              FROM employees          
       WHERE employee_id           WHERE employee_id           WHERE employee_id       
       IN(100,101);                IN(100,101);                IN(100,101);            
                                                                                       
     EMPLOYEE_ID SALARY          EMPLOYEE_ID SALARY          EMPLOYEE_ID SALARY        
     ----------- ------          ----------- ------          ----------- ------        
     100            512          100            512          100            512        
     101            600          101            600          101            600

Three different sessions simultaneously query the ID and salary of employees 100 and
101. The results returned by each query are identical.

---- --------------------------- --------------------------- ---------------------------
t1   UPDATE hr.employees      
        SET salary=salary+100 
        WHERE employee_id=100;

Session 1 updates the salary of employee 100, but does not commit. In the update, the
writer acquires a row-level lock for the updated row only, thereby preventing other
writers from modifying this row.

---- --------------------------- --------------------------- ---------------------------
t2   SELECT employee_id, salary  SELECT employee_id, salary  SELECT employee_id, salary
       FROM employees              FROM employees              FROM employees          
       WHERE employee_id           WHERE employee_id           WHERE employee_id       
       IN(100,101);                IN(100,101);                IN(100,101);            
                                                                                       
     EMPLOYEE_ID SALARY          EMPLOYEE_ID SALARY          EMPLOYEE_ID SALARY        
     ----------- ------          ----------- ------          ----------- ------        
     100            612          100            512          100            512        
     101            600          101            600          101            600        

Each session simultaneously issues the original query. Session 1 shows the salary of 612
resulting from the t1 update. The readers in session 2 and 3 return rows immediately and
do not wait for session 1 to end its transaction. The database uses multiversion read
consistency to show the salary as it existed before the update in session 1.

---- --------------------------- --------------------------- ---------------------------
t3                               UPDATE hr.employees      
                                    SET salary=salary+100 
                                    WHERE employee_id=101;

Session 2 updates the salary of employee 101, but does not commit the transaction. In the
update, the writer acquires a row-level lock for the updated row only, preventing other
writers from modifying this row.

---- --------------------------- --------------------------- ---------------------------
t4   SELECT employee_id, salary  SELECT employee_id, salary  SELECT employee_id, salary
       FROM employees              FROM employees              FROM employees          
       WHERE employee_id           WHERE employee_id           WHERE employee_id       
       IN(100,101);                IN(100,101);                IN(100,101);            
                                                                                       
     EMPLOYEE_ID SALARY          EMPLOYEE_ID SALARY          EMPLOYEE_ID SALARY        
     ----------- ------          ----------- ------          ----------- ------        
     100            612          100            512          100            512        
     101            600          101            700          101            600        

Each session simultaneously issues the original query. Session 1 shows the salary of 612
resulting from the t1 update, but not the salary update for employee 101 made in session
2. The reader in session 2 shows the salary update made in session 2, but not the salary
update made in session 1. The reader in session 3 uses read consistency to show the
salaries before modification by session 1 and 2.

---- --------------------------- --------------------------- ---------------------------

See Also:

  - Oracle Database SQL Language Reference

  - Oracle Database Reference to learn about V$LOCK

***** Storage of Row Locks

Unlike some databases, which use a lock manager to maintain a list of locks in memory,
Oracle Database stores lock information in the data block that contains the locked row.

The database uses a queuing mechanism for acquisition of row locks. If a transaction
requires a lock for an unlocked row, then the transaction places a lock in the data block.
Each row modified by this transaction points to a copy of the transaction ID stored in the
block header (see "Overview of Data Blocks" on page 12-6).

When a transaction ends, the transaction ID remains in the block header. If a different
transaction wants to modify a row, then it uses the transaction ID to determine whether
the lock is active. If the lock is active, then the session asks to be notified when the
lock is released. Otherwise, the transaction acquires the lock.

See Also:

  - Oracle Database Reference to learn about V$TRANSACTION

**** Table Locks (TM)

A table lock, also called a TM lock, is acquired by a transaction when a table is modified
by an INSERT, UPDATE, DELETE, MERGE, SELECT with the FOR UPDATE clause, or
LOCKTABLEstatement. DML operations require table locks to reserve DML access to the table
on behalf of a transaction and to prevent DDL operations that would conflict with the
transaction.

A table lock can be held in any of the following modes:

  - Row Share (RS)

    This lock, also called a subshare table lock (SS), indicates that the transaction
    holding the lock on the table has locked rows in the table and intends to update
    them. A row share lock is the least restrictive mode of table lock, offering the
    highest degree of concurrency for a table.

  - Row Exclusive Table Lock (RX)

    This lock, also called a subexclusive table lock (SX), generally indicates that the
    transaction holding the lock has updated table rows or issued SELECT ... FOR
    UPDATE. An SX lock allows other transactions to query, insert, update, delete, or lock
    rows concurrently in the same table. Therefore, SX locks allow multiple transactions
    to obtain simultaneous SX and subshare table locks for the same table.

  - Share Table Lock (S)

    A share table lock held by a transaction allows other transactions to query the table
    (without using SELECT ... FOR UPDATE), but updates are allowed only if a single
    transaction holds the share table lock. Because multiple transactions may hold a share
    table lock concurrently, holding this lock is not sufficient to ensure that a
    transaction can modify the table.

  - Share Row Exclusive Table Lock (SRX)

    This lock, also called a share-subexclusive table lock (SSX), is more restrictive than
    a share table lock. Only one transaction at a time can acquire an SSX lock on a given
    table. An SSX lock held by a transaction allows other transactions to query the table
    (except for SELECT ... FOR UPDATE) but not to update the table.

  - Exclusive Table Lock (X)

    This lock is the most restrictive, prohibiting other transactions from performing any
    type of DML statement or placing any type of lock on the table.

See Also:

  - Oracle Database SQL Language Reference

  - Oracle Database Advanced Application Developer's Guide to learn more about table locks

**** Locks and Foreign Keys

Oracle Database maximizes the concurrency control of parent keys in relation to dependent
foreign keys. Locking behavior depends on whether foreign key columns are indexed.  If
foreign keys are not indexed, then the child table will probably be locked more
frequently, deadlocks will occur, and concurrency will be decreased.  For this reason
foreign keys should almost always be indexed. The only exception is when the matching
unique or primary key is never updated or deleted.

***** Locks and Unindexed Foreign Keys

When both of the following conditions are true, the database acquires a full table lock on
the child table:

  - No index exists on the foreign key column of the child table.

  - A session modifies a primary key in the parent table (for example, deletes a row or
    modifies primary key attributes) or merges rows into the parent table. Inserts into
    the parent table do not acquire table locks on the child table.

Suppose that hr.departments table is a parent of hr.employees, which contains the
unindexed foreign key department_id. Figure 9-3 shows a session modifying the primary key
attributes of department 60 in the departments table.

In Figure 9-3, the database acquires a full table lock on employees during the primary key
modification of department 60. This lock enables other sessions to query but not update
the employees table. For example, employee phone numbers cannot be updated. The table lock
on employees releases immediately after the primary key modification on the departments
table completes. If multiple rows in departments undergo primary key modifications, then a
table lock on employees is obtained and released once for each row that is modified in
departments.

  NB: DML on a child table does not acquire a table lock on the parent table.

***** Locks and Indexed Foreign Keys

When both of the following conditions are true, the database does not acquire a full table
lock on the child table:

  - A foreign key column in the child table is indexed.

  - A session modifies a primary key in the parent table (for example, deletes a row or
    modifies primary key attributes) or merges rows into the parent table.

A lock on the parent table prevents transactions from acquiring exclusive table locks, but
does not prevent DML on the parent or child table during the primary key
modification. This situation is preferable if primary key modifications occur on the
parent table while updates occur on the child table.

If the child table specifies ON DELETE CASCADE, then deletions from the parent table can
result in deletions from the child table. For example, the deletion of department 280 can
cause the deletion of records from employees for employees in the deleted department. In
this case, waiting and locking rules are the same as if you deleted rows from the child
table after deleting rows from the parent table.

See Also:

  - "Foreign Key Constraints" on page 5-6

  - "Overview of Indexes" on page 3-1

*** DDL Locks

A data dictionary (DDL) lock protects the definition of a schema object while an ongoing
DDL operation acts on or refers to the object. Only individual schema objects that are
modified or referenced are locked during DDL operations. The database never locks the
whole data dictionary.

Oracle Database acquires a DDL lock automatically on behalf of any DDL transaction
requiring it. Users cannot explicitly request DDL locks. For example, if a user creates a
stored procedure, then Oracle Database automatically acquires DDL locks for all schema
objects referenced in the procedure definition. The DDL locks prevent these objects from
being altered or dropped before procedure compilation is complete.

**** Exclusive DDL Locks

An exclusive DDL lock prevents other sessions from obtaining a DDL or DML lock. Most DDL
operations, except for those described in "Share DDL Locks" on page 9-24, require
exclusive DDL locks for a resource to prevent destructive interference with other DDL
operations that might modify or reference the same schema object. For example, DROP TABLE
is not allowed to drop a table while ALTER TABLE is adding a column to it, and vice versa.

Exclusive DDL locks last for the duration of DDL statement execution and automatic
commit. During the acquisition of an exclusive DDL lock, if another DDL lock is held on
the schema object by another operation, then the acquisition waits until the older DDL
lock is released and then proceeds.

**** Share DDL Locks

A share DDL lock for a resource prevents destructive interference with conflicting DDL
operations, but allows data concurrency for similar DDL operations.

For example, when a CREATE PROCEDURE statement is run, the containing transaction acquires
share DDL locks for all referenced tables. Other transactions can concurrently create
procedures that reference the same tables and acquire concurrent share DDL locks on the
same tables, but no transaction can acquire an exclusive DDL lock on any referenced table.

A share DDL lock lasts for the duration of DDL statement execution and automatic
commit. Thus, a transaction holding a share DDL lock is guaranteed that the definition of
the referenced schema object remains constant during the transaction.

**** Breakable Parse Locks

A parse lock is held by a SQL statement or PL/SQL program unit for each schema object that
it references. Parse locks are acquired so that the associated shared SQL area can be
invalidated if a referenced object is altered or dropped. A parse lock is called a
breakable parse lock because it does not disallow any DDL operation and can be broken to
allow conflicting DDL operations.

A parse lock is acquired in the shared pool during the parse phase of SQL statement
execution. The lock is held as long as the shared SQL area for that statement remains in
the shared pool.

*** System Locks

Oracle Database uses various types of system locks to protect internal database and memory
structures. These mechanisms are inaccessible to users because users have no control over
their occurrence or duration.

**** Latches

Latches are simple, low-level serialization mechanisms that coordinate multiuser access to
shared data structures, objects, and files. Latches protect shared memory resources from
corruption when accessed by multiple processes. Specifically, latches protect data
structures from the following situations:

  - Concurrent modification by multiple sessions

  - Being read by one session while being modified by another session

  - Deallocation (aging out) of memory while being accessed

Typically, a single latch protects multiple objects in the SGA. For example, background
processes such as DBWn and LGWR allocate memory from the shared pool to create data
structures. To allocate this memory, these processes use a shared pool latch that
serializes access to prevent two processes from trying to inspect or modify the shared
pool simultaneously. After the memory is allocated, other processes may need to access
shared pool areas such as the library cache, which is required for parsing. In this case,
processes latch only the library cache, not the entire shared pool.

Unlike enqueue latches such as row locks, latches do not permit sessions to queue. When a
latch becomes available, the first session to request the latch obtains exclusive access
to it. Latch spinning occurs when a process repeatedly requests a latch in a loop, whereas
latch sleeping occurs when a process releases the CPU before renewing the latch request.

Typically, an Oracle process acquires a latch for an extremely short time while
manipulating or looking at a data structure. For example, while processing a salary update
of a single employee, the database may obtain and release thousands of latches. The
implementation of latches is operating system-dependent, especially in respect to whether
and how long a process waits for a latch.

An increase in latching means a decrease in concurrency. For example, excessive hard parse
operations create contention for the library cache latch. The V$LATCH view contains
detailed latch usage statistics for each latch, including the number of times each latch
was requested and waited for.

See Also:

  - "SQL Parsing" on page 7-16

  - Oracle Database Reference to learn about V$LATCH

  - Oracle Database Performance Tuning Guide to learn about wait event statistics

**** Mutexes

A mutual exclusion object (mutex) is a low-level mechanism that prevents an object in
memory from aging out or from being corrupted when accessed by concurrent processes. A
mutex is similar to a latch, but whereas a latch typically protects a group of objects, a
mutex protects a single object.

Mutexes provide several benefits:

  - A mutex can reduce the possibility of contention.

    Because a latch protects multiple objects, it can become a bottleneck when processes
    attempt to access any of these objects concurrently. By serializing access to an
    individual object rather than a group, a mutex increases availability.

  - A mutex consumes less memory than a latch.

  - When in shared mode, a mutex permits concurrent reference by multiple sessions.

**** Internal Locks

Internal locks are higher-level, more complex mechanisms than latches and mutexes and
serve various purposes. The database uses the following types of internal locks:

  - Dictionary cache locks

    These locks are of very short duration and are held on entries in dictionary caches
    while the entries are being modified or used. They guarantee that statements being
    parsed do not see inconsistent object definitions. Dictionary cache locks can be
    shared or exclusive. Shared locks are released when the parse is complete, whereas
    exclusive locks are released when the DDL operation is complete.

  - File and log management locks

    These locks protect various files. For example, an internal lock protects the control
    file so that only one process at a time can change it. Another lock coordinates the
    use and archiving of the online redo log files. Data files are locked to ensure that
    multiple instances mount a database in shared mode or that one instance mounts it in
    exclusive mode. Because file and log locks indicate the status of files, these locks
    are necessarily held for a long time.

  - Tablespace and undo segment locks

    These locks protect tablespaces and undo segments. For example, all instances
    accessing a database must agree on whether a tablespace is online or offline. Undo
    segments are locked so that only one database instance can write to a segment.

See Also:

  - "Data Dictionary Cache" on page 14-19

** Overview of Manual Data Locks

Oracle Database performs locking automatically to ensure data concurrency, data integrity,
and statement-level read consistency. However, you can manually override the Oracle
Database default locking mechanisms. Overriding the default locking is useful in
situations such as the following:

  - Applications require transaction-level read consistency or repeatable reads.

    In this case, queries must produce consistent data for the duration of the
    transaction, not reflecting changes by other transactions. You can achieve
    transaction-level read consistency by using explicit locking, read-only transactions,
    serializable transactions, or by overriding default locking.

  - Applications require that a transaction have exclusive access to a resource so that
    the transaction does not have to wait for other transactions to complete.

You can override Oracle Database automatic locking at the session or transaction level. At
the session level, a session can set the required transaction isolation level with the
ALTER SESSION statement. At the transaction level, transactions that include the following
SQL statements override Oracle Database default locking:

  - The SET TRANSACTION ISOLATION LEVEL statement

  - The LOCK TABLE statement (which locks either a table or, when used with views, the
    base tables)

  - The SELECT ... FOR UPDATE statement

Locks acquired by the preceding statements are released after the transaction ends or a
rollback to savepoint releases them.

If Oracle Database default locking is overridden at any level, then the database
administrator or application developer should ensure that the overriding locking
procedures operate correctly. The locking procedures must satisfy the following criteria:
data integrity is guaranteed, data concurrency is acceptable, and deadlocks are not
possible or are appropriately handled.

See Also:

  - Oracle Database SQL Language Reference for descriptions of LOCK TABLE and SELECT
    ... FOR UPDATE

  - Oracle Database Advanced Application Developer's Guide to learn how to manually lock
    tables

** Overview of User-Defined Locks

With Oracle Database Lock Management services, you can define your own locks for a
specific application. For example, you might create a lock to serialize access to a
message log on the file system. Because a reserved user lock is the same as an Oracle
Database lock, it has all the Oracle Database lock functionality including deadlock
detection. User locks never conflict with Oracle Database locks, because they are
identified with the prefix UL.

The Oracle Database Lock Management services are available through procedures in the
DBMS_LOCK package. You can include statements in PL/SQL blocks that:

  - Request a lock of a specific type

  - Give the lock a unique name recognizable in another procedure in the same or in
    another instance

  - Change the lock type

  - Release the lock

See Also:

  - Oracle Database Advanced Application Developer's Guide for more information about
    Oracle Database Lock Management services

  - Oracle Database PL/SQL Packages and Types Reference for information about DBMS_LOCK

* Chapter 10: Transactions

** Introduction to Transactions

A transaction is a logical, atomic unit of work that contains one or more SQL
statements. A transaction groups SQL statements so that they are either all committed,
which means they are applied to the database, or all rolled back, which means they are
undone from the database. Oracle Database assigns every transaction a unique identifier
called a transaction ID.

All Oracle transactions comply with the basic properties of a database transaction, known
as ACID properties. ACID is an acronym for the following:

  - Atomicity

    All tasks of a transaction are performed or none of them are. There are no partial
    transactions. For example, if a transaction starts updating 100 rows, but the system
    fails after 20 updates, then the database rolls back the changes to these 20 rows.

  - Consistency

    The transaction takes the database from one consistent state to another consistent
    state. For example, in a banking transaction that debits a savings account and credits
    a checking account, a failure must not cause the database to credit only one account,
    which would lead to inconsistent data.

  - Isolation

    The effect of a transaction is not visible to other transactions until the transaction
    is committed. For example, one user updating the hr.employees table does not see the
    uncommitted changes to employees made concurrently by another user. Thus, it appears
    to users as if transactions are executing serially.

  - Durability

    Changes made by committed transactions are permanent. After a transaction completes,
    the database ensures through its recovery mechanisms that changes from the transaction
    are not lost.

The use of transactions is one of the most important ways that a database management
system differs from a file system.

*** Structure of a Transaction

A database transaction consists of one or more statements. Specifically, a transaction
consists of one of the following:

  - One or more data manipulation language (DML) statements that together constitute an
    atomic change to the database

  - One data definition language (DDL) statement

A transaction has a beginning and an end.

See Also:

  - "Overview of SQL Statements" on page 7-3

**** Beginning of a Transaction

A transaction begins when the first executable SQL statement is encountered. An executable
SQL statement is a SQL statement that generates calls to a database instance, including
DML and DDL statements and the SET TRANSACTION statement.

When a transaction begins, Oracle Database assigns the transaction to an available undo
data segment to record the undo entries for the new transaction. A transaction ID is not
allocated until an undo segment and transaction table slot are allocated, which occurs
during the first DML statement. A transaction ID is unique to a transaction and represents
the undo segment number, slot, and sequence number.

The following example execute an UPDATE statement to begin a transaction and queries
V$TRANSACTION for details about the transaction:

  SQL> UPDATE hr.employees SET salary=salary;

  107 rows updated.

  SQL> SELECT XID AS "txn id", XIDUSN AS "undo seg", XIDSLOT AS "slot",
  2 XIDSQN AS "seq", STATUS AS "txn status"
  3 FROM V$TRANSACTION;

  txn id             undo seg       slot        seq txn status
  ---------------- ---------- ---------- ---------- ----------------
  0600060037000000          6          6         55 ACTIVE

See Also:

  - "Undo Segments" on page 12-24

**** End of a Transaction

A transaction ends when any of the following actions occurs:

  - A user issues a COMMIT or ROLLBACK statement without a SAVEPOINT clause.

    In a commit, a user explicitly or implicitly requested that the changes in the
    transaction be made permanent. Changes made by the transaction are permanent and
    visible to other users only after a transaction commits.

  - A user runs a DDL command such as CREATE, DROP, RENAME, or ALTER.

    The database issues an implicit COMMIT statement before and after every DDL statement.
    If the current transaction contains DML statements, then Oracle Database first commits
    the transaction and then runs and commits the DDL statement as a new, single-statement
    transaction.

  - A user exits normally from most Oracle Database utilities and tools, causing the
    current transaction to be implicitly committed. The commit behavior when a user
    disconnects is application-dependent and configurable.

    NB: Applications should always explicitly commit or undo transactions before program
        termination.

  - A client process terminates abnormally, causing the transaction to be implicitly
    rolled back using metadata stored in the transaction table and the undo segment.

After one transaction ends, the next executable SQL statement automatically starts the
following transaction. The following example executes an UPDATE to start a transaction,
ends the transaction with a ROLLBACK statement, and then executes an UPDATE to start a new
transaction (note that the transaction IDs are different):

  SQL> UPDATE hr.employees SET salary=salary;
  107 rows updated.

  SQL> SELECT XID, STATUS FROM V$TRANSACTION;
  XID              STATUS          
  ---------------- ----------------
  0800090033000000 ACTIVE

  SQL> ROLLBACK;
  Rollback complete.

  SQL> SELECT XID FROM V$TRANSACTION;
  no rows selected

  SQL> UPDATE hr.employees SET last_name=last_name;
  107 rows updated.

  SQL> SELECT XID, STATUS FROM V$TRANSACTION;
  XID              STATUS          
  ---------------- ----------------
  0900050033000000 ACTIVE

See Also:

  - "Tools for Database Administrators" on page 18-2 and "Tools for Database Developers"
    on page 19-1

  - Oracle Database SQL Language Reference to learn about COMMIT

*** Statement-Level Atomicity

Oracle Database supports statement-level atomicity, which means that a SQL statement is an
atomic unit of work and either completely succeeds or completely fails.

A successful statement is different from a committed transaction. A single SQL statement
executes successfully if the database parses and runs it without error as an atomic unit,
as when all rows are changed in a multirow update.

If a SQL statement causes an error during execution, then it is not successful and so all
effects of the statement are rolled back. This operation is a statement-level
rollback. This operation has the following characteristics:

  - A SQL statement that does not succeed causes the loss only of work it would have
    performed itself.

    The unsuccessful statement does not cause the loss of any work that preceded it in the
    current transaction. For example, if the execution of the second UPDATE statement in
    Figure 10-1 causes an error and is rolled back, then the work performed by the first
    UPDATE statement is not rolled back. The first UPDATE statement can be committed or
    rolled back explicitly by the user.

  - The effect of the rollback is as if the statement had never been run.

    Any side effects of an atomic statement, for example, triggers invoked upon execution
    of the statement, are considered part of the atomic statement. Either all work
    generated as part of the atomic statement succeeds or none does.

An example of an error causing a statement-level rollback is an attempt to insert a
duplicate primary key. Single SQL statements involved in a deadlock, which is competition
for the same data, can also cause a statement-level rollback. However, errors discovered
during SQL statement parsing, such as a syntax error, have not yet been run and so do not
cause a statement-level rollback.

See Also:

  - "SQL Parsing" on page 7-16

  - "Locks and Deadlocks" on page 9-16

  - "Overview of Triggers" on page 8-16

*** System Change Numbers (SCNs)

A system change number (SCN) is a logical, internal time stamp used by Oracle
Database. SCNs order events that occur within the database, which is necessary to satisfy
the ACID properties of a transaction. Oracle Database uses SCNs to mark the SCN before
which all changes are known to be on disk so that recovery avoids applying unnecessary
redo. The database also uses SCNs to mark the point at which no redo exists for a set of
data so that recovery can stop.

SCNs occur in a monotonically increasing sequence. Oracle Database can use an SCN like a
clock because an observed SCN indicates a logical point in time and repeated observations
return equal or greater values. If one event has a lower SCN than another event, then it
occurred at an earlier time with respect to the database. Several events may share the
same SCN, which means that they occurred at the same time with respect to the database.

Every transaction has an SCN. For example, if a transaction updates a row, then the
database records the SCN at which this update occurred. Other modifications in this
transaction have the same SCN. When a transaction commits, the database records an SCN for
this commit.

Oracle Database increments SCNs in the system global area (SGA). When a transaction
modifies data, the database writes a new SCN to the undo data segment assigned to the
transaction. The log writer process then writes the commit record of the transaction
immediately to the online redo log. The commit record has the unique SCN of the
transaction. Oracle Database also uses SCNs as part of its instance recovery and media
recovery mechanisms.

See Also:

  - "Overview of Instance Recovery" on page 13-12 and "Backup and Recovery" on page 18-9

** Overview of Transaction Control

Transaction control is the management of changes made by DML statements and the grouping
of DML statements into transactions. In general, application designers are concerned with
transaction control so that work is accomplished in logical units and data is kept
consistent.

Transaction control involves using the following statements, as described in "Transaction
Control Statements" on page 7-8:

  - The COMMIT statement ends the current transaction and makes all changes performed in
    the transaction permanent. COMMIT also erases all savepoints in the transaction and
    releases transaction locks.

  - The ROLLBACK statement reverses the work done in the current transaction; it causes
    all data changes since the last COMMIT or ROLLBACK to be discarded. The ROLLBACK TO
    SAVEPOINT statement undoes the changes since the last savepoint but does not end the
    entire transaction.

  - The SAVEPOINT statement identifies a point in a transaction to which you can later
    roll back.

Table 10-1  Transaction Control

Time Session                                  Explanation
---- ---------------------------------------- ----------------------------------------
t0   COMMIT;                                  This statement ends any existing
                                              transaction in the session.

---- ---------------------------------------- ----------------------------------------
t1   SET TRANSACTION NAME 'sal_update';       This statement begins a transaction and
                                              names it sal_update.
---- ---------------------------------------- ----------------------------------------
t2   UPDATE employees                         This statement updates the salary for
        SET salary = 7000                     Banda to 7000.
      WHERE last_name = 'Banda';
---- ---------------------------------------- ----------------------------------------
t3   SAVEPOINT after_banda_sal;               This statement creates a savepoint named 
                                              after_banda_sal, enabling changes in     
                                              this transaction to be rolled back to    
                                              this point.
---- ---------------------------------------- ----------------------------------------
t4   UPDATE employees                         Greene salary now 12000
        SET salary = 12000       
      WHERE last_name = 'Greene';
---- ---------------------------------------- ----------------------------------------
t5   SAVEPOINT after_greene_sal;              This statement creates a savepoint named
                                              after_greene_sal, enabling changes in   
                                              this transaction to be rolled back to   
                                              this point.
---- ---------------------------------------- ----------------------------------------
t6   ROLLBACK TO SAVEPOINT after_banda_sal;   This statement rolls back the           
                                              transaction to t3, undoing the update to
                                              Greene's salary at t4. The sal_update   
                                              transaction has not ended.
---- ---------------------------------------- ----------------------------------------
t7   UPDATE employees                         This statement updates the salary for
        SET salary = 11000                    Greene to 11000 in transaction       
      WHERE last_name = 'Greene';             sal_update.
---- ---------------------------------------- ----------------------------------------
t8   ROLLBACK;                                This statement rolls back all changes in
                                              transaction sal_update, ending the      
                                              transaction.
---- ---------------------------------------- ----------------------------------------
t9   SET TRANSACTION NAME 'sal_update2';      This statement begins a new transaction 
                                              in the session and names it sal_update2.
---- ---------------------------------------- ----------------------------------------
t10  UPDATE employees                         Banda salary 7050
        SET salary = 7050        
       WHERE last_name = 'Banda';
---- ---------------------------------------- ----------------------------------------
t11  UPDATE employees                         Greene salary 10950
        SET salary = 10950       
      WHERE last_name = 'Greene';
---- ---------------------------------------- ----------------------------------------
t12  COMMIT;                                  This statement commits all changes made 
                                              in transaction sal_update2, ending the  
                                              transaction. The commit guarantees that 
                                              the changes are saved in the online redo
                                              log files.                              
---- ---------------------------------------- ----------------------------------------

See Also:

  - Oracle Database SQL Language Reference to learn about transaction control statements

*** Transaction Names

A transaction name is an optional, user-specified tag that serves as a reminder of the
work that the transaction is performing. You name a transaction with the SET TRANSACTION
... NAME statement, which if used must be first statement of the transaction. In Table
10-1 on page 10-6, the first transaction was named sal_update and the second was named
sal_update2.

Transaction names provide the following advantages:

  - It is easier to monitor long-running transactions and to resolve in-doubt distributed
    transactions.

  - You can view transaction names along with transaction IDs in applications. For
    example, a database administrator can view transaction names in Oracle Enterprise
    Manager (Enterprise Manager) when monitoring system activity.

  - The database writes transaction names to the transaction auditing redo record, so you
    can use LogMiner to search for a specific transaction in the redo log.

  - You can use transaction names to find a specific transaction in data dictionary views
    such as V$TRANSACTION.

See Also:

  - "Oracle Enterprise Manager" on page 18-2

  - Oracle Database Reference to learn about V$TRANSACTION

  - Oracle Database SQL Language Reference to learn about SET TRANSACTION

*** Active Transactions

An active transaction has started but not yet committed or rolled back. In Table 10-1 on
page 10-6, the first statement to modify data in the sal_update transaction is the update
to Banda's salary. From the successful execution of this update until the ROLLBACK
statement ends the transaction, the sal_update transaction is active.

Data changes made by a transaction are temporary until the transaction is committed or
rolled back. Before the transaction ends, the state of the data is as follows:

  - Oracle Database has generated undo data information in the system global area (SGA).

    The undo data contains the old data values changed by the SQL statements of the
    transaction. See "Read Consistency in the Read Committed Isolation Level" on page 9-7.

  - Oracle Database has generated redo in the online redo log buffer of the SGA.

    The redo log record contains the change to the data block and the change to the undo
    block. See "Redo Log Buffer" on page 14-14.

  - Changes have been made to the database buffers of the SGA.

    The data changes for a committed transaction, stored in the database buffers of the
    SGA, are not necessarily written immediately to the data files by the database writer
    (DBWn). The disk write can happen before or after the commit. See "Database Buffer
    Cache" on page 14-9.

  - The rows affected by the data change are locked.

    Other users cannot change the data in the affected rows, nor can they see the
    uncommitted changes. See "Summary of Locking Behavior" on page 9-12.

*** Savepoints

A savepoint is a user-declared intermediate marker within the context of a
transaction. Internally, this marker resolves to an SCN. Savepoints divide a long
transaction into smaller parts.

If you use savepoints in a long transaction, then you have the option later of rolling
back work performed before the current point in the transaction but after a declared
savepoint within the transaction. Thus, if you make an error, you do not need to resubmit
every statement. Table 10-1 on page 10-6 creates savepoint after_banda_sal so that the
update to the Greene salary can be rolled back to this savepoint.

**** Rollback to Savepoint

A rollback to a savepoint in an uncommitted transaction means undoing any changes made
after the specified savepoint, but it does not mean a rollback of the transaction
itself. When a transaction is rolled back to a savepoint, as when the ROLLBACK TO
SAVEPOINT after_banda_sal is run in Table 10-1, the following occurs:

  - Oracle Database rolls back only the statements run after the savepoint.

    In Table 10-1, the ROLLBACK TO SAVEPOINT causes the UPDATE for Greene to be rolled
    back, but not the UPDATE for Banda.

  - Oracle Database preserves the savepoint specified in the ROLLBACK TO SAVEPOINT
    statement, but all subsequent savepoints are lost.

    In Table 10-1, the ROLLBACK TO SAVEPOINT causes the after_greene_sal savepoint to be
    lost.

  - Oracle Database releases all table and row locks acquired after the specified
    savepoint but retains all data locks acquired previous to the savepoint.

The transaction remains active and can be continued.

See Also:

  - Oracle Database SQL Language Reference to learn about the ROLLBACK and SAVEPOINT
    statements

  - Oracle Database PL/SQL Language Reference to learn about transaction processing and
    control

**** Enqueued Transactions

Depending on the scenario, transactions waiting for previously locked resources may still
be blocked after a rollback to savepoint. When a transaction is blocked by another
transaction it enqueues on the blocking transaction itself, so that the entire blocking
transaction must commit or roll back for the blocked transaction to continue.

In the scenario shown in Table 10-2, session 1 rolls back to a savepoint created before it
executed a DML statement. However, session 2 is still blocked because it is waiting for
the session 1 transaction to complete.

Time Session 1                   Session 2                   Session 3
---- --------------------------- --------------------------- ---------------------------
t0   UPDATE employees    
        SET salary = 7000
      WHERE last_name =  
            'Banda';     

Session 1 begins a transaction. The session places an exclusive lock on the Banda row (TX)
and a subexclusive table lock (SX) on the table.

---- --------------------------- --------------------------- ---------------------------
t1   SAVEPOINT after_banda_sal;

Session 1 creates a savepoint named after_banda_sal.

---- --------------------------- --------------------------- ---------------------------
t2   UPDATE employees    
        SET salary = 12000
      WHERE last_name =  
            'Greene';     

Session 1 locks the Greene row.

---- --------------------------- --------------------------- ---------------------------
t3                               UPDATE employees     
                                    SET salary = 14000
                                  WHERE last_name =   
                                        'Greene';     

Session 2 attempts to update the Greene row, but fails to acquire a lock because session 1
has a lock on this row. No transaction has begun in session 2.

---- --------------------------- --------------------------- ---------------------------
t4   ROLLBACK TO SAVEPOINT 
           after_banda_sal;

Session 1 rolls back the update to the salary for Greene, which releases the row lock for
Greene. The table lock acquired at t0 is not released.

At this point, session 2 is still blocked by session 1 because session 2 enqueues on the
session 1 transaction, which has not yet completed.

---- --------------------------- --------------------------- ---------------------------
t5                                                           UPDATE employees     
                                                                SET salary = 11000
                                                              WHERE last_name =   
                                                                    'Greene';

The Greene row is currently unlocked, so session 3 acquires a lock for an update to the
Greene row. This statement begins a transaction in session 3.

---- --------------------------- --------------------------- ---------------------------
t6   COMMIT;

Session 1 commits, ending its transaction. Session 2 is now enqueued for its update to the
Greene row behind the transaction in session 3.

---- --------------------------- --------------------------- ---------------------------

See Also:

  - "Lock Duration" on page 9-16 to learn more about when Oracle Database releases locks

*** Rollback of Transactions

A rollback of an uncommitted transaction undoes any changes to data that have been
performed by SQL statements within the transaction. After a transaction has been rolled
back, the effects of the work done in the transaction no longer exist.

In rolling back an entire transaction, without referencing any savepoints, Oracle Database
performs the following actions:

  - Undoes all changes made by all the SQL statements in the transaction by using the
    corresponding undo segments

    The transaction table entry for every active transaction contains a pointer to all the
    undo data (in reverse order of application) for the transaction. The database reads
    the data from the undo segment, reverses the operation, and then marks the undo entry
    as applied. Thus, if a transaction inserts a row, then a rollback deletes it. If a
    transaction updates a row, then a rollback reverses the update. If a transaction
    deletes a row, then a rollback reinserts it. In Table 10-1, the ROLLBACK reverses the
    updates to the salaries of Greene and Banda.

  - Releases all the locks of data held by the transaction

  - Erases all savepoints in the transaction

    In Table 10-1, the ROLLBACK deletes the savepoint after_banda_sal. The
    after_greene_sal savepoint was removed by the ROLLBACK TO SAVEPOINT statement.

  - Ends the transaction

    In Table 10-1, the ROLLBACK leaves the database in the same state as it was after the
    initial COMMIT was executed.

The duration of a rollback is a function of the amount of data modified.

See Also:

 - "Undo Segments" on page 12-24

*** Committing Transactions

A commit ends the current transaction and makes permanent all changes performed in the
transaction. In Table 10-1, a second transaction begins with sal_update2 and ends with an
explicit COMMIT statement. The changes that resulted from the two UPDATE statements are
now made permanent.

When a transaction commits, the following actions occur:

  - A system change number (SCN) is generated for the COMMIT.

    The internal transaction table for the associated undo tablespace records that the
    transaction has committed. The corresponding unique SCN of the transaction is assigned
    and recorded in the transaction table. See "Serializable Isolation Level" on page 9-8.

  - The log writer (LGWR) process writes remaining redo log entries in the redo log
    buffers to the online redo log and writes the transaction SCN to the online redo
    log.

    NB: This atomic event constitutes the commit of the transaction.

  - Oracle Database releases locks held on rows and tables.

    Users who were enqueued waiting on locks held by the uncommitted transaction are
    allowed to proceed with their work.

  - Oracle Database deletes savepoints.

    In Table 10-1, no savepoints existed in the sal_update transaction so no savepoints
    were erased.

  - Oracle Database performs a commit cleanout.

    If modified blocks containing data from the committed transaction are still in the
    SGA, and if no other session is modifying them, then the database removes lock-related
    transaction information from the blocks. Ideally, the COMMIT cleans out the blocks so
    that a subsequent SELECT does not have to perform this task.

    NB: Because a block cleanout generates redo, a query may generate redo and thus cause
        blocks to be written during the next checkpoint.

  - Oracle Database marks the transaction complete.

After a transaction commits, users can view the changes.

Typically, a commit is a fast operation, regardless of the transaction size. The speed of
a commit does not increase with the size of the data modified in the transaction. The
lengthiest part of the commit is the physical disk I/O performed by LGWR. However, the
amount of time spent by LGWR is reduced because it has been incrementally writing the
contents of the redo log buffer in the background.

The default behavior is for LGWR to write redo to the online redo log synchronously and
for transactions to wait for the buffered redo to be on disk before returning a commit to
the user. However, for lower transaction commit latency, application developers can
specify that redo be written asynchronously so that transactions need not wait for the
redo to be on disk and can return from the COMMIT call immediately.

See Also:

  - Oracle Database PL/SQL Language Reference for more information on asynchronous commit

  - "Locking Mechanisms" on page 9-5

  - "Overview of Background Processes" on page 15-7 for more information about LGWR

** Overview of Autonomous Transactions

An autonomous transaction is an independent transaction that can be called from another
transaction, called the main transaction. You can suspend the calling transaction, perform
SQL operations and commit or undo them in the autonomous transaction, and then resume the
calling transaction.

Autonomous transactions are useful for actions that must be performed independently,
regardless of whether the calling transaction commits or rolls back. For example, in a
stock purchase transaction, you want to commit customer data regardless of whether the
overall stock purchase goes through. Additionally, you want to log error messages to a
debug table even if the overall transaction rolls back.

Autonomous transactions have the following characteristics:

  - The autonomous transaction does not see uncommitted changes made by the main
    transaction and does not share locks or resources with the main transaction.

  - Changes in an autonomous transaction are visible to other transactions upon commit of
    the autonomous transactions. Thus, users can access the updated information without
    having to wait for the main transaction to commit.

  - Autonomous transactions can start other autonomous transactions. There are no limits,
    other than resource limits, on how many levels of autonomous transactions can be
    called.

In PL/SQL, an autonomous transaction executes within an autonomous scope, which is a
routine marked with the pragma AUTONOMOUS_TRANSACTION. In this context, routines include
top-level anonymous PL/SQL blocks and PL/SQL subprograms and triggers. A pragma is a
directive that instructs the compiler to perform a compilation option. The pragma
AUTONOMOUS_TRANSACTION instructs the database that this procedure, when executed, is to be
executed as a new autonomous transaction that is independent of its parent transaction.

./oracle-concepts-figure-txn-control-flow.png

txn-control-flow.png shows how control flows from the main routine (MT) to an autonomous
routine and back again. The main routine is proc1 and the autonomous routine is proc2. The
autonomous routine can commit multiple transactions (AT1 and AT2) before control returns
to the main routine.

When you enter the executable section of an autonomous routine, the main routine
suspends. When you exit the autonomous routine, the main routine resumes.

In txn-control-flow.png, the COMMIT inside proc1 makes permanent not only its own work but
any outstanding work performed in its session. However, a COMMIT in proc2 makes permanent
only the work performed in the proc2 transaction. Thus, the COMMIT statements in
transactions AT1 and AT2 have no effect on the MT transaction.

See Also:

  - Oracle Database Advanced Application Developer's Guide and Oracle Database PL/SQL
    Language Reference to learn how to use autonomous transactions

** Overview of Distributed Transactions

A distributed database is a set of databases in a distributed system that can appear to
applications as a single data source. A distributed transaction is a transaction that
includes one or more statements that update data on two or more distinct nodes of a
distributed database, using a schema object called a database link. A database link
describes how one database instance can log in to another database instance.

Unlike a transaction on a local database, a distributed transaction alters data on
multiple databases. Consequently, distributed transaction processing is more complicated
because the database must coordinate the committing or rolling back of the changes in a
transaction as an atomic unit. The entire transaction must commit or roll back. Oracle
Database must coordinate transaction control over a network and maintain data consistency,
even if a network or system failure occurs.

See Also:

  - Oracle Database Administrator's Guide

*** Two-Phase Commit

The two-phase commit mechanism guarantees that all databases participating in a
distributed transaction either all commit or all undo the statements in the transaction.
The mechanism also protects implicit DML performed by integrity constraints, remote
procedure calls, and triggers.

In a two-phase commit among multiple databases, one database coordinates the distributed
transaction. The initiating node is called the global coordinator. The coordinator asks
the other databases if they are prepared to commit. If any database responds with a no,
then the entire transaction is rolled back. If all databases vote yes, then the
coordinator broadcasts a message to make the commit permanent on each of the databases.

The two-phase commit mechanism is transparent to users who issue distributed transactions.
In fact, users need not even know the transaction is distributed. A COMMIT statement
denoting the end of a transaction automatically triggers the two-phase commit mechanism.
No coding or complex statement syntax is required to include distributed transactions
within the body of a database application.

See Also:

  - Oracle Database Administrator's Guide to learn about the two-phase commit mechanism

*** In-Doubt Transactions

An in-doubt distributed transaction occurs when a two-phase commit was interrupted by any
type of system or network failure.  For example, two databases report to the coordinating
database that they were prepared to commit, but the coordinating database instance fails
immediately after receiving the messages.  The two databases who are prepared to commit
are now left hanging while they await notification of the outcome.

The recoverer (RECO) background process automatically resolves the outcome of in-doubt
distributed transactions.  After the failure is repaired and communication is
reestablished, the RECO process of each local Oracle database automatically commits or
rolls back any in-doubt distributed transactions consistently on all involved nodes.

In the event of a long-term failure, Oracle Database enables each local administrator to
manually commit or undo any distributed transactions that are in doubt because of the
failure.  This option enables the local database administrator to free any locked
resources that are held indefinitely because of the long-term failure.

If a database must be recovered to a past time, then database recovery facilities enable
database administrators at other sites to return their databases to the earlier point in
time.  This operation ensures that the global database remains consistent.

See Also:

  - "Recoverer Process (RECO)" on page 15-11

  - Oracle Database Administrator's Guide to learn how to manage in-doubt transactions

* Part IV Oracle Database Storage Structures

* Chapter 11: Physical Storage Structures
** Introduction to Physical Storage Structures

One characteristic of an RDBMS is the independence of logical data structures such as
tables, views, and indexes from physical storage structures. Because physical and logical
structures are separate, you can manage physical storage of data without affecting access
to logical structures.  For example, renaming a database file does not rename the tables
stored in it.

An Oracle database is a set of files that store Oracle data in persistent disk storage.
This section discusses the database files generated when you issue a CREATE DATABASE
statement:

  - Data files and temp files

    A data file is a physical file on disk that was created by Oracle Database and
    contains data structures such as tables and indexes. A temp file is a data file that
    belongs to a temporary tablespace. The data is written to these files in an Oracle
    proprietary format that cannot be read by other programs.

  - Control files

    A control file is a root file that tracks the physical components of the database.

  - Online redo log files

    The online redo log is a set of files containing records of changes made to data.

A database instance is a set of memory structures that manage database files. 

./oracle-concepts-figure-db-instance-files.png

shows the relationship between the instance and the files that it manages.

See Also:

  - Oracle Database Administrator's Guide to learn how to create a database

  - Oracle Database SQL Language Reference for CREATE DATABASE semantics and syntax

*** Mechanisms for Storing Database Files

Several mechanisms are available for allocating and managing the storage of these
files. The most common mechanisms include:

  - Oracle Automatic Storage Management (Oracle ASM)

    Oracle ASM includes a file system designed exclusively for use by Oracle
    Database. "Oracle Automatic Storage Management (Oracle ASM)" on page 11-3 describes
    Oracle ASM.

  - Operating system file system

    Most Oracle databases store files in a file system, which is a data structure built
    inside a contiguous disk address space. All operating systems have file managers that
    allocate and deallocate disk space into files within a file system.

    A file system enables disk space to be allocated to many files. Each file has a name
    and is made to appear as a contiguous address space to applications such as Oracle
    Database. The database can create, read, write, resize, and delete files.

    A file system is commonly built on top of a logical volume constructed by a software
    package called a logical volume manager (LVM). The LVM enables pieces of multiple
    physical disks to be combined into a single contiguous address space that appears as
    one disk to higher layers of software.

  - Raw device

    Raw devices are disk partitions or logical volumes not formatted with a file system.
    The primary benefit of raw devices is the ability to perform direct I/O and to write
    larger buffers.  In direct I/O, applications write to and read from the storage device
    directly, bypassing the operating system buffer cache.

    NB: Many file systems now support direct I/O for databases and other applications that
        manage their own caches.  Historically, raw devices were the only means of
        implementing direct I/O.

  - Cluster file system

    A cluster file system is software that enables multiple computers to share file
    storage while maintaining consistent space allocation and file content.  In an Oracle
    RAC environment, a cluster file system makes shared storage appears as a file system
    shared by many computers in a clustered environment.  With a cluster file system, the
    failure of a computer in the cluster does not make the file system unavailable.  In an
    operating system file system, however, if a computer sharing files through NFS or
    other means fails, then the file system is unavailable.

A database employs a combination of the preceding storage mechanisms. For example, a
database could store the control files and online redo log files in a traditional file
system, some user data files on raw partitions, the remaining data files in Oracle ASM,
and archived the redo log files to a cluster file system.

See Also:

  - Oracle Database 2 Day DBA to learn how to view database storage structures with Oracle
    Enterprise Manager (Enterprise Manager)

  - Oracle Database Administrator's Guide to view database storage structures by querying
    database views

*** Oracle Automatic Storage Management (Oracle ASM)

Oracle ASM is a high-performance, ease-of-management storage solution for Oracle Database
files. Oracle ASM is a volume manager and provides a file system designed exclusively for
use by the database.

Oracle ASM provides several advantages over conventional file systems and storage
managers, including the following:

  - Simplifies storage-related tasks such as creating and laying out databases and
    managing disk space

  - Distributes data across physical disks to eliminate hot spots and to provide uniform
    performance across the disks

  - Rebalances data automatically after storage configuration changes

To use Oracle ASM, you allocate partitioned disks for Oracle Database with preferences for
striping and mirroring.  Oracle ASM manages the disk space, distributing the I/O load
across all available resources to optimize performance while removing the need for manual
I/O tuning.  For example, you can increase the size of the disk for the database or move
parts of the database to new devices without having to shut down the database.

**** Oracle ASM Storage Components

Oracle Database can store a data file as an Oracle ASM file in an Oracle ASM disk group,
which is a collection of disks that Oracle ASM manages as a unit. Within a disk group,
Oracle ASM exposes a file system interface for database files.

./oracle-concepts-figure-asm-components.png

shows the relationships between storage components in a database that uses Oracle ASM. The
diagram depicts the relationship between an Oracle ASM file and a data file, although
Oracle ASM can store other types of files. The crow's foot notation represents a
one-to-many relationship.

./oracle-concepts-figure-asm-components.png

illustrates the following Oracle ASM concepts:

  - Oracle ASM Disks

    An Oracle ASM disk is a storage device that is provisioned to an Oracle ASM disk
    group.  An Oracle ASM disk can be a physical disk or partition, a Logical Unit Number
    (LUN) from a storage array, a logical volume, or a network-attached file.

    Oracle ASM disks can be added or dropped from a disk group while the database is
    running. When you add a disk to a disk group, you either assign a disk name or the
    disk is given an Oracle ASM disk name automatically.

  - Oracle ASM Disk Groups

    An Oracle ASM disk group is a collection of Oracle ASM disks managed as a logical
    unit. The data structures in a disk group are self-contained and consume some disk
    space in a disk group.

    Within a disk group, Oracle ASM exposes a file system interface for Oracle database
    files. The content of files that are stored in a disk group are evenly distributed, or
    striped, to eliminate hot spots and to provide uniform performance across the
    disks. The performance is comparable to the performance of raw devices.

  - Oracle ASM Files

    An Oracle ASM file is a file stored in an Oracle ASM disk group. Oracle Database
    communicates with Oracle ASM in terms of files. The database can store data files,
    control files, online redo log files, and other types of files as Oracle ASM
    files. When requested by the database, Oracle ASM creates an Oracle ASM file and
    assigns it a fully qualified name beginning with a plus sign (+) followed by a disk
    group name, as in +DISK1.

    NB: Oracle ASM files can coexist with other storage management options such as raw
        disks and third-party file systems. This capability simplifies the integration of
        Oracle ASM into pre-existing environments.

  - Oracle ASM Extents

    An Oracle ASM extent is the raw storage used to hold the contents of an Oracle ASM
    file. An Oracle ASM file consists of one or more file extents. Each Oracle ASM extent
    consists of one or more allocation units on a specific disk.

    NB: An Oracle ASM extent is different from the extent used to store data in a segment.

  - Oracle ASM Allocation Units

    An allocation unit is the fundamental unit of allocation within a disk group. An
    allocation unit is the smallest contiguous disk space that Oracle ASM allocates. One
    or more allocation units form an Oracle ASM extent.

See Also:

  - Oracle Database 2 Day DBA to learn how to administer Oracle ASM disks with Oracle
    Enterprise Manager (Enterprise Manager)

  - Oracle Automatic Storage Management Administrator's Guide to learn more about Oracle
    ASM

**** Oracle ASM Instances

An Oracle ASM instance is a special Oracle instance that manages Oracle ASM disks. Both
the ASM and the database instances require shared access to the disks in an ASM disk
group. ASM instances manage the metadata of the disk group and provide file layout
information to the database instances. Database instances direct I/O to ASM disks without
going through an ASM instance.

An ASM instance is built on the same technology as a database instance. For example, an
ASM instance has a system global area (SGA) and background processes that are similar to
those of a database instance. However, an ASM instance cannot mount a database and
performs fewer tasks than a database instance.

There is a figure (not copied here by jwm) that shows one of these ASM instances.  Figure
11-3.

*** Oracle Managed Files and User-Managed Files

Oracle Managed Files is a file naming strategy that enables you to specify operations in
terms of database objects rather than file names.  For example, you can create a
tablespace without specifying the names of its data files.  In this way, Oracle Managed
Files eliminates the need for administrators to directly manage the operating system files
in a database.  Oracle ASM requires Oracle Managed Files.

  NB: This feature does not affect the creation or naming of administrative files such as
      trace files, audit files, and alert logs (see "Overview of Diagnostic Files" on page
      13-18).

With user-managed files, you directly manage the operating system files in the
database. You make the decisions regarding file structure and naming. For example, when
you create a tablespace you set the name and path of the tablespace data files.

Through initialization parameters, you specify the file system directory for a specific
type of file. The Oracle Managed Files feature ensures that the database creates a unique
file and deletes it when no longer needed. The database internally uses standard file
system interfaces to create and delete files for data files and temp files, control files,
and recovery-related files stored in the fast recovery area.

Oracle Managed Files does not eliminate existing functionality. You can create new files
while manually administering old files. Thus, a database can have a mixture of Oracle
Managed Files and user-managed files.

See Also:

  - Oracle Database Administrator's Guide to learn how to use Oracle Managed Files

** Overview of Data Files

*** Use of Data Files

Part I, "Oracle Relational Data Structures" explains the logical structures in which users
store data, the most important of which are tables. Each nonpartitioned schema object and
each partition of an object is stored in its own segment.

For ease of administration, Oracle Database allocates space for user data in tablespaces,
which like segments are logical storage structures. Each segment belongs to only one
tablespace. For example, the data for a nonpartitioned table is stored in a single
segment, which is turn is stored in one tablespace.

Oracle Database physically stores tablespace data in data files. Tablespaces and data
files are closely related, but have important differences:

  - Each tablespace consists of one or more data files, which conform to the operating
    system in which Oracle Database is running.

  - The data for a database is collectively stored in the data files located in each
    tablespace of the database.

  - A segment can span one or more data files, but it cannot span multiple tablespaces.

  - A database must have the SYSTEM and SYSAUX tablespaces. Oracle Database automatically
    allocates the first data files of any database for the SYSTEM tablespace during
    database creation.

    The SYSTEM tablespace contains the data dictionary, a set of tables that contains
    database metadata. Typically, a database also has an undo tablespace and a temporary
    tablespace (usually named TEMP).

./oracle-concepts-figure-files-tablespaces.png

is one view of the relationships between tablespaces, data files and segments.

See Also:

  - "Overview of Tablespaces" on page 12-30

  - Oracle Database Administrator's Guide and Oracle Database 2 Day DBA to learn how to
    manage data files

*** Permanent and Temporary Data Files

A permanent tablespace contains persistent schema objects. Objects in permanent
tablespaces are stored in data files.

A temporary tablespace contains schema objects only for the duration of a session. Locally
managed temporary tablespaces have temporary files (temp files), which are special files
designed to store data in hash, sort, and other operations. Temp files also store result
set data when insufficient space exists in memory.

Temp files are similar to permanent data files, with the following exceptions:

  - Permanent database objects such as tables are never stored in temp files.

  - Temp files are always set to NOLOGGING mode, which means that they never have redo
    generated for them. Media recovery does not recognize temp files.

  - You cannot make a temp file read-only.

  - You cannot create a temp file with the ALTER DATABASE statement.

  - When you create or resize temp files, they are not always guaranteed allocation of
    disk space for the file size specified. On file systems such as Linux and UNIX, temp
    files are created as sparse files. In this case, disk blocks are allocated not at file
    creation or resizing, but as the blocks are accessed for the first time.

    NB: Sparse files enable fast temp file creation and resizing; however, the disk could
        run out of space later when the temp files are accessed.

  - Temp file information is shown in the data dictionary view DBA_TEMP_FILES and the
    dynamic performance view V$TEMPFILE, but not in DBA_DATA_FILES or the V$DATAFILE view.

See Also:

  - "Temporary Tablespaces" on page 12-34

  - Oracle Database Administrator's Guide to learn how to manage temp files

*** Online and Offline Data Files

Every data file is either online (available) or offline (unavailable). You can alter the
availability of individual data files or temp files by taking them offline or bringing
them online. Offline data files cannot be accessed until they are brought back online.

Administrators may take data files offline for many reasons, including performing offline
backups, renaming a data file, or block corruption. The database takes a data file offline
automatically if the database cannot write to it.

Like a data file, a tablespace itself is offline or online. When you take a data file
offline in an online tablespace, the tablespace itself remains online. You can make all
data files of a tablespace temporarily unavailable by taking the tablespace itself offline

See Also:

  - "Online and Offline Tablespaces" on page 12-35

  - Oracle Database Administrator's Guide to learn how to alter data file availability

*** Data File Structure

Oracle Database creates a data file for a tablespace by allocating the specified amount of
disk space plus the overhead for the data file header. The operating system under which
Oracle Database runs is responsible for clearing old information and authorizations from a
file before allocating it to the database.

The data file header contains metadata about the data file such as its size and checkpoint
SCN. Each header contains an absolute file number and a relative file number. The absolute
file number uniquely identifies the data file within the database. The relative file
number uniquely identifies a data file within a tablespace.

When Oracle Database first creates a data file, the allocated disk space is formatted but
contains no user data. However, the database reserves the space to hold the data for
future segments of the associated tablespace. As the data grows in a tablespace, Oracle
Database uses the free space in the data files to allocate extents for the segment.

./oracle-concepts-figure-data-file-space.png

illustrates the different types of space in a data file. Extents are either used, which
means they contain segment data, or free, which means they are available for reuse. Over
time, updates and deletions of objects within a tablespace can create pockets of empty
space that individually are not large enough to be reused for new data. This type of empty
space is referred to as fragmented free space.

See Also:

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn how to
    view data file information

** Overview of Control Files

The database control file is a small binary file associated with only one database. Each
database has one unique control file, although it may maintain identical copies of it.

*** Use of Control Files

The control file is the root file that Oracle Database uses to find database files and to
manage the state of the database generally. A control file contains information such as
the following:

  - The database name and database unique identifier (DBID)

  - The time stamp of database creation

  - Information about data files, online redo log files, and archived redo log files

  - Tablespace information

  - RMAN backups

The control file serves the following purposes:

  - It contains information about data files, online redo log files, and so on that are
    required to open the database.

    The control file tracks structural changes to the database. For example, when an
    administrator adds, renames, or drops a data file or online redo log file, the
    database updates the control file to reflect this change.

  - It contains metadata that must be accessible when the database is not open.

    For example, the control file contains information required to recover the database,
    including checkpoints. A checkpoint indicates the SCN in the redo stream where
    instance recovery would be required to begin (see "Overview of Instance Recovery" on
    page 13-12). Every committed change before a checkpoint SCN is guaranteed to be saved
    on disk in the data files. At least every three seconds the checkpoint process records
    information in the control file about the checkpoint position in the online redo log.

Oracle Database reads and writes to the control file continuously during database use and
must be available for writing whenever the database is open. For example, recovering a
database involves reading from the control file the names of all the data files contained
in the database. Other operations, such as adding a data file, update the information
stored in the control file.

See Also:

  - "Checkpoint Process (CKPT)" on page 15-10

  - Oracle Database Administrator's Guide to learn how to manage the control file

*** Multiple Control Files

Oracle Database enables multiple, identical control files to be open concurrently and
written for the same database. By multiplexing a control file on different disks, the
database can achieve redundancy and thereby avoid a single point of failure.

  NB: Oracle recommends that you maintain multiple control file copies, each on a
      different disk.

If a control file becomes unusable, then the database instance fails when it attempts to
access the damaged control file.  When other current control file copies exist, the
database can be remounted and opened without media recovery.  If all control files of a
database are lost, however, then the instance fails and media recovery is required.  Media
recovery is not straightforward if an older backup of a control file must be used because
a current copy is not available.

See Also:

  - Oracle Database Administrator's Guide to learn how to maintain multiple control files

  - Oracle Database Backup and Recovery User's Guide to learn how to back up and restore
    control files

*** Control File Structure

Information about the database is stored in different sections of the control file.  Each
section is a set of records about an aspect of the database.  For example, one section in
the control file tracks data files and contains a set of records, one for each data file.
Each section is stored in multiple logical control file blocks.  Records can span blocks
within a section.

The control file contains the following types of records:

  - Circular reuse records

    These records contain noncritical information that is eligible to be overwritten if
    needed. When all available record slots are full, the database either expands the
    control file to make room for a new record or overwrites the oldest record. Examples
    include records about archived redo log files and RMAN backups.

  - Noncircular reuse records

    These records contain critical information that does not change often and cannot be
    overwritten. Examples of information include tablespaces, data files, online redo log
    files, and redo threads. Oracle Database never reuses these records unless the
    corresponding object is dropped from the tablespace.

As explained in "Overview of the Dynamic Performance Views" on page 6-5, you can query the
dynamic performance views, also known as V$ views, to view the information stored in the
control file.  For example, you can query V$DATABASE to obtain the database name and DBID.
However, only the database can modify the information in the control file.

Reading and writing the control file blocks is different from reading and writing data
blocks.  For the control file, Oracle Database reads and writes directly from the disk to
the program global area (PGA).  Each process allocates a certain amount of its PGA memory
for control file blocks.

See Also:

  - Oracle Database Reference to learn about the V$CONTROLFILE_RECORD_SECTION view

  - Oracle Database Reference to learn about the CONTROL_FILE_RECORD_KEEP_TIME
    initialization parameter

** Overview of the Online Redo Log

The most crucial structure for recovery is the online redo log, which consists of two or
more preallocated files that store changes to the database as they occur. The online redo
log records changes to the data files.

*** Use of the Online Redo Log

The database maintains online redo log files to protect against data loss. Specifically,
after an instance failure the online redo log files enable Oracle Database to recover
committed data not yet written to the data files.

Oracle Database writes every transaction synchronously to the redo log buffer, which is
then written to the online redo logs. The contents of the log include uncommitted
transactions, undo data, and schema and object management statements.

Oracle Database uses the online redo log only for recovery. However, administrators can
query online redo log files through a SQL interface in the Oracle LogMiner utility (see
"Oracle LogMiner" on page 18-8). Redo log files are a useful source of historical
information about database activity.

See Also:

  - "Overview of Instance Recovery" on page 13-12

*** How Oracle Database Writes to the Online Redo Log

The online redo log for a database instance is called a redo thread. In single-instance
configurations, only one instance accesses a database, so only one redo thread is present.
In an Oracle Real Application Clusters (Oracle RAC) configuration, however, two or more
instances concurrently access a database, with each instance having its own redo thread. A
separate redo thread for each instance avoids contention for a single set of online redo
log files.

An online redo log consists of two or more online redo log files. Oracle Database requires
a minimum of two files to guarantee that one is always available for writing while the
other is being archived (if the database is in ARCHIVELOG mode).

See Also:

  - Oracle Database 2 Day + Real Application Clusters Guide and Oracle Real Application
    Clusters Administration and Deployment Guide to learn about online redo log groups in
    Oracle RAC

**** Online Redo Log Switches

Oracle Database uses only one online redo log file at a time to store records written from
the redo log buffer. The online redo log file to which the log writer (LGWR) process is
actively writing is called the current online redo log file.

A log switch occurs when the database stops writing to one online redo log file and begins
writing to another. Normally, a switch occurs when the current online redo log file is
full and writing must continue. However, you can configure log switches to occur at
regular intervals, regardless of whether the current online redo log file is filled, and
force log switches manually.

Log writer writes to online redo log files circularly. When log writer fills the last
available online redo log file, the process writes to the first log file, restarting the
cycle. Figure 11â€“6 illustrates the circular writing of the redo log.

The numbers in Figure 11â€“6 shows the sequence in which LGWR writes to each online redo log
file. The database assigns each file a new log sequence number when a log switches and log
writers begins writing to it. When the database reuses an online redo log file, this file
receives the next available log sequence number.

Filled online redo log files are available for reuse depending on the archiving mode:

  - If archiving is disabled, which means that the database is in NOARCHIVELOG mode, then
    a filled online redo log file is available after the changes recorded in it have been
    checkpointed (written) to disk by database writer (DBWn).

  - If archiving is enabled, which means that the database is in ARCHIVELOG mode, then a
    filled online redo log file is available to log writer after the changes have been
    written to the data files and the file has been archived.

In some circumstances, log writer may be prevented from reusing an existing online redo
log file. For example, an online redo log file may be active (required for instance
recovery) rather than inactive (not required for instance recovery). Also, an online redo
log file may be in the process of being cleared.

See Also:

  - "Overview of Background Processes" on page 15-7

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn how to
    manage the online redo log

**** Multiple Copies of Online Redo Log Files

Oracle Database can automatically maintain two or more identical copies of the online redo
log in separate locations. An online redo log group consists of an online redo log file
and its redundant copies. Each identical copy is a member of the online redo log
group. Each group is defined by a number, such as group 1, group 2, and so on.

Maintaining multiple members of an online redo log group protects against the loss of the
redo log. Ideally, the locations of the members should be on separate disks so that the
failure of one disk does not cause the loss of the entire online redo log.

  NB: Oracle recommends that you multiplex the online redo log. The loss of log files can
      be catastrophic if recovery is required. When you multiplex the online redo log, the
      database must increase the amount of I/O it performs. Depending on your system, this
      additional I/O may impact overall database performance.

See Also:

  - Oracle Database Administrator's Guide to learn how to maintain multiple copies of the
    online redo log files

**** Archived Redo Log Files

An archived redo log file is a copy of a filled member of an online redo log group. This
file is not considered part of the database, but is an offline copy of an online redo log
file created by the database and written to a user-specified location.

Archived redo log files are a crucial part of a backup and recovery strategy. You can use
archived redo log files to:

  - Recover a database backup

  - Update a standby database (see "Computer Failures" on page 17-7)

  - Obtain information about the history of a database using the LogMiner utility (see
    "Oracle LogMiner" on page 18-8)

Archiving is the operation of generating an archived redo log file. Archiving is either
automatic or manual and is only possible when the database is in ARCHIVELOG mode.

An archived redo log file includes the redo entries and the log sequence number of the
identical member of the online redo log group. In Figure 11â€“7, files A_LOG1 and B_LOG1 are
identical members of Group 1. If the database is in ARCHIVELOG mode, and if automatic
archiving is enabled, then the archiver process (ARCn) will archive one of these files. If
A_LOG1 is corrupted, then the process can archive B_LOG1. The archived redo log contains a
copy of every group created since you enabled archiving.

See Also:

  - "Data File Recovery" on page 18-14

  - Oracle Database Administrator's Guide to learn how to manage the archived redo log

*** Structure of the Online Redo Log

Online redo log files contain redo records. A redo record is made up of a group of change
vectors, each of which describes a change to a data block. For example, an update to a
salary in the employees table generates a redo record that describes changes to the data
segment block for the table, the undo segment data block, and the transaction table of the
undo segments.

The redo records have all relevant metadata for the change, including the following:

  - SCN and time stamp of the change

  - Transaction ID of the transaction that generated the change

  - SCN and time stamp when the transaction committed (if it committed)

  - Type of operation that made the change

  - Name and type of the modified data segment

See Also:

  - "Overview of Data Blocks" on page 12-6

* Chapter 12: Logical Storage Structures

** Introduction to Logical Storage Structures

Oracle Database allocates logical space for all data in the database. The logical units of
database space allocation are data blocks, extents, segments, and tablespaces. At a
physical level, the data is stored in data files on disk (see Chapter 11, "Physical
Storage Structures"). The data in the data files is stored in operating system blocks.

./oracle-concepts-figure-logical-storage.png

is an entity-relationship diagram for physical and logical storage. The crow's foot
notation represents a one-to-many relationship.

*** Logical Storage Hierarchy

./oracle-concepts-figure-tablespace-layout.png

shows the relationships among data blocks, extents, and segments within a tablespace. In
this example, a segment has two extents stored in different data files.

At the finest level of granularity, Oracle Database stores data in data blocks. One
logical data block corresponds to a specific number of bytes of physical disk space, for
example, 2 KB. Data blocks are the smallest units of storage that Oracle Database can use
or allocate.

An extent is a set of logically contiguous data blocks allocated for storing a specific
type of information. In Figure 12â€“2, the 24 KB extent has 12 data blocks, while the 72 KB
extent has 36 data blocks.

A segment is a set of extents allocated for a specific database object, such as a
table. For example, the data for the employees table is stored in its own data segment,
whereas each index for employees is stored in its own index segment. Every database object
that consumes storage consists of a single segment.

Each segment belongs to one and only one tablespace. Thus, all extents for a segment are
stored in the same tablespace. Within a tablespace, a segment can include extents from
multiple data files, as shown in Figure 12â€“2. For example, one extent for a segment may be
stored in users01.dbf, while another is stored in users02.dbf. A single extent can never
span data files.

See Also:

  - "Overview of Data Files" on page 11-7

*** Logical Space Management

Oracle Database must use logical space management to track and allocate the extents in a
tablespace. When a database object requires an extent, the database must have a method of
finding and providing it. Similarly, when an object no longer requires an extent, the
database must have a method of making the free extent available.

Oracle Database manages space within a tablespace based on the type that you create. You
can create either of the following types of tablespaces:

  - Locally managed tablespaces (default)

    The database uses bitmaps in the tablespaces themselves to manage extents. Thus,
    locally managed tablespaces have a part of the tablespace set aside for a bitmap.
    Within a tablespace, the database can manage segments with automatic segment space
    management (ASSM) or manual segment space management (MSSM).

  - Dictionary-managed tablespaces

    The database uses the data dictionary to manage extents (see "Overview of the Data
    Dictionary" on page 6-1).

**** Locally Managed Tablespaces

A locally managed tablespace maintains a bitmap in the data file header to track free and
used space in the data file body. Each bit corresponds to a group of blocks. When space is
allocated or freed, Oracle Database changes the bitmap values to reflect the new status of
the blocks.

A locally managed tablespace has the following advantages:

  - Avoids using the data dictionary to manage extents

    Recursive operations can occur in dictionary-managed tablespaces if consuming or
    releasing space in an extent results in another operation that consumes or releases
    space in a data dictionary table or undo segment.

  - Tracks adjacent free space automatically

    In this way, the database eliminates the need to coalesce free extents.

  - Determines the size of locally managed extents automatically

    Alternatively, all extents can have the same size in a locally managed tablespace and
    override object storage options.

    NB: Oracle strongly recommends the use of locally managed tablespaces with Automatic
        Segment Space Management.

"Segment space management" is an attribute inherited from the tablespace that contains the
segment. Within a locally managed tablespace, the database can manage segments
automatically or manually. For example, segments in tablespace users can be managed
automatically while segments in tablespace tools are managed manually.

***** Automatic Segment Space Management

The ASSM method uses bitmaps to manage space. Bitmaps provide the following advantages:

  - Simplified administration

    ASSM avoids the need to manually determine correct settings for many storage
    parameters.  Only one crucial SQL parameter controls space allocation: PCTFREE. This
    parameter specifies the percentage of space to be reserved in a block for future
    updates (see "Percentage of Free Space in Data Blocks" on page 12-12).

  - Increased concurrency

    Multiple transactions can search separate lists of free data blocks, thereby reducing
    contention and waits. For many standard workloads, application performance with ASSM
    is better than the performance of a well-tuned application that uses MSSM.

  - Dynamic affinity of space to instances in an Oracle Real Application Clusters (Oracle
    RAC) environment

ASSM is more efficient and is the default for permanent, locally managed tablespaces.

  NB: This chapter assumes the use of ASSM in all of its discussions of logical storage
      space.

***** Manual Segment Space Management

The legacy MSSM method uses a linked list called a free list to manage free space in the
segment. For a database object that has free space, a free list keeps track of blocks
under the high water mark (HWM), which is the dividing line between segment space that is
used and not yet used. As blocks are used, the database puts blocks on or removes blocks
from the free list as needed.

In addition to PCTFREE, MSSM requires you to control space allocation with SQL parameters
such as PCTUSED, FREELISTS, and FREELIST GROUPS. PCTUSED sets the percentage of free space
that must exist in a currently used block for the database to put it on the free list. For
example, if you set PCTUSED to 40 in a CREATE TABLE statement, then you cannot insert rows
into a block in the segment until less than 40% of the block space is used.

As an illustration, suppose you insert a row into a table. The database checks a free list
of the table for the first available block. If the row cannot fit in the block, and if the
used space in the block is greater than or equal to PCTUSED, then the database takes the
block off the list and searches for another block. If you delete rows from the block, then
the database checks whether used space in the block is now less than PCTUSED. If so, then
the database places the block at the beginning of the free list.

An object may have multiple free lists. In this way, multiple sessions performing DML on a
table can use different lists, which can reduce contention. Each database session uses
only one free list for the duration of its session.

As shown in Figure 12â€“4, you can also create an object with one or more free list groups,
which are collections of free lists. Each group has a master free list that manages the
individual process free lists in the group. Space overhead for free lists, especially for
free list groups, can be significant.

Managing segment space manually can be complex. You must adjust PCTFREE and PCTUSED to
reduce row migration (see "Chained and Migrated Rows" on page 12-16) and avoid wasting
space. For example, if every used block in a segment is half full, and if PCTUSED is 40,
then the database does not permit inserts into any of these blocks. Because of the
difficulty of fine-tuning space allocation parameters, Oracle strongly recommends ASSM. In
ASSM, PCTFREE determines whether a new row can be inserted into a block, but it does not
use free lists and ignores PCTUSED.

See Also:

  - Oracle Database Administrator's Guide to learn about locally managed tablespaces

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn more
    about automatic segment space management

  - Oracle Database SQL Language Reference to learn about storage parameters such as
    PCTFREE and PCTUSED

**** Dictionary-Managed Tablespaces

A dictionary-managed tablespace uses the data dictionary to manage its extents. Oracle
Database updates tables in the data dictionary whenever an extent is allocated or freed
for reuse. For example, when a table needs an extent, the database queries the data
dictionary tables, and searches for free extents. If the database finds space, then it
modifies one data dictionary table and inserts a row into another. In this way, the
database manages space by modifying and moving data.

The SQL that the database executes in the background to obtain space for database objects
is recursive SQL. Frequent use of recursive SQL can have a negative impact on performance
because updates to the data dictionary must be serialized. Locally managed tablespaces,
which are the default, avoid this performance problem.

See Also:

  - Oracle Database Administrator's Guide to learn how to migrate tablespaces from
    dictionary-managed to locally managed

** Overview of Data Blocks

Oracle Database manages the logical storage space in the data files of a database in units
called data blocks, also called Oracle blocks or pages. A data block is the minimum unit
of database I/O.

*** Data Blocks and Operating System Blocks

At the physical level, database data is stored in disk files made up of operating system
blocks. An operating system block is the minimum unit of data that the operating system
can read or write. In contrast, an Oracle block is a logical storage structure whose size
and structure are not known to the operating system.

Figure 12â€“5 shows that operating system blocks may differ in size from data blocks. The
database requests data in multiples of data blocks, not operating system blocks.

When the database requests a data block, the operating system translates this operation
into a requests for data in permanent storage. The logical separation of data blocks from
operating system blocks has the following implications:

  - Applications do not need to determine the physical addresses of data on disk.

  - Database data can be striped or mirrored on multiple physical disks.

**** Database Block Size

Every database has a database block size. The DB_BLOCK_SIZE initialization parameter sets
the data block size for a database when it is created. The size is set for the SYSTEM and
SYSAUX tablespaces and is the default for all other tablespaces. The database block size
cannot be changed except by re-creating the database.

If DB_BLOCK_SIZE is not set, then the default data block size is operating
system-specific. The standard data block size for a database is 4 KB or 8 KB. If the size
differs for data blocks and operating system blocks, then the data block size must be a
multiple of the operating system block size.

See Also:

  - Oracle Database Reference to learn about the DB_BLOCK_SIZE initialization parameter

  - Oracle Database Administrator's Guide and Oracle Database Performance Tuning Guide to
    learn how to choose block sizes

**** Tablespace Block Size

You can create individual tablespaces whose block size differs from the DB_BLOCK_SIZE
setting. A nonstandard block size can be useful when moving a transportable tablespace to
a different platform.

See Also:

  - Oracle Database Administrator's Guide to learn how to specify a nonstandard block size
    for a tablespace

*** Data Block Format

Every data block has a format or internal structure that enables the database to track the
data and free space in the block. This format is similar whether the data block contains
table, index, or table cluster data.

./oracle-concepts-figure-data-block.png

shows the format of an uncompressed data block (see "Data Block Compression" on page 12-11
to learn about compressed blocks).

**** Data Block Overhead

Oracle Database uses the block overhead to manage the block itself. The block overhead is
not available to store user data. As shown in

./oracle-concepts-figure-data-block.png

the block overhead includes the following parts:

  - Block header

    This part contains general information about the block, including disk address and
    segment type. For blocks that are transaction-managed, the block header contains
    active and historical transaction information.

    A transaction entry is required for every transaction that updates the block. Oracle
    Database initially reserves space in the block header for transaction entries. In data
    blocks allocated to segments that support transactional changes, free space can also
    hold transaction entries when the header space is depleted. The space required for
    transaction entries is operating system dependent. However, transaction entries in
    most operating systems require approximately 23 bytes.

  - Table directory

    For a heap-organized table, this directory contains metadata about tables whose rows
    are stored in this block. Multiple tables can store rows in the same block.

  - Row directory

    For a heap-organized table, this directory describes the location of rows in the data
    portion of the block.

    After space has been allocated in the row directory, the database does not reclaim
    this space after row deletion. Thus, a block that is currently empty but formerly had
    up to 50 rows continues to have 100 bytes allocated for the row directory. The
    database reuses this space only when new rows are inserted in the block.

Some parts of the block overhead are fixed in size, but the total size is variable. On
average, the block overhead totals 84 to 107 bytes.

**** Row Format

The row data part of the block contains the actual data, such as table rows or index key
entries. Just as every data block has an internal format, every row has a row format that
enables the database to track the data in the row.

Oracle Database stores rows as variable-length records. A row is contained in one or more
row pieces. Each row piece has a row header and column data.

./oracle-concepts-figure-row-format.png

***** Row Header

Oracle Database uses the row header to manage the row piece stored in the block. The row
header contains information such as the following:

  - Columns in the row piece

  - Pieces of the row located in other data blocks

    If an entire row can be inserted into a single data block, then Oracle Database stores
    the row as one row piece. However, if all of the row data cannot be inserted into a
    single block or an update causes an existing row to outgrow its block, then the
    database stores the row in multiple row pieces (see "Chained and Migrated Rows" on
    page 12-16). A data block usually contains only one row piece per row.

  - Cluster keys for table clusters (see "Overview of Table Clusters" on page 2-22)

A row fully contained in one block has at least 3 bytes of row header.

***** Column Data

After the row header, the column data section stores the actual data in the row. The row
piece usually stores columns in the order listed in the CREATE TABLE statement, but this
order is not guaranteed. For example, columns of type LONG are created last.

As shown in 

./oracle-concepts-figure-row-format.png

for each column in a row piece, Oracle Database stores the column length and data
separately. The space required depends on the data type. If the data type of a column is
variable length, then the space required to hold a value can grow and shrink with updates
to the data.  Each row has a slot in the row directory of the data block header. The slot
points to the beginning of the row.

See Also:

  - "Table Storage" on page 2-18 and "Index Storage" on page 3-20

***** Rowid Format 

Oracle Database uses a rowid to uniquely identify a row. Internally, the rowid is a
structure that holds information that the database needs to access a row. A rowid is not
physically stored in the database, but is inferred from the file and block on which the
data is stored.

An extended rowid includes a data object number. This rowid type uses a base 64 encoding
of the physical address for each row. The encoding characters are A-Z, a-z, 0-9, +, and /.

Example 12â€“1 queries the ROWID pseudocolumn to show the extended rowid of the row in the
employees table for employee 100.

  SQL> SELECT ROWID FROM employees WHERE employee_id = 100;

  ROWID
  ------------------
  AAAPecAAFAAAABSAAA

./oracle-concepts-figure-rowid-format.png

shows the format of an extended ROWID.

An extended rowid is displayed in a four-piece format, OOOOOOFFFBBBBBBRRR, with the format
divided into the following components:

  - OOOOOO

    The data object number identifies the segment (data object AAAPec in Example 12â€“1). A
    data object number is assigned to every database segment. Schema objects in the same
    segment, such as a table cluster, have the same data object number.

  - FFF

    The tablespace-relative data file number identifies the data file that contains the
    row (file AAF in Example 12â€“1).

  - BBBBBB

    The data block number identifies the block that contains the row (block AAAABS in
    Example 12â€“1). Block numbers are relative to their data file, not their
    tablespace. Thus, two rows with identical block numbers could reside in different data
    files of the same tablespace.

  - RRR

    The row number identifies the row in the block (row AAA in Example 12â€“1).

After a rowid is assigned to a row piece, the rowid can change in special circumstances.
For example, if row movement is enabled, then the rowid can change because of partition
key updates, Flashback Table operations, shrink table operations, and so on. If row
movement is disabled, then a rowid can change if the row is exported and imported using
Oracle Database utilities.

  NB: Internally, the database performs row movement as if the row were physically deleted
      and reinserted. However, row movement is considered an update, which has
      implications for triggers.

See Also:

  - "Rowid Data Types" on page 2-13

  - Oracle Database SQL Language Reference to learn about rowids

*** Data Block Compression

The database can use table compression to eliminate duplicate values in a data block (see
"Table Compression" on page 2-19). This section describes the format of data blocks that
use compression.

The format of a data block that uses basic and OLTP table compression is essentially the
same as an uncompressed block. The difference is that a symbol table at the beginning of
the block stores duplicate values for the rows and columns. The database replaces
occurrences of these values with a short reference to the symbol table.

*** Space Management in Data Blocks

As the database fills a data block from the bottom up, the amount of free space between
the row data and the block header decreases. This free space can also shrink during
updates, as when changing a trailing null to a nonnull value. The database manages free
space in the data block to optimize performance and avoid wasted space.

  NB: This section assumes the use of automatic segment space management.

**** Percentage of Free Space in Data Blocks

The PCTFREE storage parameter is essential to how the database manages free space. This
SQL parameter sets the minimum percentage of a data block reserved as free space for
updates to existing rows. Thus, PCTFREE is important for preventing row migration and
avoiding wasted space.

For example, assume that you create a table that will require only occasional updates,
most of which will not increase the size of the existing data. You specify the PCTFREE
parameter within a CREATE TABLE statement as follows:

  CREATE TABLE test_table (n NUMBER) PCTFREE 20;

./oracle-concepts-figure-pctfree.png

shows how a PCTFREE setting of 20 affects space management. The database adds rows to the
block over time, causing the row data to grow upwards toward the block header, which is
itself expanding downward toward the row data. The PCTFREE setting ensures that at least
20% of the data block is free. For example, the database prevents an INSERT statement from
filling the block so that the row data and header occupy a combined 90% of the total block
space, leaving only 10% free.

  NB: This discussion does not apply to LOB data types, which do not use the PCTFREE
  storage parameter or free lists. See "Overview of LOBs" on page 19-12.

See Also:

  - Oracle Database SQL Language Reference for the syntax and semantics of the PCTFREE
    parameter

**** Optimization of Free Space in Data Blocks

While the percentage of free space cannot be less than PCTFREE, the amount of free space
can be greater. For example, a PCTFREE setting of 20% prevents the total amount of free
space from dropping to 5% of the block, but permits 50% of the block to be free space. The
following SQL statements can increase free space:

  - DELETE statements

  - UPDATE statements that either update existing values to smaller values or increase
    existing values and force a row to migrate

  - INSERT statements on a table that uses OLTP compression

    If inserts fill a block with data, then the database invokes block compression, which
    may result in the block having more free space.

The space released is available for INSERT statements under the following conditions:

  - If the INSERT statement is in the same transaction and after the statement that frees
    space, then the statement can use the space.

  - If the INSERT statement is in a separate transaction from the statement that frees
    space (perhaps run by another user), then the statement can use the space made
    available only after the other transaction commits and only if the space is needed.

See Also:

  - Oracle Database Administrator's Guide to learn about OLTP compression

***** Coalescing Fragmented Space

Released space may or may not be contiguous with the main area of free space in a data
block, as shown in Figure 12â€“10. Noncontiguous free space is called fragmented space.

Oracle Database automatically and transparently coalesces the free space of a data block
only when the following conditions are true:

  - An INSERT or UPDATE statement attempts to use a block that contains sufficient free
    space to contain a new row piece.

  - The free space is fragmented so that the row piece cannot be inserted in a contiguous
    section of the block.

After coalescing, the amount of free space is identical to the amount before the
operation, but the space is now contiguous. Figure 12â€“11 shows a data block after space
has been coalesced.

Oracle Database performs coalescing only in the preceding situations because otherwise
performance would decrease because of the continuous coalescing of the free space in data
blocks.

***** Reuse of Index Space

The database can reuse space within an index block. For example, if you insert a value
into a column and delete it, and if an index exists on this column, then the database can
reuse the index slot when a row requires it.

The database can reuse an index block itself. Unlike a table block, an index block only
becomes free when it is empty. The database places the empty block on the free list of the
index structure and makes it eligible for reuse. However, Oracle Database does not
automatically compact the index: an ALTER INDEX REBUILD or COALESCE statement is required.

**** Chained and Migrated Rows

Oracle Database must manage rows that are too large to fit into a single block. The
following situations are possible:

  - The row is too large to fit into one data block when it is first inserted.

    In row chaining, Oracle Database stores the data for the row in a chain of one or more
    data blocks reserved for the segment. Row chaining most often occurs with large
    rows. Examples include rows that contain a column of data type LONG or LONG RAW, a
    VARCHAR2(4000) column in a 2 KB block, or a row with a huge number of columns. Row
    chaining in these cases is unavoidable.

  - A row that originally fit into one data block is updated so that the overall row
    length increases, but insufficient free space exists to hold the updated row.

    In row migration, Oracle Database moves the entire row to a new data block, assuming
    the row can fit in a new block. The original row piece of a migrated row contains a
    pointer or "forwarding address" to the new block containing the migrated row. The
    rowid of a migrated row does not change.

  - A row has more than 255 columns.

    Oracle Database can only store 255 columns in a row piece. Thus, if you insert a row
    into a table that has 1000 columns, then the database creates 4 row pieces, typically
    chained over multiple blocks.

When a row is chained or migrated, the I/O needed to retrieve the data increases. This
situation results because Oracle Database must scan multiple blocks to retrieve the
information for the row. For example, if the database performs one I/O to read an index
and one I/O to read a nonmigrated table row, then an additional I/O is required to obtain
the data for a migrated row.

The Segment Advisor, which can be run both manually and automatically, is an Oracle
Database component that identifies segments that have space available for reclamation. The
advisor can offer advice about objects that have significant free space or too many
chained rows.

See Also:

  - "Row Storage" on page 2-19 and "Rowids of Row Pieces" on page 2-19

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn how to
    reclaim wasted space

  - Oracle Database Performance Tuning Guide to learn about reducing chained and migrated
    rows

** Overview of Extents

An extent is a logical unit of database storage space allocation made up of contiguous
data blocks. Data blocks in an extent are logically contiguous but can be physically
spread out on disk because of RAID striping and file system implementations.

JWM SKIPPED:  See oracle-11-2-concept-guide.pdf 
I skipped the rest of the Overview of Extents section including

*** Allocation of Extents
*** Deallocation of Extents
*** Storage Parameters for Extents

** Overview of Segments

A segment is a set of extents that contains all the data for a logical storage structure
within a tablespace. For example, Oracle Database allocates one or more extents to form
the data segment for a table. The database also allocates one or more extents to form the
index segment for a table.

As explained in "Logical Space Management", Oracle Database manages segment space
automatically or manually. This section assumes the use of ASSM.

JWM SKIPPED:  See oracle-11-2-concept-guide.pdf 
I skipped the rest of this section including

*** User Segments
*** Temporary Segments
*** Undo Segments
*** Segment Space and the High Water Mark

** Overview of Tablespaces

A tablespace is a logical storage container for segments. Segments are database objects,
such as tables and indexes, that consume storage space. At the physical level, a
tablespace stores data in one or more data files or temp files.

A database must have the SYSTEM and SYSAUX tablespaces.

JWM SKIPPED:  See oracle-11-2-concept-guide.pdf 
I skipped the rest of this section including

*** Permanent Tablespaces
*** Temporary Tablespaces
*** Tablespace Modes
*** Tablespace File Size

* Part V  Oracle Instance Architecture

* Chapter 13: Oracle Database Instance

This chapter explains the nature of an Oracle database instance, the parameter and
diagnostic files associated with an instance, and what occurs during instance creation and
the opening and closing of a database.

** Introduction to the Oracle Database Instance

A database instance is a set of memory structures that manage database files. A database
is a set of physical files on disk created by the CREATE DATABASE statement. The instance
manages its associated data and serves the users of the database.

Every running Oracle database is associated with at least one Oracle database instance.
Because an instance exists in memory and a database exists on disk, an instance can exist
without a database and a database can exist without an instance.

*** Database Instance Structure

When an instance is started, Oracle Database allocates a memory area called the system
global area (SGA) and starts one or more background processes. The SGA serves various
purposes, including the following:

  - Maintaining internal data structures that are accessed by many processes and threads
    concurrently

  - Caching data blocks read from disk

  - Buffering redo data before writing it to the online redo log files

  - Storing SQL execution plans

The SGA is shared by the Oracle processes, which include server processes and background
processes, running on a single computer. The way in which Oracle processes are associated
with the SGA varies according to operating system.

A database instance includes background processes. Server processes, and the process
memory allocated in these processes, also exist in the instance. The instance continues to
function when server processes terminate.

./oracle-concepts-figure-db-instance.png

shows the main components of an Oracle database instance.

See Also:

  - "Overview of the System Global Area" on page 14-8

  - "Overview of Background Processes" on page 15-7

*** Database Instance Configurations

You can run Oracle Database in either of the following mutually exclusive configurations:

  - Single-instance configuration A one-to-one relationship exists between the database
    and an instance.

  - Oracle Real Application Clusters (Oracle RAC) configuration A one-to-many relationship
    exists between the database and instances.

Whether in a single-instance or Oracle RAC configuration, a database instance is
associated with only one database at a time. You can start a database instance and mount
(associate the instance with) one database, but not mount two databases simultaneously
with the same instance.

  NB: This chapter discusses a single-instance database configuration unless otherwise
      noted.

Multiple instances can run concurrently on the same computer, each accessing its own
database. For example, a computer can host two distinct databases: prod1 and prod2. One
database instance manages prod1, while a separate instance manages prod2.

See Also:

  - Oracle Real Application Clusters Administration and Deployment Guide for information
    specific to Oracle RAC

**** Duration of an Instance

An instance begins when it is created with the STARTUP command and ends when it is
terminated. During this period, an instance can associate itself with one and only one
database. Furthermore, the instance can mount a database only once, close it only once,
and open it only once. After a database has been closed or shut down, you must start a
different instance to mount and open this database.

Table 13-1  Duration of an Instance

Statement                                     Explanation
--------------------------------------------- ---------------------------------------------
SQL> STARTUP                                  The STARTUP command creates an instance,
ORACLE instance started.                      which mounts and opens the database.    
                                          
Total System Global Area   468729856 bytes
Fixed Size                   1333556 bytes
Variable Size              440403660 bytes
Database Buffers            16777216 bytes
Redo Buffers                10215424 bytes
Database mounted.                         
Database opened.                          

--------------------------------------------- ---------------------------------------------
SQL> SELECT                                   This query shows the time that the current
     TO_CHAR(STARTUP_TIME,                    instance was started.                     
             'MON-DD-RR HH24:MI:SS')      
     AS "Inst Start Time" FROM V$INSTANCE;
                                          
Inst Start Time                           
------------------                        
JUN-18-09 13:14:48                        

--------------------------------------------- ---------------------------------------------
SQL> ALTER DATABASE CLOSE;                    The instance closes the database, leaving it 
                                              in a mounted state. The instance can read and
Database altered.                             write to the control file but not the data   
                                              files.

--------------------------------------------- ---------------------------------------------
SQL> ALTER DATABASE OPEN;                     The instance attempts to reopen the database
ALTER DATABASE OPEN                           that it previously closed. Oracle Database  
 *                                            issues an error because the same instance   
ERROR at line 1:                              cannot open a database twice.               
                                       
ORA-16196: database has been previously
opened and closed

--------------------------------------------- ---------------------------------------------
SQL> SHUTDOWN IMMEDIATE                       At this stage, the only option for the      
                                              instance is to shut down, ending the life of
                                              this instance.

--------------------------------------------- ---------------------------------------------
SQL> STARTUP                                  The STARTUP command creates a new instance
Oracle instance started.                      and mounts and open the database.
  ...

--------------------------------------------- ---------------------------------------------
SQL> SELECT                                   This query shows the time that the current
     TO_CHAR(STARTUP_TIME,                    instance was started. The different start 
             'MON-DD-RR HH24:MI:SS')          time shows that this instance is different
     AS "Inst Start Time" FROM V$INSTANCE;    from the one that shut down the database. 
                                          
Inst Start Time                           
------------------                        
JUN-18-09 13:16:40                        

--------------------------------------------- ---------------------------------------------

**** Oracle System Identifier (SID)

The system identifier (SID) is a unique name for an Oracle database instance on a specific
host. On UNIX and Linux, Oracle Database uses the SID and Oracle home values to create a
key to shared memory. Also, the SID is used by default to locate the parameter file, which
is used to locate relevant files such as the database control files.

On most platforms, the ORACLE_SID environment variable sets the SID, whereas the
ORACLE_HOME variable sets the Oracle home. When connecting to an instance, clients can
specify the SID in an Oracle Net connection or use a net service name. Oracle Database
converts a service name into an ORACLE_HOME and ORACLE_SID.

See Also:

  - "Service Names" on page 16-8

  - Oracle Database Administrator's Guide to learn how to specify an Oracle SID

** Overview of Instance Startup and Shutdown

JWM SKIPPED; including sections:

*** Overview of Instance and Database Startup
*** Overview of Database and Instance Shutdown

** Oveview of Checkpoints

A checkpoint is a crucial mechanism in consistent database shutdowns, instance recovery,
and Oracle Database operation generally. The term checkpoint has the following related
meanings:

  - A data structure that indicates the checkpoint position, which is the SCN in the redo
    stream where instance recovery must begin

    The checkpoint position is determined by the oldest dirty buffer in the database
    buffer cache. The checkpoint position acts as a pointer to the redo stream and is
    stored in the control file and in each data file header.

  - The writing of modified database buffers in the database buffer cache to disk

See Also:

  - "System Change Numbers (SCNs)" on page 10-5


JWM SKIPPED; including sections:

*** Purpose of Checkpoints
*** When Oracle Database Initiates Checkpoints

** Overview of Instance Recovery

Instance recovery is the process of applying records in the online redo log to data files
to reconstruct changes made after the most recent checkpoint. Instance recovery occurs
automatically when an administrator attempts to open a database that was previously shut
down inconsistently.

JWM SKIPPED; including:

*** Purpose of Instance Recovery
*** When Oracle Database Performs Instance Recovery
*** Importance of Checkpoints for Instance Recovery
*** Instance Recovery Phases

** Overview of Parameter Files

JWM SKIPPED, including

*** Initialization Parameters
*** Server Parameter Files
*** Text Initialization Parameter Files
*** Modification of Initialization Parameter Values

** Overview of Diagnostic Files

JWM SKIPPED, including

*** Automatic Diagnostic Repository
*** Alert Log
*** Trace Files

* Chapter 14: Memory Architecture

** Introduction to Oracle Database Memory Structures

When an instance is started, Oracle Database allocates a memory area and starts background
processes. The memory area stores information such as the following:

  - Program code

  - Information about each connected session, even if it is not currently active

  - Information needed during program execution, for example, the current state of a query
    from which rows are being fetched

  - Information such as lock data that is shared and communicated among processes

  - Cached data, such as data blocks and redo records, that also exists on disk

See Also:

  - Chapter 15, "Process Architecture"

*** Basic Memory Structures

The basic memory structures associated with Oracle Database include:

  - System global area (SGA)

    The SGA is a group of shared memory structures, known as SGA components, that contain
    data and control information for one Oracle Database instance. The SGA is shared by
    all server and background processes. Examples of data stored in the SGA include cached
    data blocks and shared SQL areas.

  - Program global area (PGA)

    A PGA is a nonshared memory region that contains data and control information
    exclusively for use by an Oracle process. The PGA is created by Oracle Database when
    an Oracle process is started.

    One PGA exists for each server process and background process. The collection of
    individual PGAs is the total instance PGA, or instance PGA. Database initialization
    parameters set the size of the instance PGA, not individual PGAs.

  - User Global Area (UGA)

    The UGA is memory associated with a user session.

  - Software code areas

    Software code areas are portions of memory used to store code that is being run or can
    be run. Oracle Database code is stored in a software area that is typically at a
    different location from user programs -- a more exclusive or protected location.

./oracle-concepts-figure-db-mem-structures.png

shows the relationships among these structures.

*** Oracle Database Memory Management

Memory management involves maintaining optimal sizes for the Oracle instance memory
structures as demands on the database change. Oracle Database manages memory based on the
settings of memory-related initialization parameters. The basic options for memory
management are as follows:

  - Automatic memory management

    You specify the target size for instance memory. The database instance automatically
    tunes to the target memory size, redistributing memory as needed between the SGA and
    the instance PGA.


  - Automatic shared memory management

    This management mode is partially automated. You set a target size for the SGA and
    then have the option of setting an aggregate target size for the PGA or managing PGA
    work areas individually.

  - Manual memory management

    Instead of setting the total memory size, you set many initialization parameters to
    manage components of the SGA and instance PGA individually.

If you create a database with Database Configuration Assistant (DBCA) and choose the basic
installation option, then automatic memory management is the default.

See Also:

  - "Memory Management" on page 18-15 for more information about memory management options
    for DBAs

  - "Tools for Database Installation and Configuration" to learn about DBCA

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn about
    memory management options

** Overview of the User Global Area

The UGA is session memory, which is memory allocated for session variables, such as logon
information, and other information required by a database session. Essentially, the UGA
stores the session state.

If a session loads a PL/SQL package into memory, then the UGA contains the package state,
which is the set of values stored in all the package variables at a specific time (see
"PL/SQL Packages" on page 8-6). The package state changes when a package subprogram
changes the variables. By default, the package variables are unique to and persist for the
life of the session.

The OLAP page pool is also stored in the UGA. This pool manages OLAP data pages, which are
equivalent to data blocks. The page pool is allocated at the start of an OLAP session and
released at the end of the session. An OLAP session opens automatically whenever a user
queries a dimensional object such as a cube.

The UGA must be available to a database session for the life of the session. For this
reason, the UGA cannot be stored in the PGA when using a shared server connection because
the PGA is specific to a single process. Therefore, the UGA is stored in the SGA when
using shared server connections, enabling any shared server process access to it. When
using a dedicated server connection, the UGA is stored in the PGA.

See Also:

  - "Connections and Sessions" on page 15-4

  - Oracle Database Net Services Administrator's Guide to learn about shared server
    connections

  - Oracle OLAP User's Guide for an overview of Oracle OLAP

** Overview of the Program Global Area

The PGA is memory specific to an operating process or thread that is not shared by other
processes or threads on the system. Because the PGA is process-specific, it is never
allocated in the SGA.

The PGA is a memory heap that contains session-dependent variables required by a dedicated
or shared server process. The server process allocates memory structures that it requires
in the PGA.

An analogy for a PGA is a temporary countertop workspace used by a file clerk. In this
analogy, the file clerk is the server process doing work on behalf of the customer (client
process). The clerk clears a section of the countertop, uses the workspace to store
details about the customer request and to sort the folders requested by the customer, and
then gives up the space when the work is done.

  NB: Background processes also allocate their own PGAs. This discussion focuses on server
      process PGAs only.

*** Contents of the PGA

The PGA is subdivided into different areas, each with a different purpose.

./oracle-concepts-figure-pga-contents.png

shows the possible contents of the PGA for a dedicated server session. Not all of the PGA
areas will exist in every case.

**** Private SQL Area

A private SQL area holds information about a parsed SQL statement and other
session-specific information for processing. When a server process executes SQL or PL/SQL
code, the process uses the private SQL area to store bind variable values, query execution
state information, and query execution work areas.

Do not confuse a private SQL area, which is in the UGA, with the shared SQL area, which
stores execution plans in the SGA. Multiple private SQL areas in the same or different
sessions can point to a single execution plan in the SGA. For example, 20 executions of
SELECT * FROM employees in one session and 10 executions of the same query in a different
session can share the same plan. The private SQL areas for each execution are not shared
and may contain different values and data.

A cursor is a name or handle to a specific private SQL area. As shown in

./oracle-concepts-figure-cursor.png

you can think of a cursor as a pointer on the client side and as a state on the server
side.  Because cursors are closely associated with private SQL areas, the terms are
sometimes used interchangeably.

A private SQL area is divided into the following areas:

  - The run-time area

    This area contains query execution state information. For example, the run-time area
    tracks the number of rows retrieved so far in a full table scan.

    Oracle Database creates the run-time area as the first step of an execute request. For
    DML statements, the run-time area is freed when the SQL statement is closed.

  - The persistent area

    This area contains bind variable values. A bind variable value is supplied to a SQL
    statement at run time when the statement is executed. The persistent area is freed
    only when the cursor is closed.

The client process is responsible for managing private SQL areas. The allocation and
deallocation of private SQL areas depends largely on the application, although the number
of private SQL areas that a client process can allocate is limited by the initialization
parameter OPEN_CURSORS.

Although most users rely on the automatic cursor handling of database utilities, the
Oracle Database programmatic interfaces offer developers more control over cursors. In
general, applications should close all open cursors that will not be used again to free
the persistent area and to minimize the memory required for application users.

See Also:

  - "Shared SQL Areas" on page 14-16

  - Oracle Database Advanced Application Developer's Guide and Oracle Database PL/SQL
    Language Reference to learn how to use cursors

**** SQL Work Areas

A work area is a private allocation of PGA memory used for memory-intensive operations.
For example, a sort operator uses the sort area to sort a set of rows. Similarly, a hash
join operator uses a hash area to build a hash table from its left input, whereas a bitmap
merge uses the bitmap merge area to merge data retrieved from scans of multiple bitmap
indexes.

If the amount of data to be processed by the operators does not fit into a work area, then
Oracle Database divides the input data into smaller pieces. In this way, the database
processes some data pieces in memory while writing the rest to temporary disk storage for
processing later.

The database automatically tunes work area sizes when automatic PGA memory management is
enabled. You can also manually control and tune the size of a work area. See "Memory
Management" on page 18-15 for more information.

Generally, larger work areas can significantly improve performance of an operator at the
cost of higher memory consumption. Optimally, the size of a work area is sufficient to
accommodate the input data and auxiliary memory structures allocated by its associated SQL
operator. If not, response time increases because part of the input data must be cached on
disk. In the extreme case, if the size of a work area is too small compared to input data
size, then the database must perform multiple passes over the data pieces, dramatically
increasing response time.

See Also:

  - Oracle Database Administrator's Guide to learn how to use automatic PGA management

  - Oracle Database Performance Tuning Guide to learn how to tune PGA memory

*** PGA Usage in Dedicated and Shared Server Modes

PGA memory allocation depends on whether the database uses dedicated or shared server
connections. Table 14â€“1 shows the differences:

Table 14-1  Differences in Memory Allocation Between Dedicated and Shared Servers

Memory Area                                                  Dedicated  Shared
                                                             Server     Server
------------------------------------------------------------ ---------- ----------
Nature of session memory                                     Private    Shared

Location of the persistent area                              PGA        SGA

Location of the run-time area for DML/DDL statements         PGA        PGA
------------------------------------------------------------ ---------- ----------

See Also:

  - Oracle Database Net Services Administrator's Guide to learn how to configure a
    database for shared server

** Overview of the System Global Area

The SGA is a read/write memory area that, along with the Oracle background processes, make
up a database instance. All server processes that execute on behalf of users can read
information in the instance SGA. Several processes write to the SGA during database
operation.

  NB: The server and background processes do not reside within the SGA, but exist in a
      separate memory space.

Each database instance has its own SGA. Oracle Database automatically allocates memory for
an SGA at instance startup and reclaims the memory at instance shutdown. When you start an
instance with SQL*Plus or Oracle Enterprise Manager, the size of the SGA is shown as in
the following example:

  SQL> STARTUP
  ORACLE instance started.
  
  Total System Global Area    368283648 bytes
  Fixed Size                    1300440 bytes
  Variable Size               343935016 bytes
  Database Buffers             16777216 bytes
  Redo Buffers                  6270976 bytes
  Database mounted.
  Database opened.
  
As shown in Figure 14â€“1, the SGA consists of several memory components, which are pools of
memory used to satisfy a particular class of memory allocation requests. All SGA
components except the redo log buffer allocate and deallocate space in units of contiguous
memory called granules. Granule size is platform-specific and is determined by total SGA
size.

You can query the V$SGASTAT view for information about SGA components. The most important
SGA components are the following:

  - Database Buffer Cache

  - Redo Log Buffer

  - Shared Pool

  - Large Pool

  - Java Pool

  - Streams Pool

  - Fixed SGA

See Also:

  - "Introduction to the Oracle Database Instance" on page 13-1

  - Oracle Database Performance Tuning Guide to learn more about granule sizing

*** Database Buffer Cache

The database buffer cache, also called the buffer cache, is the memory area that stores
copies of data blocks read from data files. A buffer is a main memory address in which the
buffer manager temporarily caches a currently or recently used data block. All users
concurrently connected to a database instance share access to the buffer cache.

Oracle Database uses the buffer cache to achieve the following goals:

  - Optimize physical I/O

    The database updates data blocks in the cache and stores metadata about the changes in
    the redo log buffer. After a COMMIT, the database writes the redo buffers to disk but
    does not immediately write data blocks to disk. Instead, database writer (DBWn)
    performs lazy writes in the background.

  - Keep frequently accessed blocks in the buffer cache and write infrequently accessed
    blocks to disk

    When Database Smart Flash Cache (flash cache) is enabled, part of the buffer cache can
    reside in the flash cache. This buffer cache extension is stored on a flash disk
    device, which is a solid state storage device that uses flash memory. The database can
    improve performance by caching buffers in flash memory instead of reading from
    magnetic disk.

  NB: Database Smart Flash Cache is available only in Solaris and Oracle Enterprise Linux.

**** Buffer States

The database uses internal algorithms to manage buffers in the cache. A buffer can be in
any of the following mutually exclusive states:

  - Unused

    The buffer is available for use because it has never been used or is currently
    unused. This type of buffer is the easiest for the database to use.

  - Clean

    This buffer was used earlier and now contains a read-consistent version of a block as
    of a point in time. The block contains data but is "clean" so it does not need to be
    checkpointed. The database can pin the block and reuse it.

  - Dirty

    The buffer contain modified data that has not yet been written to disk. The database
    must checkpoint the block before reusing it.

Every buffer has an access mode: pinned or free (unpinned). A buffer is "pinned" in the
cache so that it does not age out of memory while a user session accesses it. Multiple
sessions cannot modify a pinned buffer at the same time.

The database uses a sophisticated algorithm to make buffer access efficient. Pointers to
dirty and nondirty buffers exist on the same least recently used (LRU) list, which has a
hot end and cold end. A cold buffer is one that has not been recently used. A hot buffer
is frequently accessed and has been recently used.

  NB: Conceptually, there is only one LRU, but for concurrency the database actually uses
      several LRUs.

**** Buffer Modes

When a client requests data, Oracle Database retrieves buffers from the database buffer
cache in either of the following modes:

  - Current mode

    A current mode get, also called a db block get, is a retrieval of a block as it
    currently appears in the buffer cache. For example, if an uncommitted transaction has
    updated two rows in a block, then a current mode get retrieves the block with these
    uncommitted rows. The database uses db block gets most frequently during modification
    statements, which must update only the current version of the block.

  - Consistent mode

    A consistent read get is a retrieval of a read-consistent version of a block. This
    retrieval may use undo data. For example, if an uncommitted transaction has updated
    two rows in a block, and if a query in a separate session requests the block, then the
    database uses undo data to create a read-consistent version of this block (called a
    consistent read clone) that does not include the uncommitted updates. Typically, a
    query retrieves blocks in consistent mode.

See Also:

  - "Read Consistency and Undo Segments" on page 9-3

  - Oracle Database Reference for descriptions of database statistics such as db block get
    and consistent read get

**** Buffer I/O

A logical I/O, also known as a buffer I/O, refers to reads and writes of buffers in the
buffer cache. When a requested buffer is not found in memory, the database performs a
physical I/O to copy the buffer from either the flash cache or disk into memory, and then
a logical I/O to read the cached buffer.

***** Buffer Writes

The database writer (DBWn) process periodically writes cold, dirty buffers to disk. DBWn
writes buffers in the following circumstances:

  - A server process cannot find clean buffers for reading new blocks into the database
    buffer cache.

    As buffers are dirtied, the number of free buffers decreases. If the number drops
    below an internal threshold, and if clean buffers are required, then server processes
    signal DBWn to write.

    The database uses the LRU to determine which dirty buffers to write. When dirty
    buffers reach the cold end of the LRU, the database moves them off the LRU to a write
    queue. DBWn writes buffers in the queue to disk, using multiblock writes if
    possible. This mechanism prevents the end of the LRU from becoming clogged with dirty
    buffers and allows clean buffers to be found for reuse.

  - The database must advance the checkpoint, which is the position in the redo thread
    from which instance recovery must begin.

  - Tablespaces are changed to read-only status or taken offline.

See Also:

  - "Database Writer Process (DBWn)" on page 15-8

  - Oracle Database Performance Tuning Guide to learn how to diagnose and tune buffer
    write issues

***** Buffer Reads

When the number of clean or unused buffers is low, the database must remove buffers from
the buffer cache. The algorithm depends on whether the flash cache is enabled:

  - Flash cache disabled

    The database re-uses each clean buffer as needed, overwriting it. If the overwritten
    buffer is needed later, then the database must read it from magnetic disk.

  - Flash cache enabled

    DBWn can write the body of a clean buffer to the flash cache, enabling reuse of its
    in-memory buffer. The database keeps the buffer header in an LRU list in main memory
    to track the state and location of the buffer body in the flash cache. If this buffer
    is needed later, then the database can read it from the flash cache instead of from
    magnetic disk.

When a client process requests a buffer, the server process searches the buffer cache for
the buffer. A cache hit occurs if the database finds the buffer in memory. The search
order is as follows:

  1- The server process searches for the whole buffer in the buffer cache.

     If the process finds the whole buffer, then the database performs a logical read of
     this buffer.

  2- The server process searches for the buffer header in the flash cache LRU list.

     If the process finds the buffer header, then the database performs an optimized
     physical read of the buffer body from the flash cache into the in-memory cache.

  3- If the process does not find the buffer in memory (a cache miss), then the server
     process performs the following steps:

     a- Copies the block from a data file into memory (a physical read)

     b- Performs a logical read of the buffer that was read into memory

In general, accessing data through a cache hit is faster than through a cache miss. The
buffer cache hit ratio measures how often the database found a requested block in the
buffer cache without needing to read it from disk.

The database can perform physical reads from either a data file or a temp file. Reads from
a data file are followed by logical I/Os. Reads from a temp file occur when insufficient
memory forces the database write data to a temporary table and read it back later. These
physical reads bypass the buffer cache and do not incur a logical I/O.

See Also:

  - Oracle Database Performance Tuning Guide to learn how to calculate the buffer cache
    hit ratio

***** Buffer Touch Counts

The database measures the frequency of access of buffers on the LRU list using a touch
count. This mechanism enables the database to increment a counter when a buffer is pinned
instead of constantly shuffling buffers on the LRU list.

  NB: The database does not physically move blocks in memory. The movement is the change
      in location of a pointer on a list.

When a buffer is pinned, the database determines when its touch count was last
incremented.  If the count was incremented over three seconds ago, then the count is
incremented; otherwise, the count stays the same. The three-second rule prevents a burst
of pins on a buffer counting as many touches. For example, a session may insert several
rows in a data block, but the database considers these inserts as one touch.

If a buffer is on the cold end of the LRU, but its touch count is high, then the buffer
moves to the hot end. If the touch count is low, then the buffer ages out of the cache.

***** Buffers and Full Table Scans

When buffers must be read from disk, the database inserts the buffers into the middle of
the LRU list. In this way, hot blocks can remain in the cache so that they do not need to
be read from disk again.

A problem is posed by a full table scan, which sequentially reads all rows under the table
high water mark (see "Segment Space and the High Water Mark" on page 12-27). Suppose that
the total size of the blocks in a table segment is greater than the size of the buffer
cache. A full scan of this table could clean out the buffer cache, preventing the database
from maintaining a cache of frequently accessed blocks.

Blocks read into the database cache as the result of a full scan of a large table are
treated differently from other types of reads. The blocks are immediately available for
reuse to prevent the scan from effectively cleaning out the buffer cache.

In the rare case where the default behavior is not desired, you can change the CACHE
attribute of the table. In this case, the database does not force or pin the blocks in the
buffer cache, but ages them out of the cache in the same way as any other block. Use care
when exercising this option because a full scan of a large table may clean most of the
other blocks out of the cache.

See Also:

  - Oracle Database SQL Language Reference for information about the CACHE clause

  - Oracle Database Performance Tuning Guide to learn how to interpret buffer cache
    advisory statistics

**** Buffer Pools

A buffer pool is a collection of buffers. The database buffer cache is divided into one or
more buffer pools.

You can manually configure separate buffer pools that either keep data in the buffer cache
or make the buffers available for new data immediately after using the data blocks. You
can then assign specific schema objects to the appropriate buffer pool to control how
blocks age out of the cache.

The possible buffer pools are as follows:

  - Default pool

    This pool is the location where blocks are normally cached. Unless you manually
    configure separate pools, the default pool is the only buffer pool.

  - Keep pool

    This pool is intended for blocks that were accessed frequently, but which aged out of
    the default pool because of lack of space. The goal of the keep buffer pool is to
    retain objects in memory, thus avoiding I/O operations.

  - Recycle pool

    This pool is intended for blocks that are used infrequently. A recycle pool prevent
    objects from consuming unnecessary space in the cache.

A database has a standard block size (see "Database Block Size" on page 12-7). You can
create a tablespace with a block size that differs from the standard size. Each nondefault
block size has its own pool. Oracle Database manages the blocks in these pools in the same
way as in the default pool.

See Also:

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn more
    about buffer pools

  - Oracle Database Performance Tuning Guide to learn how to use multiple buffer pools

*** Redo Log Buffer

The redo log buffer is a circular buffer in the SGA that stores redo entries describing
changes made to the database. Redo entries contain the information necessary to
reconstruct, or redo, changes made to the database by DML or DDL operations. Database
recovery applies redo entries to data files to reconstruct lost changes.

Oracle Database processes copy redo entries from the user memory space to the redo log
buffer in the SGA. The redo entries take up continuous, sequential space in the
buffer. The background process log writer (LGWR) writes the redo log buffer to the active
online redo log group on disk.

LGWR writes redo sequentially to disk while DBWn performs scattered writes of data blocks
to disk. Scattered writes tend to be much slower than sequential writes. Because LGWR
enable users to avoid waiting for DBWn to complete its slow writes, the database delivers
better performance.

The LOG_BUFFER initialization parameter specifies the amount of memory that Oracle
Database uses when buffering redo entries. Unlike other SGA components, the redo log
buffer and fixed SGA buffer do not divide memory into granules.

See Also:

  - "Log Writer Process (LGWR)" on page 15-9 and "Importance of Checkpoints for Instance
    Recovery" on page 13-13

  - Oracle Database Administrator's Guide for information about the online redo log

*** Shared Pool

The shared pool caches various types of program data. For example, the shared pool stores
parsed SQL, PL/SQL code, system parameters, and data dictionary information. The shared
pool is involved in almost every operation that occurs in the database. For example, if a
user executes a SQL statement, then Oracle Database accesses the shared pool.

The shared pool is divided into several subcomponents, the most important of which are
shown in:

./oracle-concepts-figure-shared-pool.png

**** Library Cache

The library cache is a shared pool memory structure that stores executable SQL and PL/SQL
code. This cache contains the shared SQL and PL/SQL areas and control structures such as
locks and library cache handles. In a shared server architecture, the library cache also
contains private SQL areas.

When a SQL statement is executed, the database attempts to reuse previously executed
code. If a parsed representation of a SQL statement exists in the library cache and can be
shared, then the database reuses the code, known as a soft parse or a library cache hit.
Otherwise, the database must build a new executable version of the application code, known
as a hard parse or a library cache miss.

***** Shared SQL Areas

The database represents each SQL statement that it runs in the following SQL areas:

  - Shared SQL area

    The database uses the shared SQL area to process the first occurrence of a SQL
    statement. This area is accessible to all users and contains the statement parse tree
    and execution plan. Only one shared SQL area exists for a unique statement.

  - Private SQL area

    Each session issuing a SQL statement has a private SQL area in its PGA (see "Private
    SQL Area" on page 14-5). Each user that submits the same statement has a private SQL
    area pointing to the same shared SQL area. Thus, many private SQL areas in separate
    PGAs can be associated with the same shared SQL area.

    The database automatically determines when applications submit similar SQL
    statements. The database considers both SQL statements issued directly by users and
    applications and recursive SQL statements issued internally by other statements.

    The database performs the following steps:

    1. Checks the shared pool to see if a shared SQL area exists for a syntactically and
       semantically identical statement:

      - If an identical statement exists, then the database uses the shared SQL area for
        the execution of the subsequent new instances of the statement, thereby reducing
        memory consumption.

      - If an identical statement does not exist, then the database allocates a new shared
        SQL area in the shared pool. A statement with the same syntax but different
        semantics uses a child cursor.

      In either case, the private SQL area for the user points to the shared SQL area that
      contains the statement and execution plan.

    2. Allocates a private SQL area on behalf of the session

       The location of the private SQL area depends on the connection established for the
       session. If a session is connected through a shared server, then part of the
       private SQL area is kept in the SGA.

See Also:

  - Oracle Database Performance Tuning Guide to learn more about managing the library cache

  - Oracle Database Advanced Application Developer's Guide for more information about
    shared SQL

***** Program Units and the Library Cache

The library cache holds executable forms of PL/SQL programs and Java classes. These items
are collectively referred to as program units.

The database processes program units similarly to SQL statements. For example, the
database allocates a shared area to hold the parsed, compiled form of a PL/SQL program.
The database allocates a private area to hold values specific to the session that runs the
program, including local, global, and package variables, and buffers for executing SQL. If
multiple users run the same program, then each user maintains a separate copy of his or
her private SQL area, which holds session-specific values, and accesses a single shared
SQL area.

The database processes individual SQL statements within a PL/SQL program unit as
previously described.  Despite their origins within a PL/SQL program unit, these SQL
statements use a shared area to hold their parsed representations and a private area for
each session that runs the statement.

***** Allocation and Reuse of Memory in the Shared Pool

The database allocates shared pool memory when a new SQL statement is parsed. The memory
size depends on the complexity of the statement.

In general, an item in the shared pool stays until it is removed according to an LRU
algorithm.  The database allows shared pool items used by many sessions to remain in
memory as long as they are useful, even if the process that created the item terminates.
This mechanism minimizes the overhead and processing of SQL statements.

If space is needed for new items, then the database frees memory for infrequently used
items.  A shared SQL area can be removed from the shared pool even if the shared SQL area
corresponds to an open cursor that has not been used for some time.  If the open cursor is
subsequently used to run its statement, then Oracle Database reparses the statement and
allocates a new shared SQL area.

The database also removes a shared SQL area from the shared pool in the following
circumstances:

  - If statistics are gathered for a table, table cluster, or index, then by default the
    database gradually removes all shared SQL areas that contain statements referencing
    the analyzed object after a period of time. The next time a removed statement is run,
    the database parses it in a new shared SQL area to reflect the new statistics for the
    schema object.

  - If a schema object is referenced in a SQL statement, and if this object is later
    modified by a DDL statement, then the database invalidates the shared SQL area. The
    optimizer must reparse the statement the next time it is run.

  - If you change the global database name, then the database removes all information from
    the shared pool.

You can use the ALTER SYSTEM FLUSH SHARED_POOL statement to manually remove all
information in the shared pool to assess the performance that can be expected after an
instance restart.

See Also:

  - Oracle Database SQL Language Reference for information about using ALTER SYSTEM FLUSH
    SHARED_POOL

  - Oracle Database Reference for information about V$SQL and V$SQLAREA dynamic views

**** Data Dictionary Cache

The data dictionary is a collection of database tables and views containing reference
information about the database, its structures, and its users. Oracle Database accesses
the data dictionary frequently during SQL statement parsing.

The data dictionary is accessed so often by Oracle Database that the following special
memory locations are designated to hold dictionary data:

  - Data dictionary cache

    This cache holds information about database objects. The cache is also known as the
    row cache because it holds data as rows instead of buffers.

  - Library cache

All server processes share these caches for access to data dictionary information.

See Also:

  - Chapter 6, "Data Dictionary and Dynamic Performance Views"

  - Oracle Database Performance Tuning Guide to learn how to allocate additional memory to
    the data dictionary cache

**** Server Result Cache

JWM: SKIPPED THE REST OF THIS CHAPTER INCLUDING:

***** SQL Query Result Cache
***** PL/SQL Function Result Cache
**** Reserved Pool
*** Large Pool
*** Java Pool
*** Streams Pool
*** Fixed SGA
** Overview of Software Code Areas

* Chapter 15: Process Architecture

** Introduction to Processes

A process is a mechanism in an operating system that can run a series of steps. The
mechanism depends on the operating system. For example, on Linux an Oracle background
process is a Linux process. On Windows, an Oracle background process is a thread of
execution within a process.

Code modules are run by processes. All connected Oracle Database users must run the
following modules to access a database instance:

  - Application or Oracle Database utility

    A database user runs a database application, such as a precompiler program or a
    database tool such as SQL*Plus, that issues SQL statements to a database.

  - Oracle database code

    Each user has Oracle database code executing on his or her behalf that interprets and
    processes the application's SQL statements.

A process normally runs in its own private memory area. Most processes can periodically
write to an associated trace file (see "Trace Files" on page 13-22).

See Also:

  - "Tools for Database Administrators" on page 18-2 and "Tools for Database Developers"
    on page 19-1

** Multiple-Process Oracle Database Systems

Multiple-process Oracle (also called multiuser Oracle) uses several processes to run
different parts of the Oracle Database code and additional processes for the usersâ€”either
one process for each connected user or one or more processes shared by multiple
users. Most databases are multiuser because a primary advantages of a database is managing
data needed by multiple users simultaneously.

Each process in a database instance performs a specific job. By dividing the work of the
database and applications into several processes, multiple users and applications can
connect to an instance simultaneously while the system gives good performance.

** Types of Processes

A database instance contains or interacts with the following types of processes:

  - Client processes run the application or Oracle tool code.

  - Oracle processes run the Oracle database code. Oracle processes including the
    following subtypes:

    - Background processes start with the database instance and perform maintenance tasks
      such as performing instance recovery, cleaning up processes, writing redo buffers to
      disk, and so on.

    - Server processes perform work based on a client request.

      For example, these processes parse SQL queries, place them in the shared pool,
      create and execute a query plan for each query, and read buffers from the database
      buffer cache or from disk.

      NB: Server processes, and the process memory allocated in these processes, run in
          the instance. The instance continues to function when server processes
          terminate.

    - Slave processes perform additional tasks for a background or server process.

The process structure varies depending on the operating system and the choice of Oracle
Database options. For example, the code for connected users can be configured for
dedicated server or shared server connections. In a shared server architecture, each
server process that runs database code can serve multiple client processes.

./oracle-concepts-figure-processes.png

shows a system global area (SGA) and background processes using dedicated server
connections. For each user connection, the application is run by a client process that is
different from the dedicated server process that runs the database code. Each client
process is associated with its own server process, which has its own program global area
(PGA).

See Also:

  - "Dedicated Server Architecture" on page 16-9 and "Shared Server Architecture" on page
    16-11

  - Your Oracle Database operating system-specific documentation for more details on
    configuration choices

  - Oracle Database Reference to learn about the V$PROCESS view

** Overview of Client Processes

When a user runs an application such as a Pro*C program or SQL*Plus, the operating system
creates a client process (sometimes called a user process) to run the user application.
The client application has Oracle Database libraries linked into it that provide the APIs
required to communicate with the database.

*** Client and Server Processes

Client processes differ in important ways from the Oracle processes interacting directly
with the instance. The Oracle processes servicing the client process can read from and
write to the SGA, whereas the client process cannot. A client process can run on a host
other than the database host, whereas Oracle processes cannot.

*** Connections and Sessions

A connection is a physical communication pathway between a client process and a database
instance. A communication pathway is established using available interprocess
communication mechanisms or network software. Typically, a connection occurs between a
client process and a server process or dispatcher, but it can also occur between a client
process and Oracle Connection Manager (CMAN).

A session is a logical entity in the database instance memory that represents the state of
a current user login to a database. For example, when a user is authenticated by the
database with a password, a session is established for this user. A session lasts from the
time the user is authenticated by the database until the time the user disconnects or
exits the database application.

A single connection can have 0, 1, or more sessions established on it. The sessions are
independent: a commit in one session does not affect transactions in other sessions.

  NB: If Oracle Net connection pooling is configured, then it is possible for a connection
      to drop but leave the sessions intact.

Multiple sessions can exist concurrently for a single database user. As shown in Figure
15â€“2, user hr can have multiple connections to a database. In dedicated server
connections, the database creates a server process on behalf of each connection. Only the
client process that causes the dedicated server to be created uses it. In a shared server
connection, many client processes access a single shared server process.

Generating an autotrace report of SQL statement execution statistics re-creates the
scenario in Figure 15â€“3. Example 15â€“2 connects SQL*Plus to the database as user SYSTEM and
enables tracing, thus creating a new session (sample output included).

Example 15â€“1  One Connection with Two Sessions

  SQL> SELECT SID, SERIAL#, PADDR FROM V$SESSION WHERE USERNAME = USER;

  SID SERIAL# PADDR
  --- ------- --------
   90      91 3BE2E41C

  SQL> SET AUTOTRACE ON STATISTICS;
  SQL> SELECT SID, SERIAL#, PADDR FROM V$SESSION WHERE USERNAME = USER;

  SID SERIAL# PADDR
  --- ------- --------
   88      93 3BE2E41C
   90      91 3BE2E41C

  SQL> DISCONNECT

The DISCONNECT command in Example 15â€“1 actually ends the sessions, not the connection.
Opening a new terminal and connecting to the instance as a different user, the query in
Example 15â€“2 shows that the connection from Example 15â€“1 is still active.

Example 15â€“2 Connection with No Sessions

  SQL> CONNECT dba1@inst1
  Password: ********
  Connected.
  SQL> SELECT PROGRAM FROM V$PROCESS WHERE ADDR = HEXTORAW('3BE2E41C');

  PROGRAM
  ------------------------------------------------
  oracle@stbcs09-1 (TNS V1-V3)

See Also: 

  - "Shared Server Architecture" on page 16-11

** Overview of Server Processes

Oracle Database creates server processes to handle the requests of client processes
connected to the instance. A client process always communicates with a database through a
separate server process.  

Server processes created on behalf of a database application can perform one or more of
the following tasks:

  - Parse and run SQL statements issued through the application, including creating and
    executing the query plan (see "Stages of SQL Processing" on page 7-15)

  - Execute PL/SQL code

  - Read data blocks from data files into the database buffer cache (the DBWn background
    process has the task of writing modified blocks back to disk)

  - Return results in such a way that the application can process the information

*** Dedicated Server Processes

In dedicated server connections, the client connection is associated with one and only one
server process (see "Dedicated Server Architecture" on page 16-9). On Linux, 20 client
processes connected to a database instance are serviced by 20 server processes.

Each client process communicates directly with its server process. This server process is
dedicated to its client process for the duration of the session. The server process stores
process-specific information and the UGA in its PGA (see "PGA Usage in Dedicated and
Shared Server Modes" on page 14-7).

*** Shared Server Processes

In shared server connections, client applications connect over a network to a dispatcher
process, not a server process (see "Shared Server Architecture" on page 16-11). For
example, 20 client processes can connect to a single dispatcher process.

The dispatcher process receives requests from connected clients and puts them into a
request queue in the large pool (see "Large Pool" on page 14-21). The first available
shared server process takes the request from the queue and processes it. Afterward, the
shared server place the result into the dispatcher response queue. The dispatcher process
monitors this queue and transmits the result to the client.

Like a dedicated server process, a shared server process has its own PGA. However, the UGA
for a session is in the SGA so that any shared server can access session data.

** Overview of Background Processes

A multiprocess Oracle database uses some additional processes called background processes.
The background processes perform maintenance tasks required to operate the database and to
maximize performance for multiple users.

Each background process has a separate task, but works with the other processes. For
example, the LGWR process writes data from the redo log buffer to the online redo log.
When a filled log file is ready to be archived, LGWR signals another process to archive
the file.

Oracle Database creates background processes automatically when a database instance
starts.  An instance can have many background processes, not all of which always exist in
every database configuration. The following query lists the background processes running
on your database:

  SELECT PNAME
    FROM V$PROCESS
   WHERE PNAME IS NOT NULL
   ORDER BY PNAME;

See Also:

  - Oracle Database Reference for descriptions of all the background processes

*** Mandatory Background Processes

The mandatory background processes are present in all typical database configurations.
These processes run by default in a database instance started with a minimally configured
initialization parameter file (see Example 13â€“1 on page 13-20).

See Also:

  - Oracle Database Reference for descriptions of other mandatory processes, including
    MMAN, DIAG, VKTM, DBRM, and PSP0

  - Oracle Real Application Clusters Administration and Deployment Guide and Oracle
    Clusterware Administration and Deployment Guide for more information about background
    processes specific to Oracle RAC and Oracle Clusterware

**** Process Monitor Process (PMON)

The process monitor (PMON) monitors the other background processes and performs process
recovery when a server or dispatcher process terminates abnormally. PMON is responsible
for cleaning up the database buffer cache and freeing resources that the client process
was using. For example, PMON resets the status of the active transaction table, releases
locks that are no longer required, and removes the process ID from the list of active
processes.

PMON also registers information about the instance and dispatcher processes with the
Oracle Net listener (see "The Oracle Net Listener" on page 16-6). When an instance starts,
PMON polls the listener to determine whether it is running. If the listener is running,
then PMON passes it relevant parameters. If it is not running, then PMON periodically
attempts to contact it.

**** System Monitor Process (SMON)

The system monitor process (SMON) is in charge of a variety of system-level cleanup
duties. The duties assigned to SMON include:

  - Performing instance recovery, if necessary, at instance startup. In an Oracle RAC
    database, the SMON process of one database instance can perform instance recovery for
    a failed instance.

  - Recovering terminated transactions that were skipped during instance recovery because
    of file-read or tablespace offline errors. SMON recovers the transactions when the
    tablespace or file is brought back online.

  - Cleaning up unused temporary segments. For example, Oracle Database allocates extents
    when creating an index. If the operation fails, then SMON cleans up the temporary
    space.

  - Coalescing contiguous free extents within dictionary-managed tablespaces.

SMON checks regularly to see whether it is needed. Other processes can call SMON if they
detect a need for it.

**** Database Writer Process (DBWn)

The database writer process (DBWn) writes the contents of database buffers to data
files. DBWn processes write modified buffers in the database buffer cache to disk (see
"Database Buffer Cache" on page 14-9).

Although one database writer process (DBW0) is adequate for most systems, you can
configure additional processesâ€”DBW1 through DBW9 and DBWa through DBWjâ€”to improve write
performance if your system modifies data heavily. These additional DBWn processes are not
useful on uniprocessor systems.

The DBWn process writes dirty buffers to disk under the following conditions:

  - When a server process cannot find a clean reusable buffer after scanning a threshold
    number of buffers, it signals DBWn to write. DBWn writes dirty buffers to disk
    asynchronously if possible while performing other processing.

  - DBWn periodically writes buffers to advance the checkpoint, which is the position in
    the redo thread from which instance recovery begins (see "Overview of Checkpoints" on
    page 13-11). The log position of the checkpoint is determined by the oldest dirty
    buffer in the buffer cache.

In many cases the blocks that DBWn writes are scattered throughout the disk. Thus, the
writes tend to be slower than the sequential writes performed by LGWR. DBWn performs
multiblock writes when possible to improve efficiency. The number of blocks written in a
multiblock write varies by operating system.

See Also:

  - Oracle Database Performance Tuning Guide for advice on configuring, monitoring, and
    tuning DBWn

**** Log Writer Process (LGWR)

The log writer process (LGWR) manages the redo log buffer. LGWR writes one contiguous
portion of the buffer to the online redo log. By separating the tasks of modifying
database buffers, performing scattered writes of dirty buffers to disk, and performing
fast sequential writes of redo to disk, the database improves performance.

In the following circumstances, LGWR writes all redo entries that have been copied into
the buffer since the last time it wrote:

  - A user commits a transaction (see "Committing Transactions" on page 10-10).

  - An online redo log switch occurs.

  - Three seconds have passed since LGWR last wrote.

  - The redo log buffer is one-third full or contains 1 MB of buffered data.

  - DBWn must write modified buffers to disk.

    Before DBWn can write a dirty buffer, redo records associated with changes to the
    buffer must be written to disk (the write-ahead protocol). If DBWn finds that some
    redo records have not been written, it signals LGWR to write the records to disk and
    waits for LGWR to complete before writing the data buffers to disk.

***** LGWR and Commits

Oracle Database uses a fast commit mechanism to improve performance for committed
transactions.  When a user issues a COMMIT statement, the transaction is assigned a system
change number (SCN).  LGWR puts a commit record in the redo log buffer and writes it to
disk immediately, along with the commit SCN and transaction's redo entries.

The redo log buffer is circular. When LGWR writes redo entries from the redo log buffer to
an online redo log file, server processes can copy new entries over the entries in the
redo log buffer that have been written to disk. LGWR normally writes fast enough to ensure
that space is always available in the buffer for new entries, even when access to the
online redo log is heavy.

The atomic write of the redo entry containing the transaction's commit record is the
single event that determines the transaction has committed. Oracle Database returns a
success code to the committing transaction although the data buffers have not yet been
written to disk. The corresponding changes to data blocks are deferred until it is
efficient for DBWn to write them to the data files.

  NB: LGWR can write redo log entries to disk before a transaction commits. The redo
      entries become permanent only if the transaction later commits.

When activity is high, LGWR can use group commits. For example, a user commits, causing
LGWR to write the transaction's redo entries to disk. During this write other users
commit. LGWR cannot write to disk to commit these transactions until its previous write
completes. Upon completion, LGWR can write the list of redo entries of waiting
transactions (not yet committed) in one operation. In this way, the database minimizes
disk I/O and maximizes performance. If commits requests continue at a high rate, then
every write by LGWR can contain multiple commit records.

***** LGWR and Inaccessible Files

LGWR writes synchronously to the active mirrored group of online redo log files. If a log
file is inaccessible, then LGWR continues writing to other files in the group and writes
an error to the LGWR trace file and the alert log. If all files in a group are damaged, or
if the group is unavailable because it has not been archived, then LGWR cannot continue to
function.

See Also:

  - "How Oracle Database Writes to the Online Redo Log" on page 11-12 and "Redo Log
    Buffer" on page 14-14

  - Oracle Database Performance Tuning Guide for information about how to monitor and tune
    the performance of LGWR

**** Checkpoint Process (CKPT)

The checkpoint process (CKPT) updates the control file and data file headers with
checkpoint information and signals DBWn to write blocks to disk. Checkpoint information
includes the checkpoint position, SCN, location in online redo log to begin recovery, and
so on. As shown in

./oracle-concepts-figure-checkpoint.png

CKPT does not write data blocks to data files or redo blocks to online redo log files.

**** Manageability Monitor Processes (MMON and MMNL)

The manageability monitor process (MMON) performs many tasks related to the Automatic
Workload Repository (AWR). For example, MMON writes when a metric violates its threshold
value, taking snapshots, and capturing statistics value for recently modified SQL objects.

The manageability monitor lite process (MMNL) writes statistics from the Active Session
History (ASH) buffer in the SGA to disk. MMNL writes to disk when the ASH buffer is full.

See Also:

  - "Automatic Workload Repository (AWR)" on page 18-21 and "Active Session History (ASH)"
    on page 18-23

**** Recoverer Process (RECO)

In a distributed database, the recoverer process (RECO) automatically resolves failures in
distributed transactions. The RECO process of a node automatically connects to other
databases involved in an in-doubt distributed transaction. When RECO reestablishes a
connection between the databases, it automatically resolves all in-doubt transactions,
removing from each database's pending transaction table any rows that correspond to the
resolved transactions.

See Also:

  - Oracle Database Administrator's Guide for more information about transaction recovery
    in distributed systems

*** Optional Background Processes

An optional background process is any background process not defined as mandatory. Most
optional background processes are specific to tasks or features. For example, background
processes that support Oracle Streams Advanced Queuing (AQ) or Oracle Automatic Storage
Management (Oracle ASM) are only available when these features are enabled.

See Also:

  - "Oracle Streams Advanced Queuing (AQ)" on page 17-23

  - Oracle Database Reference for descriptions of background processes specific to AQ and
    ASM

**** Archiver Processes (ARCn)

The archiver processes (ARCn) copy online redo log files to offline storage after a redo
log switch occurs. These processes can also collect transaction redo data and transmit it
to standby database destinations. ARCn processes exist only when the database is in
ARCHIVELOG mode and automatic archiving is enabled.

See Also:

  - "Archived Redo Log Files" on page 11-15

  - Oracle Database Administrator's Guide to learn how to adjust the number of archiver
    processes

  - Oracle Database Performance Tuning Guide to learn how to tune archiver performance

**** Job Queue Processes (CJQ0 and Jnnn)

Oracle Database uses job queue processes to run user jobs, often in batch mode. A job is a
user-defined task scheduled to run one or more times. For example, you can use a job queue
to schedule a long-running update in the background. Given a start date and a time
interval, the job queue processes attempt to run the job at the next occurrence of the
interval.

Oracle Database manages job queue processes dynamically, thereby enabling job queue
clients to use more job queue processes when required. The database releases resources
used by the new processes when they are idle.

Dynamic job queue processes can run a large number of jobs concurrently at a given
interval. The sequence of events is as follows:

  - The job coordinator process (CJQ0) is automatically started and stopped as needed by
    Oracle Scheduler (see "Oracle Scheduler" on page 18-19). The coordinator process
    periodically selects jobs that need to be run from the system JOB$ table. New jobs
    selected are ordered by time.

  - The coordinator process dynamically spawns job queue slave processes (Jnnn) to run the
    jobs.

  - The job queue process runs one of the jobs that was selected by the CJQ0 process for
    execution. Each job queue process runs one job at a time to completion.

  - After the process finishes execution of a single job, it polls for more jobs. If no
    jobs are scheduled for execution, then it enters a sleep state, from which it wakes up
    at periodic intervals and polls for more jobs. If the process does not find any new
    jobs, then it terminates after a preset interval.

The initialization parameter JOB_QUEUE_PROCESSES represents the maximum number of job
queue processes that can concurrently run on an instance. However, clients should not
assume that all job queue processes are available for job execution.

  NB: The coordinator process is not started if the initialization parameter
      JOB_QUEUE_PROCESSES is set to 0.

See Also:

  - Oracle Database Administrator's Guide to learn about Oracle Scheduler jobs

  - Oracle Streams Advanced Queuing User's Guide to learn about AQ background processes

**** Flashback Data Archiver Process (FBDA)

The flashback data archiver process (FBDA) archives historical rows of tracked tables into
Flashback Data Archives. When a transaction containing DML on a tracked table commits,
this process stores the pre-image of the rows into the Flashback Data Archive. It also
keeps metadata on the current rows.

FBDA automatically manages the flashback data archive for space, organization, and
retention. Additionally, the process keeps track of how far the archiving of tracked
transactions has occurred.

**** Space Management Coordinator Process (SMCO)

The SMCO process coordinates the execution of various space management related tasks, such
as proactive space allocation and space reclamation. SMCO dynamically spawns slave
processes (Wnnn) to implement the task.

See Also:

  - Oracle Database Advanced Application Developer's Guide to learn about Flashback Data
    Archive

*** Slave Processes

Slave processes are background processes that perform work on behalf of other processes.
This section describes some slave processes used by Oracle Database.

See Also:

  - Oracle Database Reference for descriptions of Oracle Database slave processes

**** I/O Slave Processes

I/O slave processes (Innn) simulate asynchronous I/O for systems and devices that do not
support it. In asynchronous I/O, there is no timing requirement for transmission, enabling
other processes to start before the transmission has finished.

For example, assume that an application writes 1000 blocks to a disk on an operating
system that does not support asynchronous I/O. Each write occurs sequentially and waits
for a confirmation that the write was successful. With asynchronous disk, the application
can write the blocks in bulk and perform other work while waiting for a response from the
operating system that all blocks were written.

To simulate asynchronous I/O, one process oversees several slave processes. The invoker
process assigns work to each of the slave processes, who wait for each write to complete
and report back to the invoker when done. In true asynchronous I/O the operating system
waits for the I/O to complete and reports back to the process, while in simulated
asynchronous I/O the slaves wait and report back to the invoker.

The database supports different types of I/O slaves, including the following:

  - I/O slaves for Recovery Manager (RMAN)

    When using RMAN to back up or restore data, you can make use of I/O slaves for both
    disk and tape devices.

  - Database writer slaves

    If it is not practical to use multiple database writer processes, such as when the
    computer has one CPU, then the database can distribute I/O over multiple slave
    processes.  DBWR is the only process that scans the buffer cache LRU list for blocks
    to be written to disk. However, I/O slaves perform the I/O for these blocks.

See Also:

  - Oracle Database Backup and Recovery User's Guide to learn more about I/O slaves for
    backup and restore operations

  - Oracle Database Performance Tuning Guide to learn more about database writer slaves

**** Parallel Query Slaves

In parallel execution or parallel processing, multiple processes work together
simultaneously to run a single SQL statement. By dividing the work among multiple
processes, Oracle Database can run the statement more quickly. For example, four processes
handle four different quarters in a year instead of one process handling all four quarters
by itself.

Parallel execution reduces response time for data-intensive operations on large databases
such as data warehouses. Symmetric multiprocessing (SMP) and clustered system gain the
largest performance benefits from parallel execution because statement processing can be
split up among multiple CPUs. Parallel execution can also benefit certain types of OLTP
and hybrid systems.

In Oracle RAC systems, the service placement of a particular service controls parallel
execution. Specifically, parallel processes run on the nodes on which you have configured
the service. By default, Oracle Database runs the parallel process only on the instance
that offers the service used to connect to the database. This does not affect other
parallel operations such as parallel recovery or the processing of GV$ queries.

See Also:

  - Oracle Database Data Warehousing Guide and Oracle Database VLDB and Partitioning Guide
    to learn more about parallel execution

  - Oracle Real Application Clusters Administration and Deployment Guide for
    considerations regarding parallel execution in Oracle RAC environments

***** Serial Execution

In serial execution, a single server process performs all necessary processing for the
sequential execution of a SQL statement.

***** Parallel Execution

In parallel execution, the server process acts as the parallel execution coordinator
responsible for parsing the query, allocating and controlling the slave processes, and
sending output to the user. Given a query plan for a SQL query, the coordinator breaks
down each operator in a SQL query into parallel pieces, runs them in the order specified
in the query, and integrates the partial results produced by the slave processes executing
the operators.

./oracle-concepts-figure-parallel-scan.png

shows a parallel scan of the employees table. The table is divided dynamically (dynamic
partitioning) into load units called granules. Each granule is a range of data blocks of
the table read by a single slave process, called a parallel execution server, which uses
Pnnn as a name format.

The database maps granules to execution servers at execution time. When an execution
server finishes reading the rows corresponding to a granule, and when granules remain, it
obtains another granule from the coordinator. This operation continues until the table has
been read. The execution servers send results back to the coordinator, which assembles the
pieces into the desired full table scan.

The number of parallel execution servers assigned to a single operation is the degree of
parallelism for an operation. Multiple operations within the same SQL statement all have
the same degree of parallelism.

See Also:

  - Oracle Database VLDB and Partitioning Guide to learn how to use parallel execution

  - Oracle Database Data Warehousing Guide to learn about recommended initialization
    parameters for parallelism

* Chapter 16: Application and Networking Architecture

** Overview of Oracle Application Architecture

In the context of this chapter, application architecture refers to the computing
environment in which a database application connects to an Oracle database.

*** Overview of Client/Server Architecture

In the Oracle Database environment, the database application and the database are
separated into a client/server architecture:

  - The client runs the database application, for example, SQL*Plus or a Visual Basic data
    entry program, that accesses database information and interacts with a user.

  - The server runs the Oracle Database software and handles the functions required for
    concurrent, shared data access to an Oracle database.

Although the client application and database can run on the same computer, greater
efficiency is often achieved when the client portions and server portion are run by
different computers connected through a network. The following sections discuss variations
in the Oracle Database client/server architecture.

**** Distributed Processing

  NB: This rest of this chapter applies to environments with one database on one server.

**** Advantages of a Client/Server Architecture

Oracle Database client/server architecture in a distributed processing environment
provides the following benefits:

  - Client applications are not responsible for performing data processing. Rather, they
    request input from users, request data from the server, and then analyze and present
    this data using the display capabilities of the client workstation or the terminal
    (for example, using graphics or spreadsheets).

  - Client applications are not dependent on the physical location of the data. Even if
    the data is moved or distributed to other database servers, the application continues
    to function with little or no modification.

  - Oracle Database exploits the multitasking and shared-memory facilities of its
    underlying operating system. As a result, it delivers the highest possible degree of
    concurrency, data integrity, and performance to its client applications.

  - Client workstations or terminals can be optimized for the presentation of data (for
    example, by providing graphics and mouse support), while the server can be optimized
    for the processing and storage of data (for example, by having large amounts of memory
    and disk space).

  - In networked environments, you can use inexpensive client workstations to access the
    remote data of the server effectively.

  - The database can be scaled as your system grows. You can add multiple servers to
    distribute the database processing load throughout the network (horizontally scaled),
    or you can move the database to a minicomputer or mainframe to take advantage of a
    larger system's performance (vertically scaled). In either case, data and applications
    are maintained with little or no modification because Oracle Database is portable
    between systems.

  - In networked environments, shared data is stored on the servers rather than on all
    computers, making it easier and more efficient to manage concurrent access.

  - In networked environments, client applications submit database requests to the server
    using SQL statements. After it is received, each SQL statement is processed by the
    server, which returns results to the client. Network traffic is minimized because only
    the requests and the results are shipped over the network.

See Also:

  - Oracle Database Administrator's Guide to learn more about distributed databases

*** Overview of Multitier Architecture

In a traditional multitier architecture environment, an application server provides data
for clients and serves as an interface between clients and database servers. This
architecture enables use of an application server to:

  - Validate the credentials of a client, such as a Web browser

  - Connect to a database server

  - Perform the requested operation

**** Clients

A client initiates a request for an operation to be performed on the database server. The
client can be a Web browser or other end-user program. In a multitier architecture, the
client connects to the database server through one or more application servers.

**** Application Servers

An application server provides access to the data for the client. It serves as an
interface between the client and one or more database servers, and hosts the applications.

An application server permits thin clients, which are clients equipped with minimal
software configurations, to access applications without requiring ongoing maintenance of
the client computers. The application server can also perform some data reformatting for
the client, reducing the load on the client workstation.

The application server assumes the identity of the client when it is performing operations
on the database server for that client. The privileges of the application server should be
restricted to prevent it from performing unneeded and unwanted operations during a client
operation.

**** Database Servers

A database server provides the data requested by an application server on behalf of a
client.  The database performs all of the query processing.

The database server can audit operations performed by the application server on behalf of
clients and operations performed by the application server on its own behalf (see
"Monitoring" on page 17-5). For example, a client operation can request information to
display on the client, while an application server operation can request a connection to
the database server.

**** Service Oriented Architecture (SOA)

The database can serve as a Web service provider in traditional multitier or
service-oriented architecture (SOA) environments. SOA is a multitier architecture relying
on services that support computer-to-computer interaction over a network. The services can
be dynamically discovered and queried on available functions and calling sequences.

SOA services are usually implemented as Web services accessible through the HTTP protocol.
They are based on XML standards such as WSDL and SOAP.

The Oracle Database Web service capability, which is implemented as part of XML DB, must
be specifically enabled by the DBA. Applications can then accomplish the following through
database Web services:

  - Submit SQL or XQuery queries and receive results as XML

  - Invoke standalone PL/SQL functions and receive results (see "PL/SQL Subprograms" on
    page 8-3)

  - Invoke PL/SQL package functions and receive results

Database Web services provide a simple way to add Web services to an application
environment without the need for an application server. However, invoking Web services
through application servers such as Oracle Fusion Middleware offers security, scalability,
UDDI registration, and reliable messaging in an SOA environment. However, because database
Web services integrate easily with Oracle Fusion Middleware, they may be appropriate for
optimizing SOA solutions.

See Also:

  - Oracle XML DB Developer's Guide for information on enabling and using database Web
    services

  - Oracle Fusion Middleware documentation for more information on SOA and Web services

*** Overview of Grid Architecture

In an Oracle Database environment, grid computing is a computing architecture that
effectively pools large numbers of servers and storage into a flexible, on-demand
computing resource. Modular hardware and software components can be connected and rejoined
on demand to meet the changing needs of businesses.

See Also:

  - "Overview of Grid Computing" on page 17-11 for more detailed information about server
    and storage grids

** Overview of Oracle Networking Architecture

Oracle Net Services is a suite of networking components that provides enterprise-wide
connectivity solutions in distributed, heterogeneous computing environments. Oracle Net
Services enables a network session from an application to a database instance and a
database instance to another database instance.

Oracle Net Services provides location transparency, centralized configuration and
management, and quick installation and configuration. It also lets you maximize system
resources and improve performance. The Oracle Database shared server architecture
increases the scalability of applications and the number of clients simultaneously
connected to the database. The Virtual Interface (VI) protocol places most of the
messaging burden on high-speed network hardware, freeing the CPU.

Oracle Net Services uses the communication protocols or application programmatic
interfaces (APIs) supported by a wide range of networks to provide distributed database
and distributed processing. After a network session is established, Oracle Net Services
acts as a data courier for the client application and the database server, establishing
and maintaining a connection and exchanging messages. Oracle Net Services can perform
these tasks because it exists on each computer in the network.

See Also:

  - Oracle Database Net Services Administrator's Guide for an overview of Oracle Net
    architecture

*** How Oracle Net Services Works

Oracle Database protocols take SQL statements from the interface of the Oracle
applications and package them for transmission to Oracle Database through a supported
industry-standard higher level protocol or API. Replies from Oracle Database are packaged
through the same higher level communications mechanism. This work occurs independently of
the network operating system.

Depending on the operating system that runs Oracle Database, the Oracle Net Services
software of the database server could include the driver software and start an additional
background process.

**** The Oracle Net Listener

The Oracle Net Listener, also called the listener, is a server-side process that listens
for incoming client connection requests and manages traffic to the database. When a
database instance starts, and at various times during its life, the instance contacts a
listener and establishes a communication pathway to this instance.

Service registration enables the listener to determine whether a database service and its
service handlers are available. A service handler is a dedicated server process or
dispatcher that acts as a connection point to a database. During registration, the PMON
process provides the listener with the instance name, database service names, and the type
and addresses of service handlers. This information enables the listener to start a
service handler when a client request arrives.

./oracle-concepts-figure-listener-db.png

shows two databases, each on a separate host. The database environment is serviced by two
listeners, each on a separate host. The PMON process running in each database instance
communicates with both listeners to register the database.

./oracle-concepts-figure-listener-arch.png

shows a browser making an HTTP connection and a client making a database connection
through a listener. The listener does not need to reside on the database host.

The basic steps by which a client establishes a connection through a listener are:

  - A client process or another database requests a connection.

  - The listener selects an appropriate service handler to service the client request and
    forwards the request to the handler.

  - The client process connects directly to the service handler. The listener is no longer
    involved in the communication.

See Also:

  - "Overview of Client Processes" on page 15-3 and "Overview of Server Processes" on page
    15-6

**** Service Names

In the context of net services, a service is a set of one or more database instances. A
service name is a logical representation of a service used for client connections.

When a client connects to a listener, it requests a connection to a service. When a
database instance starts, it registers itself with a listener as providing one or more
services by name. Thus, the listener acts as a mediator between the client and instances
and routes the connection request to the right place.

A single service, as known by a listener, can identify one or more database instances.
Also, a single database instance can register one or more services with a listener.
Clients connecting to a service need not specify which instance they require.

Figure 16-5 shows one single-instance database associated with two services, book.example.com and
soft.example.com. The services enable the same database to be identified differently by
different clients. A database administrator can limit or reserve system resources,
permitting better resource allocation to clients requesting one of these services.

See Also:

  - Oracle Database Net Services Administrator's Guide to learn more about naming methods

**** Service Registration

Service registration is a feature by which the PMON process dynamically registers instance
information with a listener, which enables the listener to forward client connection
requests to the appropriate service handler. PMON provides the listener with information
about the following:

  - Names of the database services provided by the database

  - Name of the database instance associated with the services and its current and maximum
    load

  - Service handlers (dispatchers and dedicated servers) available for the instance,
    including their type, protocol addresses, and current and maximum load

Service registration is dynamic and does not require configuration in the listener.ora
file. Dynamic registration reduces administrative overhead for multiple databases or
instances.

The initialization parameter SERVICE_NAMES lists the services an instance belongs to. On
startup, each instance registers with the listeners of other instances belonging to the
same services. During database operations, the instances of each service pass information
about CPU use and current connection counts to all listeners in the same services. This
communication enables dynamic load balancing and connection failover.

See Also:

  - "Process Monitor Process (PMON)" on page 15-8

  - Oracle Database Net Services Administrator's Guide to learn more about service
    registration

  - Oracle Real Application Clusters Administration and Deployment Guide to learn about
    instance registration and client/service connections in Oracle RAC

*** Dedicated Server Architecture

In a dedicated server architecture, the server process created on behalf of each client
process is called a dedicated server process (or shadow process). This server process is
separate from the client process and acts only on its behalf, as shown in Figure 16â€“6.

A one-to-one ratio exists between the client processes and server processes. Even when the
user is not actively making a database request, the dedicated server process remains --
although it is inactive and can be paged out on some operating systems.

Figure 16â€“6 shows user and server processes running on networked computers. However, the
dedicated server architecture is also used if the same computer runs both the client
application and the database code but the host operating system could not maintain the
separation of the two programs if they were run in a single process. Linux is an example
of such an operating system.

In the dedicated server architecture, the user and server processes communicate using
different mechanisms:

  - If the client process and the dedicated server process run on the same computer, then
    the program interface uses the host operating system's interprocess communication
    mechanism to perform its job.

  - If the client process and the dedicated server process run on different computers,
    then the program interface provides the communication mechanisms (such as the network
    software and Oracle Net Services) between the programs.

Underutilized dedicated servers sometimes result in inefficient use of operating system
resources. Consider an order entry system with dedicated server processes. A customer
places an order as a clerk enters the order into the database. For most of the
transaction, the clerk is talking to the customer while the server process dedicated to
the clerk's client process is idle. The server process is not needed during most of the
transaction, and the system may be slower for other clerks entering orders if the system
is managing too many processes. For applications of this type, the shared server
architecture may be preferable.

See Also:

  - Oracle Database Net Services Administrator's Guide to learn more about dedicated
    server processes

*** Shared Server Architecture

In a shared server architecture, a dispatcher directs multiple incoming network session
requests to a pool of shared server processes, eliminating the need for a dedicated server
process for each connection. An idle shared server process from the pool picks up a
request from a common queue.

The potential benefits of shared server are as follows:

  - Reduces the number of processes on the operating system

    A small number of shared servers can perform the same amount of processing as many
    dedicated servers.

  - Reduces instance PGA memory

    Every dedicated or shared server has a PGA. Fewer server processes means fewer PGAs
    and less process management.

  - Increases application scalability and the number of clients that can simultaneously
    connect to the database
 
  - May be faster than dedicated server when the rate of client connections and
    disconnections is high

Shared server has several disadvantages, including slower response time in some cases,
incomplete feature support, and increased complexity for setup and tuning. As a general
guideline, only use shared server when you have more concurrent connections to the
database than the operating system can handle.

The following processes are needed in a shared server architecture:

  - A network listener that connects the client processes to dispatchers or dedicated
    servers (the listener is part of Oracle Net Services, not Oracle Database)

    NB: To use shared servers, a client process must connect through Oracle Net Services,
        even if the process runs on the same computer as the Oracle Database instance.

  - One or more dispatcher process (Dnnn)

  - One or more shared server processes

Note that a database can support both shared server and dedicated server connections
simultaneously. For example, one client can connect using a dedicated server while a
different client connects to the same database using a shared server.

See Also:

  - Oracle Database Net Services Administrator's Guide for more information about the
    shared server architecture

  - Oracle Database Administrator's Guide to learn how to configure a database for shared
    server

**** Dispatcher Request and Response Queues

A request from a user is a single API call that is part of the user's SQL statement. When
a user makes a call, the following actions occur:

  - The dispatcher places the request on the request queue, where it is picked up by the
    next available shared server process.

    The request queue is in the SGA and is common to all dispatcher processes of an
    instance (see "Large Pool" on page 14-21).

  - The shared server processes check the common request queue for new requests, picking
    up new requests on a first-in-first-out basis.

  - One shared server process picks up one request in the queue and makes all necessary
    calls to the database to complete this request.

    A different server process can handle each database call. Therefore, requests to parse
    a query, fetch the first row, fetch the next row, and close the result set may each be
    processed by a different shared server.

  - When the server process completes the request, it places the response on the calling
    dispatcher's response queue. Each dispatcher has its own response queue.

  - The dispatcher returns the completed request to the appropriate client process.

For example, in an order entry system, each clerk's client process connects to a
dispatcher.  Each request made by the clerk is sent to this dispatcher, which places the
request in the queue. The next available shared server picks up the request, services it,
and puts the response in the response queue. When a request is completed, the clerk
remains connected to the dispatcher, but the shared server that processed the request is
released and available for other requests. While one clerk talks to a customer, another
clerk can use the same shared server process.

***** Dispatcher Processes (Dnnn)

The dispatcher processes enable client processes to share a limited number of server
processes. You can create multiple dispatcher processes for a single database instance.
The optimum number of dispatcher processes depending on the operating system limitation
and the number of connections for each process.

  NB: Each client process that connects to a dispatcher must use Oracle Net Services, even
      if both processes run on the same host.

Dispatcher processes establish communication as follows:

  - When an instance starts, the network listener process opens and establishes a
    communication pathway through which users connect to Oracle Database.

  - Each dispatcher process gives the listener process an address at which the dispatcher
    listens for connection requests.

    At least one dispatcher process must be configured and started for each network
    protocol that the database clients will use.

  - When a client process makes a connection request, the listener determines whether the
    client process should use a shared server process:

    - If the listener determines that a shared server process is required, then the
      listener returns the address of the dispatcher process that has the lightest load,
      and the client process connects to the dispatcher directly.

    - If the process cannot communicate with the dispatcher, or if the client process
      requests a dedicated server, then the listener creates a dedicated server and
      establishes an appropriate connection.

See Also:

  - Oracle Database Net Services Administrator's Guide to learn how to configure
    dispatchers

***** Shared Server Processes (Snnn)

Each shared server process serves multiple client requests in the shared server
configuration.  Shared and dedicated server processes provide the same functionality,
except shared server processes are not associated with a specific client process. Instead,
a shared server process serves any client request in the shared server configuration.

The PGA of a shared server process does not contain UGA data, which must be accessible to
all shared server processes (see "Overview of the Program Global Area" on page 14-4). The
shared server PGA contains only process-specific data.

All session-related information is contained in the SGA. Each shared server process must
be able to access all sessions' data spaces so that any server can handle requests from
any session. Space is allocated in the SGA for each session's data space.

**** Restricted Operations of the Shared Server

Certain administrative activities cannot be performed while connected to a dispatcher
process, including shutting down or starting an instance and media recovery. These
activities are typically performed when connected with administrator privileges. To
connect with administrator privileges in a system configured with shared servers, you must
specify that you want to use a dedicated server process.

See Also:

  - Oracle Database Net Services Administrator's Guide for the proper connect string
    syntax

*** Database Resident Connection Pooling

Database Resident Connection Pooling (DRCP) provides a connection pool of dedicated
servers for typical Web application scenarios. A Web application typically makes a
database connection, uses the connection briefly, and then releases it. Through DRCP, the
database can scale to tens of thousands of simultaneous connections.

DRCP provides the following advantages:

  - Complements middle-tier connection pools that share connections between threads in a
    middle-tier process.

  - Enables database connections to be shared across multiple middle-tier processes. These
    middle-tier processes may belong to the same or different middle-tier host.

  - Enables a significant reduction in key database resources required to support many
    client connections. For example, DRCP reduces the memory required for the database and
    boosts the scalability of the database and middle tier. The pool of available servers
    also reduces the cost of re-creating client connections.

  - Provides pooling for architectures with multi-process, single-threaded application
    servers, such as PHP and Apache, that cannot do middle-tier connection pooling.

DRCP uses a pooled server, which is the equivalent of a dedicated server process (not a
shared server process) and a database session combined. The pooled server model avoids the
overhead of dedicating a server for every connection that requires the server for a short
period.

Clients obtaining connections from the database resident connection pool connect to an
Oracle background process known as the connection broker. The connection broker implements
the pool functionality and multiplexes pooled servers among inbound connections from
client processes.

As shown in

./oracle-concepts-figure-drcp.png

when a client requires database access, the connection broker picks up a server process
from the pool and hands it off to the client. The client is directly connected to the
server process until the request is served. After the server has finished, the server
process is released into the pool. The connection from the client is restored to the
broker.

In DRCP, releasing resources leaves the session intact, but no longer associated with a
connection (server process). Unlike in shared server, this session stores its UGA in the
PGA, not in the SGA. A client can reestablish a connection transparently upon detecting
activity.

See Also:

  - "Connections and Sessions" on page 15-4

  - Oracle Database Administrator's Guide and Oracle Call Interface Programmer's Guide to
    learn more about DRCP

** Overview of the Program Interface (API)

*** Program Interface (API) Structure

The program interface consists of the following pieces:

  - Oracle call interface (OCI) or the Oracle run-time library (SQLLIB)

  - The client or user side of the program interface

  - Various Oracle Net Services drivers (protocol-specific communications software)

  - Operating system communications software

  - The server or Oracle Database side of the program interface (also called the OPI)

The user and Oracle Database sides of the program interface run Oracle software, as do the drivers.

*** Program Interface (API) Drivers

Drivers are pieces of software that transport data, usually across a network. They perform
operations such as connect, disconnect, signal errors, and test for errors. Drivers are
specific to a communications protocol.

There is always a default driver. You can install multiple drivers, such as the
asynchronous or DECnet drivers, and select one as the default driver, but allow a user to
use other drivers by specifying a driver when connecting.

Different processes can use different drivers. A process can have concurrent connections
to a single database or to multiple databases using different Oracle Net Services drivers.

See Also:

  - Your system installation and configuration guide for details about choosing,
    installing, and adding drivers

  - Oracle Database Net Services Administrator's Guide to learn about JDBC drivers

*** Communications Software for the Operating System

The lowest-level software connecting the user side to the Oracle Database side of the
program interface is the communications software, which is provided by the host operating
system. DECnet, TCP/IP, LU6.2, and ASYNC are examples. The communication software can be
supplied by Oracle, but it is usually purchased separately from the hardware vendor or a
third-party software supplier.

* Part VI Oracle Database Administration and Development
* Chapter 17: Topics for Database Administrators and Developers

** Overview of Database Security

In general, database security involves user authentication, encryption, access control,
and monitoring.

*** User Accounts

Each Oracle database has a list of valid database users. The database contains several
default accounts, including the default administrative account SYSTEM (see "SYS and SYSTEM
Schemas" on page 2-5). You can create user accounts as needed.

To access a database, a user must provide a valid user name and authentication
credential. The credential may be a password, Kerberos ticket, or public key
infrastructure (PKI) certificate. You can configure database security to lock accounts
based on failed login attempts.

**** Privilege and Role Authorization

In general, database access control involves restricting data access and database
activities. For example, you can restrict users from querying specified tables or
executing specified database commands.

A user privilege is the right to run specific SQL statements. Privileges can be divided
into the following categories:

  - System privilege

    This is the right to perform a specific action in the database, or perform an action
    on any objects of a specific type. For example, CREATE USER and CREATE SESSION are
    system privileges.

  - Object privilege

    This is the right to perform a specific action on an object, for example, query the
    employees table. Privilege types are defined by the database.

Privileges are granted to users at the discretion of other users. Administrators should
grant privileges to users so they can accomplish tasks required for their jobs. Good
security practice involves granting a privilege only to a user who requires that privilege
to accomplish the necessary work.

A role is a named group of related privileges that you grant to users or other roles. A
role helps manage privileges for a database application or user group.

./oracle-concepts-figure-user-roles.png

depicts a common use for roles.

See Also:

  - Oracle Database 2 Day + Security Guide and Oracle Database Security Guide to learn how
    to manage privileges

  - Oracle Database Security Guide to learn about using roles for security

  - Oracle Database 2 Day DBA and Oracle Database Administrator's Guide to learn how to
    administer roles

  - Oracle Database Reference to learn about the SESSION_PRIVS view

**** Profiles

In the context of system resources, a profile is a named set of resource limits and
password parameters that restrict database usage and instance resources for a user.
Profiles can limit the number of concurrent sessions for a user, CPU processing time
available for each session, and amount of logical I/O available (see "Buffer I/O" on page
14-10). For example, the clerk profile could limit a user to system resources required for
clerical tasks.

  NB: It is preferable to use Database Resource Manager to limit resources and to use
      profiles to manage passwords.

Profiles provide a single point of reference for users that share a set of attributes.
You can assign a profile to one set of users, and a default profile to all others.  Each
user has at most one profile assigned at any point in time.

See Also:

  - Oracle Database Security Guide to learn how to manage resources with profiles

  - Oracle Database SQL Language Reference for CREATE PROFILE syntax and semantics

*** Authentication

Authentication is the process by which a user presents credentials to the database, which
verifies the credentials and allows access to the database.  Validating the identity
establishes a trust relationship for further interactions.  Authentication also enables
accountability by making it possible to link access and actions to specific identities.

Oracle Database provides different authentication methods, including the following:

  - Authentication by the database

    Oracle database can authenticate users using a password, Kerberos ticket, or PKI
    certificate.  Oracle also supports RADIUS-compliant devices for other forms of
    authentication, including biometrics.  The type of authentication must be specified
    when a user is created in the Oracle database.

  - Authentication by the operating system

    Some operating systems permit Oracle Database to use information they maintain to
    authenticate users.  After being authenticated by the operating system, users can
    connect to a database without specifying a user name or password.

Database operations such as shutting down or starting up the database should not be
performed by non-administrative database users. These operations require SYSDBA or SYSOPER
privileges (see "Connection with Administrator Privileges" on page 13-6).

See Also:

  - Oracle Database Security Guide and Oracle Database Advanced Security Administrator's
    Guide for more information about authentication methods

  - Oracle Database Administrator's Guide to learn about administrative authentication

*** Encryption

Encryption is the process of transforming data into an unreadable format using a secret
key and an encryption algorithm.  Encryption is often used to meet regulatory compliance
requirements, such as those associated with the Payment Card Industry Data Security
Standard (PCI-DSS) or breach notification laws.  For example, credit card numbers, social
security numbers, or patient health information must be encrypted.

**** Network Encryption

Network encryption refers to encrypting data as it travels across the network between a
client and server.  An intruder can use a network packet sniffer to capture information as
it travels on the network, and then spool it to a file for malicious use. Encrypting data
on the network prevents this sort of activity.

**** Transparent Data Encryption

Oracle Advanced Security transparent data encryption enables you to encrypt individual
table columns or a tablespace. When a user inserts data into an encrypted column, the
database automatically encrypts the data. When users select the column, the data is
decrypted. This form of encryption is transparent, provides high performance, and is easy
to implement.

Transparent data encryption includes industry-standard encryption algorithms such as the
Advanced Encryption Standard (AES) and built-in key management.

See Also:

  - Oracle Database 2 Day + Security Guide and Oracle Database Advanced Security
    Administrator's Guide

*** Access Control

**** Oracle Database Vault

Oracle Database Vault is a security option that restricts privileged user access to
application data.  You can use Oracle Database Vault to control when, where, and how the
databases, data, and applications are accessed.  Thus, you can address common security
problems such as protecting against insider threats, complying with regulatory
requirements, and enforcing separation of duty.

See Also:

  - Oracle Database 2 Day + Security Guide and Oracle Database Vault Administrator's Guide

**** Virtual Private Database (VPD)

Virtual Private Database (VPD) enables you to enforce security at the row and column
level.  A security policy establishes methods for protecting a database from accidental or
malicious destruction of data or damage to the database infrastructure.

VPD is useful when security protections such as privileges and roles are not sufficiently
fine-grained.  For example, you can allow all users to access the employees table, but
create security policies to restrict access to employees in the same department as the
user.

Essentially, the database adds a dynamic WHERE clause to a SQL statement issued against
the table, view, or synonym to which an Oracle VPD security policy was applied.  The WHERE
clause allows only users whose credentials pass the security policy to access the
protected data.

See Also:

  - Oracle Database 2 Day + Security Guide and Oracle Database Security Guide

**** Oracle Label Security (OLS)

Oracle Label Security (OLS) is a security option that enables you to assign data
classification and control access using security labels. You can assign a label to both
data and users.

When assigned to data, the label can be attached as a hidden column to existing tables,
providing transparency to existing SQL. For example, rows that contain highly sensitive
data can be labeled HIGHLY SENSITIVE, while rows that are less sensitive can be labeled
SENSITIVE, and so on. When a user attempts to access data, OLS compares the user label
with the data label and determines whether access should be granted. Unlike VPD, OLS
provides an out-of-the-box security policy and the metadata repository for defining and
storing labels.

See Also:

  - Oracle Database 2 Day + Security Guide and Oracle Label Security Administrator's Guide

*** Monitoring

**** Database Auditing

Database auditing is the monitoring and recording of selected user database actions. You
can use standard auditing to audit SQL statements, privileges, schemas, objects, and
network and multitier activity.  Alternatively, you can use fine-grained auditing to
monitor specific database activities, such as actions on a database table or times that
activities occur. For example, you can audit a table accessed after 9:00 p.m.

Reasons for using auditing include:

  - Enabling future accountability for current actions

  - Deterring users (or others, such as intruders) from inappropriate actions based on
    their accountability

  - Investigating, monitoring, and recording suspicious activity

  - Addressing auditing requirements for compliance

See Also:

  - Oracle Database 2 Day + Security Guide and Oracle Database Security Guide to learn how
    to enable and disable auditing

  - Oracle Label Security Administrator's Guide to learn about Oracle Label Security
    auditing, which supplements standard auditing

**** Oracle Audit Vault

Oracle Audit Vault enables you to consolidate, report, and configure alerts for audited
data. You can consolidate audit data generated by Oracle Database and other relational
databases. You can also use Oracle Audit Vault to monitor audit settings on target
databases.

See Also:

  - Oracle Audit Vault Administrator's Guide

**** Enterprise Manager Auditing Support

Oracle Enterprise Manager (Enterprise Manager) enables you to view and configure
audit-related initialization parameters. Also, you can administer objects when auditing
statements and schema objects. For example, Enterprise Manager enables you to display and
search for the properties of current audited statements, privileges, and objects. You can
enable and disable auditing as needed.


** Overview of High Availability

Availability is the degree to which an application, service, or functionality is available
on demand. For example, an OLTP database used by an online bookseller is available to the
extent that it is accessible by customers making purchases. Reliability, recoverability,
timely error detection, and continuous operations are the primary characteristics of high
availability.

The importance of high availability in a database environment is tied to the cost of
downtime, which is the time that a resource is unavailable. Downtime can be categorized as
either planned or unplanned. The main challenge when designing a highly available
environment is examining all possible causes of downtime and developing a plan to deal
with them.

See Also:

  - Oracle Database High Availability Overview for an introduction to high availability

*** High Availability and Unplanned Downtime

**** Site Failures

A site failure occurs when an event causes all or a significant portion of an application
to stop processing or slow to an unusable service level. A site failure may affect all
processing at a data center, or a subset of applications supported by a data center.
Examples include an extended site-wide power or network failure, a natural disaster making
a data center inoperable, or a malicious attack on operations or the site.

The simplest form of protection against site failures is to create database backups using
RMAN and store them offsite.  You can restore the database to another host.  However, this
technique can be time-consuming, and the backup may not be current.  Maintaining one or
more standby databases in a Data Guard environment enables you to provide continuous
database service if the production site fails.

See Also:

  - Oracle Database High Availability Overview to learn about site failures

  - Oracle Database Backup and Recovery User's Guide for information on RMAN and backup
    and recovery solutions

  - Oracle Data Guard Concepts and Administration for an introduction to standby databases

**** Computer Failures

A computer failure outage occurs when the system running the database becomes unavailable
because it has shut down or is no longer accessible.  Examples of computers failures
include hardware and operating system failures.

The following Oracle features protect against or help respond to computer failures:

  - Enterprise Grids

    In an Oracle Real Applications Cluster (Oracle RAC) environment, Oracle Database runs
    on two or more systems in a cluster while concurrently accessing a single shared
    database.  A single database system spans multiple hardware systems yet appears to the
    application as a single database. See "Overview of Grid Computing" on page 17-11.

  - Oracle Data Guard

    Data Guard enables you to maintain a copy of a production database, called a standby
    database, that can reside on a different continent or in the same data center. If the
    primary database is unavailable because of an outage, then Data Guard can switch any
    standby database to the primary role, minimizing downtime. See Oracle Data Guard
    Concepts and Administration.

  - Oracle Restart

    Components in the Oracle Database software stack, including the database instance,
    listener, and Oracle ASM instance, can restart automatically after a component failure
    or whenever the database host computer restarts. Oracle Restart ensures that Oracle
    components are started in the proper order, in accordance with component dependencies.
    See Oracle Database Administrator's Guide to learn how to configure Oracle Restart.

  - Fast Start Fault Recovery

    A common cause of unplanned downtime is a system fault or crash. The fast start fault
    recovery technology in Oracle Database automatically bounds database instance recovery
    time. See Oracle Database Performance Tuning Guide for information on fast start fault
    recovery.

See Also:

  - Oracle Database High Availability Best Practices to learn how to use High Availability
    for processes and applications that run in a single-instance database

**** Storage Failures

A storage failure outage occurs when the storage holding some or all of the database
contents becomes unavailable because it has shut down or is no longer accessible.
Examples of storage failures include the failure of a disk drive or storage array.

In addition to Oracle Data Guard, solutions for storage failures include the following:

  - Oracle Automatic Storage Management (Oracle ASM)

    Oracle ASM is a vertically integrated file system and volume manager in the database
    kernel (see "Oracle Automatic Storage Management (Oracle ASM)" on page 11-3).  Oracle
    ASM eliminates the complexity associated with managing data and disks, and simplifies
    mirroring and the process of adding and removing disks.

  - Backup and recovery

    The Recovery Manager (RMAN) utility can back up data, restore data from a previous
    backup, and recover changes to that data up to the time before the failure occurred
    (see "Backup and Recovery" on page 18-9).

See Also:

  - Oracle Database 2 Day DBA to learn how to administer Oracle ASM disks with Oracle
    Enterprise Manager (Enterprise Manager)

  - Oracle Automatic Storage Management Administrator's Guide to learn more about Oracle
    ASM

**** Data Corruption

A data corruption occurs when a hardware, software or network component causes corrupt
data to be read or written. For example, a volume manager error causes bad disk read or
writes. Data corruptions are rare but can have a catastrophic effect on a database, and
therefore a business.

In addition to Data Guard and Recovery Manager, Oracle Database supports the following
forms of protection against data corruption:

  - Lost write protection

    A data block lost write occurs when an I/O subsystem acknowledges the completion of
    the block write when the write did not occur.  You can configure the database so that
    it records buffer cache block reads in the redo log.  Lost write detection is most
    effective when used with Data Guard.

  - Data block corruption detection

    A block corruption is a data block that is not in a recognized Oracle format, or whose
    contents are not internally consistent.  Several database components and utilities,
    including RMAN, can detect a corrupt block and record it in
    V$DATABASE_BLOCK_CORRUPTION.  If the environment uses a real-time standby database,
    then RMAN can automatically repair corrupt blocks.

  - Data Recovery Advisor

    Data Recovery Advisor is an Oracle tool that automatically diagnoses data failures,
    determines and presents appropriate repair options, and executes repairs at the user's
    request.

See Also:

  - Oracle Database High Availability Best Practices to learn how to protect against data
    corruptions

  - Oracle Database Backup and Recovery User's Guide for information on RMAN and backup
    and recovery solutions

**** Human Errors

A human error outage occurs when unintentional or malicious actions are committed that
cause data in the database to become logically corrupt or unusable. The service level
impact of a human error outage can vary significantly depending on the amount and critical
nature of the affected data.

Much research cites human error as the largest cause of downtime. Oracle Database provides
powerful tools to help administrators quickly diagnose and recover from these errors.  It
also includes features that enable end users to recover from problems without
administrator involvement.

Oracle Database recommends the following forms of protection against human error:

  - Restriction of user access

    The best way to prevent errors is to restrict user access to data and services. Oracle
    Database provides a wide range of security tools to control user access to application
    data by authenticating users and then allowing administrators to grant users only
    those privileges required to perform their duties (see "Overview of Database Security"
    on page 17-1).

  - Oracle Flashback Technology

    Oracle Flashback Technology is a family of human error correction features in Oracle
    Database.  Oracle Flashback provides a SQL interface to quickly analyze and repair
    human errors. For example, you can perform:

    - Fine-grained surgical analysis and repair for localized damage

    - Rapid correction of more widespread damage

    - Recovery at the row, transaction, table, tablespace, and database level

  - Oracle LogMiner

    Oracle LogMiner is a relational tool that enables online redo log files to be read,
    analyzed, and interpreted using SQL (see "Oracle LogMiner" on page 18-8).

See Also:

  - Oracle Database High Availability Best Practices to learn how to recover from human
    errors

  - Oracle Database Backup and Recovery User's Guide and Oracle Database Advanced
    Application Developer's Guide to learn more about Oracle Flashback features

  - Oracle Database Utilities to learn more about Oracle LogMiner

*** High Availability and Planned Downtime

**** System and Database Changes

Planned system changes occur when you perform routine and periodic maintenance operations
and new deployments, including scheduled changes to the operating environment that occur
outside of the organizational data structure in the database. Examples include adding or
removing CPUs and cluster nodes (a node is a computer on which a database instance
resides), upgrading system hardware or software, and migrating the system platform.

Oracle Database provides dynamic resource provisioning as a solution to planned system and
database changes:

  - Dynamic reconfiguration of the database

    Oracle Database dynamically accommodates various changes to hardware and database
    configurations, including adding and removing processors from an SMP server and adding
    and remove storage arrays using Oracle ASM. For example, Oracle Database monitors the
    operating system to detect changes in the number of CPUs. If the CPU_COUNT
    initialization parameter is set to the default, then the database workload can
    dynamically take advantage of newly added processors.

  - Autotuning memory management

    Oracle Database uses a noncentralized policy to free and acquire memory in each
    subcomponent of the SGA and the PGA. Oracle Database autotunes memory by prompting the
    operating system to transfer granules of memory to components that require it. See
    "Memory Management" on page 18-15.

  - Automated distributions of data files, control files, and online redo log files

    Oracle ASM automates and simplifies the layout of data files, control files, and log
    files by automatically distributing them across all available disks. See Oracle
    Automatic Storage Management Administrator's Guide to learn more about Oracle ASM.

**** Data Changes

Planned data changes occur when there are changes to the logical structure or physical
organization of Oracle Database objects. The primary objective of these changes is to
improve performance or manageability. Examples include table redefinition, adding table
partitions, and creating or rebuilding indexes.

Oracle Database minimizes downtime for data changes through online reorganization and
redefinition. This architecture enables you to perform the following tasks when the
database is open:

  - Perform online table redefinition, which enables you to make table structure
    modifications without significantly affecting the availability of the table

  - Create, analyze, and reorganize indexes (see Chapter 3, "Indexes and Index-Organized
    Tables")

  - Move table partitions (see "Overview of Partitions" on page 4-1)

See Also:

  - Oracle Database Administrator's Guide to learn how to change data structures online

**** Application Changes

Planned application changes may include changes to data, schemas, and programs. The
primary objective of these changes is to improve performance, manageability, and
functionality.  An example is an application upgrade.

Oracle Database supports the following solutions for minimizing application downtime
required to make changes to an application's database objects:

  - Rolling patch updates

    Oracle Database supports the application of patches to the nodes of an Oracle RAC
    system in a rolling fashion. See Oracle Database High Availability Best Practices.

  - Rolling release upgrades

    Oracle Database supports the installation of database software upgrades, and the
    application of patchsets, in a rolling fashionâ€”with near zero database downtimeâ€”by
    using Data Guard SQL Apply and logical standby databases. See Oracle Database Upgrade
    Guide.

  - Edition-based redefinition

    Edition-based redefinition enables you to upgrade the database objects of an
    application while the application is in use, thus minimizing or eliminating down time.
    Oracle Database accomplishes this task by changing (redefining) database objects in a
    private environment known as an edition.  See Oracle Database Advanced Application
    Developer's Guide.

  - DDL with the default WAIT option

    DDL commands require exclusive locks on internal structures (see "DDL Locks" on page
    9-24).  In previous releases, DDL commands would fail if they could not obtain the
    locks.  DDL specified with the WAIT option resolves this issue.  See Oracle Database
    High Availability Overview.

  - Creation of triggers in a disabled state

    You can create a trigger in the disabled state so that you can ensure that your code
    compiles successfully before you enable the trigger.  See Oracle Database PL/SQL
    Language Reference.

** Overview of Grid Computing

Grid computing is a computing architecture that effectively pools large numbers of servers
and storage into a flexible, on-demand resource for all enterprise computing needs.  A
Database Server Grid is a collection of commodity servers connected together to run on one
or more databases.  A Database Storage Grid is a collection of low-cost modular storage
arrays combined together and accessed by the computers in the Database Server Grid.

With the Database Server and Storage Grid, you can build a pool of system resources. You
can dynamically allocate and deallocate these resources based on business priorities.

./oracle-concepts-figure-grid.png

illustrates the Database Server Grid and Database Storage Grid in a Grid enterprise
computing environment.

See Also:

  - Oracle Database High Availability Overview for an overview of Grid Computing

  - http://www.gridforum.org/ to learn about the standards organization Global Grid Forum
    (GGF)

*** Database Server Grid

Oracle Real Application Clusters (Oracle RAC) enables multiple instances that are linked
by an interconnect to share access to an Oracle database. In an Oracle RAC environment,
Oracle Database runs on two or more systems in a cluster while concurrently accessing a
single shared database. Oracle RAC enables a Database Server Grid by providing a single
database that spans multiple low-cost servers yet appears to the application as a single,
unified database system.

Oracle Clusterware is software that enables servers to operate together as if they are one
server. Each server looks like any standalone server. However, each server has additional
processes that communicate with each other so that separate servers work together as if
they were one server. Oracle Clusterware provides all of the features required to run the
cluster, including node membership and messaging services.

See Also:

  - Oracle Database 2 Day + Real Application Clusters Guide for an introduction to Oracle
    Clusterware and Oracle RAC

  - Oracle Real Application Clusters Administration and Deployment Guide to learn how to
    manage an Oracle RAC database

  - Oracle Clusterware Administration and Deployment Guide to learn how to administer and
    deploy Oracle Clusterware

**** Scalability

In a Database Server Grid, Oracle RAC enables you to add nodes to the cluster as the
demand for capacity increases. The Cache Fusion technology implemented in Oracle RAC
enables you to scale capacity without changing your applications. Thus, you can scale the
system incrementally to save costs and eliminate the need to replace smaller single-node
systems with larger ones.

You can incrementally add nodes to a cluster instead of replacing existing systems with
larger nodes. Grid Plug and Play simplifies addition and removal of nodes from a cluster,
making it easier to deploy clusters in a dynamically provisioned environment. Grid Plug
and Play also enables databases and services to be managed in a location-independent
manner. SCAN enables clients to connect to the database service without regard for its
location within the grid.

See Also:

  - Oracle Real Application Clusters Administration and Deployment Guide to learn more
    about Cache Fusion

  - Oracle Database Installation Guide to learn how to install Grid Plug and Play

**** Fault Tolerance

Fault tolerance is the protection provided by a high availability architecture against the
failure of a component in the architecture. A key advantage of the Oracle RAC architecture
is the inherent fault tolerance provided by multiple nodes. Because the physical nodes run
independently, the failure of one or more nodes does not affect other nodes in the
cluster.

Failover can happen to any node on the Grid. In the extreme case, an Oracle RAC system
provides database service even when all but one node is down. This architecture allows a
group of nodes to be transparently put online or taken offline, for maintenance, while the
rest of the cluster continues to provide database service.

Oracle RAC provides built-in integration with Oracle Clients and connection pools. With
this capability, an application is immediately notified of any failure through the pool
that terminates the connection. The application avoids waiting for a TCP timeout and can
immediately take the appropriate recovery action. Oracle RAC integrates the listener with
Oracle Clients and the connection pools to create optimal application throughput. Oracle
RAC can balance cluster workload based on the load at the time of the transaction.

See Also:

  - "Database Resident Connection Pooling" on page 16-14

  - Oracle Real Application Clusters Administration and Deployment Guide to learn more
    about automatic workload management

  - Oracle Database High Availability Best Practices for an overview of fault tolerance in
    Oracle RAC

**** Services

Oracle RAC supports services that can group database workloads and route work to the
optimal instances assigned to offer the services. A service represents the workload of
applications with common attributes, performance thresholds, and priorities.

You define and apply business policies to these services to perform tasks such as to
allocate nodes for times of peak processing or to automatically handle a server failure.
Using services ensures the application of system resources where and when they are needed
to achieve business goals.

Services are integrated with the Database Resource Manager, which enables you to restrict
the resources that are used by a service within an instance. In addition, Oracle Scheduler
jobs can run using a service, as opposed to using a specific instance.

See Also:

  - Oracle Database 2 Day + Real Application Clusters Guide to learn about Oracle services

  - Oracle Database Administrator's Guide to learn about the Database Resource Manager and
    Oracle Scheduler

*** Database Storage Grid

A DBA or storage administrator can use the Oracle ASM interface to specify the disks
within the Database Storage Grid that ASM should manage across all server and storage
platforms.  ASM partitions the disk space and evenly distributes the data across the disks
provided to ASM.  Additionally, ASM automatically redistributes data as disks from storage
arrays are added or removed from the Database Storage Grid.

See Also:

  - "Oracle Automatic Storage Management (Oracle ASM)" on page 11-3

  - Oracle Database High Availability Overview for an overview of the Database Storage
    Grid

  - Oracle Automatic Storage Management Administrator's Guide for more information about
    clustered Oracle ASM

** Overview of Data Warehousing and Business Intelligence

A data warehouse is a relational database designed for query and analysis rather than for
transaction processing.  For example, a data warehouse could track historical stock prices
or income tax records.  A warehouse usually contains data derived from historical
transaction data, but it can include data from other sources.

A data warehouse environment includes several tools in addition to a relational database.
A typical environment includes an ETL solution, an OLAP engine, Oracle Warehouse Builder,
client analysis tools, and other applications that gather data and deliver it to users.

*** Data Warehousing and OLTP

A common way of introducing data warehousing is to refer to the characteristics of a data
warehouse as set forth by William Inmon (Building the Data Warehouse, John Wiley and Sons,
1996.):

  - Subject-Oriented

    Data warehouses enable you to define a database by subject matter, such as sales.

  - Integrated

    Data warehouses must put data from disparate sources into a consistent format. They
    must resolve such problems as naming conflicts and inconsistencies among units of
    measure.  When they achieve this goal, they are said to be integrated.

  - Nonvolatile

    The purpose of a warehouse is to enable you to analyze what has occurred. Thus, after
    data has entered into the warehouse, data should not change.

  - Time-Variant

    The focus of a data warehouse is on change over time.

Data warehouses and OLTP database have different requirements.  For example, to discover
trends in business, data warehouses must maintain large amounts of data.  In contrast,
good performance requires historical data to be moved regularly from OLTP systems to an
archive.  Table 17â€“1 lists differences between data warehouses and OLTP.

Characteristics     Data Warehouse                          OLTP
---------------     ------------------------------------    ------------------------------------
Workload            Designed to accommodate ad hoc          Supports only predefined      
                    queries.  You may not know the          operations.  Your applications
                    workload of your data warehouse in      might be specifically tuned or
                    advance, so it should be optimized      designed to support only these
                    to perform well for a wide variety      operations.
                    of possible queries.              

---------------     ------------------------------------    ------------------------------------
Data                Updated on a regular basis by the       Subject to individual DML            
modifications       ETL process using bulk data             statements routinely issued by end
                    modification techniques.  End           users.  The OLTP database is      
                    users of a data warehouse do not        always up to date and reflects the
                    directly update the database.           current state of each business    
                                                            transaction.

---------------     ------------------------------------    ------------------------------------
Schema design       Uses denormalized or partially          Uses fully normalized schemas to
                    denormalized schemas (such as a         optimize DML performance and to 
                    star schema) to optimize query          guarantee data consistency.
                    performance.

---------------     ------------------------------------    ------------------------------------
Typical             A typical query scans thousands or      A typical operation accesses only 
operations          millions of rows.  For example, a       a handful of records. For example,
                    user may request the total sales        a user may retrieve the current   
                    for all customers last month.           order for a single customer.

---------------     ------------------------------------    ------------------------------------
Historical data     Stores many months or years of          Stores data from only a few weeks
                    data to support historical              or months.  Historical data      
                    analysis.                               retained as needed to meet the   
                                                            requirements of the current      
                                                            transaction.
---------------     ------------------------------------    ------------------------------------

See Also:

  - Oracle Database Data Warehousing Guide for a more detailed description of a database
    warehouse

  - Oracle Database VLDB and Partitioning Guide for a more detailed description of an OLTP
    system

*** Data Warehouse Architecture

**** Data Warehouse Architecture (Basic)

./oracle-concepts-figure-data-warehouse-basic.png

shows a simple architecture for a data warehouse. End users directly access data that was
transported from several source systems to the data warehouse.

Figure 17â€“3 shows both the metadata and raw data of a traditional OLTP system and summary
data.  A summary is an aggregate view that improves query performance by precalculating
expensive joins and aggregation operations and storing the results in a table.  For
example, a summary table can contain the sums of sales by region and by product. Summaries
are also called materialized views.

See Also:

  - Oracle Database Data Warehousing Guide to learn about basic materialized views

**** Data Warehouse Architecture (with a Staging Area)

In the architecture shown in Figure 17â€“3, operational data must be cleaned and processed
before being put into the warehouse.

./oracle-concepts-figure-data-warehouse-staging.png

shows a data warehouse with a staging area, which is a place where data is preprocessed
before entering the warehouse. A staging area simplifies the tasks of building summaries
and managing the warehouse.

**** Data Warehouse Architecture (with a Staging Area and Data Marts)

You may want to customize your warehouse architecture for different groups within your
organization. You can achieve this goal by transporting data in the warehouse to data
marts, which are independent databases designed for a specific business or project.
Typically, data marts include many summary tables.

./oracle-concepts-figure-data-warehouse-data-marts.png

separates purchasing, sales, and inventory information into independent data marts.  A
financial analyst can query the data marts for historical information about purchases and
sales.

See Also:

  - Oracle Database Data Warehousing Guide to learn about transformation mechanisms

*** Overview of Extraction, Transformation, and Loading (ETL)

The process of extracting data from source systems and bringing it into the warehouse is
commonly called ETL: extraction, transformation, and loading. ETL refers to a broad
process rather than three well-defined steps.

In a typical scenario, data from one or more operational systems is extracted and then
physically transported to the target system or an intermediate system for processing.
Depending on the method of transportation, some transformations can occur during this
process. For example, a SQL statement that directly accesses a remote target through a
gateway can concatenate two columns as part of the SELECT statement.

Oracle Database is not itself an ETL tool. However, Oracle Database provides a rich set of
capabilities usable by ETL tools such as Oracle Warehouse Builder and customized ETL
solutions.  ETL capabilities provided by Oracle Database include:

  - Transportable tablespaces

    You can transport tablespaces between different computer architectures and operating
    systems.  Transportable tablespaces are the fastest way for moving large volumes of
    data between two Oracle databases.  See Oracle Database Administrator's Guide to learn
    about transportable tablespaces.

  - Table functions

    A table function can produce a set of rows as output and can accept a set of rows as
    input. Table functions provide support for pipelined and parallel execution of
    transformations implemented in PL/SQL, C, or Java without requiring the use of
    intermediate staging tables. See Oracle Database Data Warehousing Guide to learn about
    table functions.

  - External tables

    External tables enable external data to be joined directly and in parallel without
    requiring it to be first loaded in the database (see "External Tables" on page
    2-16). Thus, external tables enable the pipelining of the loading phase with the
    transformation phase.

  - Table compression

    To reduce disk use and memory use, you can store tables and partitioned tables in a
    compressed format (see "Table Compression" on page 2-19). The use of table compression
    often leads to a better scaleup for read-only operations and faster query execution.

  - Change Data Capture

    This feature efficiently identifies and captures data that has been added to, updated
    in, or removed from, relational tables and makes this change data available for use by
    applications or individuals.

See Also:

  - Oracle Database Data Warehousing Guide to learn about Change Data Capture

  - Oracle Warehouse Builder Data Modeling, ETL, and Data Quality Guide for an overview of
    ETL

*** Business Intelligence

Business intelligence is the analysis of an organization's information as an aid to making
business decisions.  Business intelligence and analytical applications are dominated by
actions such as drilling up and down hierarchies and comparing aggregate values.  Oracle
Database provides several technologies to support business intelligence operations.

**** Analytic SQL

Oracle Database has introduced many SQL operations for performing analytic operations.
These operations include ranking, moving averages, cumulative sums, ratio-to-reports, and
period-over-period comparisons. For example, Oracle Database supports the following forms
of analytic SQL:

  - SQL for aggregation

    Aggregate functions such as COUNT return a single result row based on groups of rows
    rather than on single rows. Aggregation is fundamental to data warehousing. To improve
    aggregation performance in a warehouse, the database provides extensions to the GROUP
    BY clause to make querying and reporting easier and faster. See Oracle Database Data
    Warehousing Guide to learn about aggregation.

  - SQL for analysis

    Analytic functions compute an aggregate value based on a group of rows. They differ
    from aggregate functions in that they return multiple rows for each group.  Oracle has
    advanced SQL analytical processing capabilities using a family of analytic SQL
    functions.  For example, these analytic functions enable you to calculate rankings and
    percentiles and moving windows. See Oracle Database Data Warehousing Guide to learn
    about SQL for analysis and reporting.

  - SQL for modeling

    With the MODEL clause, you can create a multidimensional array from query results and
    apply rules to this array to calculate new values. For example, you can partition data
    in a sales view by country and perform a model computation, as defined by multiple
    rules, on each country. One rule could calculate the sales of a product in 2008 as the
    sum of sales in 2006 and 2007. See Oracle Database Data Warehousing Guide to learn
    about SQL modeling.

See Also:

  - Oracle Database SQL Language Reference to learn about SQL functions

**** OLAP

Oracle online analytical processing (OLAP) provides native multidimensional storage and
rapid response times when analyzing data across multiple dimensions.  OLAP enables
analysts to quickly obtain answers to complex, iterative queries during interactive
sessions.

Oracle OLAP has the following primary characteristics:

  - Oracle OLAP is integrated in the database so that you can use standard SQL
    administrative, querying, and reporting tools.

  - The OLAP engine runs within the kernel of Oracle Database.

  - Dimensional objects are stored in Oracle Database in their native multidimensional
    format.

  - Cubes and other dimensional objects are first class data objects represented in the
    Oracle data dictionary.

  - Data security is administered in the standard way, by granting and revoking privileges
    to Oracle Database users and roles.

Oracle OLAP offers the power of simplicity: one database, standard administration and
security, and standard interfaces and development tools.

See Also:

  - "Overview of Dimensions" on page 4-21

  - Oracle OLAP User's Guide for an overview of Oracle OLAP

**** Data Mining

Data mining involves automatically searching large stores of data for patterns and trends
that go beyond simple analysis. Data mining uses sophisticated mathematical algorithms to
segment data and evaluate the probability of future events. Typical applications of data
mining include call centers, ATMs, E-business relational management (ERM), and business
planning.

With Oracle Data Mining, the data, data preparation, model building, and model scoring
results all remain in the database. Oracle Data Mining supports a PL/SQL API, a Java API,
SQL functions for model scoring, and a GUI called Oracle Data Miner. Thus, Oracle Database
provides an infrastructure for application developers to integrate data mining seamlessly
with database applications.

See Also:

  - Oracle Data Mining Concepts

** Overview of Oracle Information Integration

As an organization evolves, it becomes increasingly important for it to be able to share
information among multiple databases and applications. The basic approaches to sharing
information are as follows:

  - Consolidation

    You can consolidate the information into a single database, which eliminates the need
    for further integration. Oracle RAC, Grid computing, and Oracle VPD can enable you to
    consolidate information into a single database.

  - Federation

    You can leave information distributed, and provide tools to federate this information,
    making it appear to be in a single virtual database.

  - Sharing

    You can share information, which lets you maintain the information in multiple data
    stores and applications.

This section focuses on Oracle solutions for federating and sharing information.

See Also:

  - Oracle Database 2 Day + Data Replication and Integration Guide for an introduction to
    data replication and integration

*** Federated Access

The foundation of federated access is a distributed environment, which is a network of
disparate systems that seamlessly communicate with each other. Each system in the
environment is called a node. The system to which a user is directly connected is called
the local system. Additional systems accessed by this user are remote systems.

A distributed environment enables applications to access and exchange data from the local
and remote systems. All the data can be simultaneously accessed and modified.

**** Distributed SQL

Distributed SQL synchronously accesses and updates data distributed among multiple
databases.  An Oracle distributed database system can be transparent to users, making it
appear as a single Oracle database.

Distributed SQL includes distributed queries and distributed transactions. The Oracle
distributed database architecture provides query and transaction transparency. For
example, standard DML statements work just as they do in a non-distributed database
environment. Additionally, applications control transactions using the standard SQL
statements COMMIT, SAVEPOINT, and ROLLBACK.

See Also:

  - "Overview of Distributed Transactions" on page 10-12

  - Oracle Database 2 Day + Data Replication and Integration Guide to learn about
    distributed SQL

  - Oracle Database Administrator's Guide to learn how to manage distributed transactions

**** Database Links

A database link is a connection between two physical databases that enables a client to
access them as one logical database. Oracle Database uses database links to enable users
on one database to access objects in a remote database. A local user can access a link to
a remote database without being a user on the remote database.

See Also:

  - Oracle Database Administrator's Guide to learn about database links

*** Information Sharing

Start here

* End Of Outline

Local Variables:
mode: outline-minor
End:


